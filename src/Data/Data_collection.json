[
    {
        "\ufeffID": "L10937",
        "Parent": "L8817",
        "commitID_before": "ad9bac95199736c270940c4037b7ee7174bacca6",
        "commitID_after": "3468a5fbd868ce63c4cb61782e9baddac2ed24ae",
        "Project": "https://github.com/antlr/antlr4",
        "Type": "INTRODUCE_EXPLAINING_VARIABLE",
        "Fowler_type": "Extract Variable",
        "path_before": "tool\\src\\org\\antlr\\v4\\codegen\\ParserFactory.java",
        "path_after": "tool\\src\\org\\antlr\\v4\\codegen\\ParserFactory.java",
        "name": "List<SrcOp> set(GrammarAST setAST, GrammarAST labelAST, boolean invert)",
        "LongName": "org.antlr.v4.codegen.ParserFactory.set(Lorg/antlr/v4/tool/ast/GrammarAST;Lorg/antlr/v4/tool/ast/GrammarAST;Z)Ljava/util/List;",
        "b_StartLine": "",
        "b_StartColumn": "",
        "b_EndLine": "",
        "b_EndColumn": "",
        "a_StartLine": "178",
        "a_StartColumn": "2",
        "a_EndLine": "199",
        "a_EndColumn": "3",
        "BeforeRefact": "\n\tpublic List<SrcOp> set(GrammarAST setAST, GrammarAST labelAST, boolean invert) {\n\t\tMatchSet matchOp;\n\t\tif ( invert ) matchOp = new MatchNotSet(this, setAST);\n\t\telse matchOp = new MatchSet(this, setAST);\n\t\tif ( labelAST!=null ) {\n\t\t\tString label = labelAST.getText();\n\t\t\tDecl d = getTokenLabelDecl(label);\n\t\t\tmatchOp.labels.add(d);\n\t\t\tgetCurrentRuleFunction().addContextDecl(setAST.getAltLabel(), d);\n\t\t\tif ( labelAST.parent.getType() == ANTLRParser.PLUS_ASSIGN ) {\n\t\t\t\tTokenListDecl l = getTokenListLabelDecl(label);\n\t\t\t\tgetCurrentRuleFunction().addContextDecl(setAST.getAltLabel(), l);\n\t\t\t}\n\t\t}\n\t\tif ( controller.needsImplicitLabel(setAST, matchOp) ) defineImplicitLabel(setAST, matchOp);\n\t\tAddToLabelList listLabelOp = getAddToListOpIfListLabelPresent(matchOp, labelAST);\n\t\treturn list(matchOp, listLabelOp);\n\t}",
        "AfterRefact": "public List<SrcOp> set(GrammarAST setAST, GrammarAST labelAST, boolean invert) {\n\t\tMatchSet matchOp;\n\t\tif ( invert ) matchOp = new MatchNotSet(this, setAST);\n\t\telse matchOp = new MatchSet(this, setAST);\n\t\tif ( labelAST!=null ) {\n\t\t\tString label = labelAST.getText();\n\t\t\tRuleFunction rf = getCurrentRuleFunction();\n\t\t\tif ( labelAST.parent.getType() == ANTLRParser.PLUS_ASSIGN ) {\n\t\t\t\tdefineImplicitLabel(setAST, matchOp);\n\t\t\t\tTokenListDecl l = getTokenListLabelDecl(label);\n\t\t\t\trf.addContextDecl(setAST.getAltLabel(), l);\n\t\t\t}\n\t\t\telse {\n\t\t\t\tDecl d = getTokenLabelDecl(label);\n\t\t\t\tmatchOp.labels.add(d);\n\t\t\t\trf.addContextDecl(setAST.getAltLabel(), d);\n\t\t\t}\n\t\t}\n\t\tif ( controller.needsImplicitLabel(setAST, matchOp) ) defineImplicitLabel(setAST, matchOp);\n\t\tAddToLabelList listLabelOp = getAddToListOpIfListLabelPresent(matchOp, labelAST);\n\t\treturn list(matchOp, listLabelOp);\n\t}",
        "Extra": ""
    },
    {
        "\ufeffID": "L5343",
        "Parent": "L543",
        "commitID_before": "ad9bac95199736c270940c4037b7ee7174bacca6",
        "commitID_after": "3468a5fbd868ce63c4cb61782e9baddac2ed24ae",
        "Project": "https://github.com/antlr/antlr4",
        "Type": "INTRODUCE_EXPLAINING_VARIABLE",
        "Fowler_type": "Extract Variable",
        "path_before": "runtime\\Java\\src\\org\\antlr\\v4\\runtime\\Parser.java",
        "path_after": "runtime\\Java\\src\\org\\antlr\\v4\\runtime\\Parser.java",
        "name": "List<ParseTreeListener> getParseListeners()",
        "LongName": "org.antlr.v4.runtime.Parser.getParseListeners()Ljava/util/List;",
        "b_StartLine": "",
        "b_StartColumn": "",
        "b_EndLine": "",
        "b_EndColumn": "",
        "a_StartLine": "298",
        "a_StartColumn": "2",
        "a_EndLine": "305",
        "a_EndColumn": "3",
        "BeforeRefact": "public List<ParseTreeListener> getParseListeners() {\n        return _parseListeners;\n    }",
        "AfterRefact": "public List<ParseTreeListener> getParseListeners() {\n\t\tList<ParseTreeListener> listeners = _parseListeners;\n\t\tif (listeners == null) {\n\t\t\treturn Collections.emptyList();\n\t\t}\n\n\t\treturn listeners;\n\t}",
        "Extra": ""
    },
    {
        "\ufeffID": "L3671",
        "Parent": "L3660",
        "commitID_before": "ad9bac95199736c270940c4037b7ee7174bacca6",
        "commitID_after": "3468a5fbd868ce63c4cb61782e9baddac2ed24ae",
        "Project": "https://github.com/antlr/antlr4",
        "Type": "INTRODUCE_EXPLAINING_VARIABLE",
        "Fowler_type": "Extract Variable",
        "path_before": "runtime\\Java\\src\\org\\antlr\\v4\\runtime\\DiagnosticErrorListener.java",
        "path_after": "runtime\\Java\\src\\org\\antlr\\v4\\runtime\\DiagnosticErrorListener.java",
        "name": "void reportAmbiguity(Parser recognizer, DFA dfa, int startIndex, int stopIndex, boolean exact, BitSet ambigAlts, ATNConfigSet configs)",
        "LongName": "org.antlr.v4.runtime.DiagnosticErrorListener.reportAmbiguity(Lorg/antlr/v4/runtime/Parser;Lorg/antlr/v4/runtime/dfa/DFA;IIZLjava/util/BitSet;Lorg/antlr/v4/runtime/atn/ATNConfigSet;)V",
        "b_StartLine": "",
        "b_StartColumn": "",
        "b_EndLine": "",
        "b_EndColumn": "",
        "a_StartLine": "89",
        "a_StartColumn": "2",
        "a_EndLine": "107",
        "a_EndColumn": "3",
        "BeforeRefact": " public void reportAmbiguity(@NotNull Parser recognizer,\n\t\t\t\t\t\t\t\tDFA dfa, int startIndex, int stopIndex,\n\t\t\t\t\t\t\t\t@NotNull BitSet ambigAlts,\n\t\t\t\t\t\t\t\t@NotNull ATNConfigSet configs)\n    {\n        recognizer.notifyErrorListeners(\"reportAmbiguity d=\" + dfa.decision +\n\t\t\t\": ambigAlts=\" + ambigAlts + \", input='\" +\n\t\t\trecognizer.getTokenStream().getText(Interval.of(startIndex, stopIndex)) + \"'\");\n    }",
        "AfterRefact": "public void reportAmbiguity(@NotNull Parser recognizer,\n\t\t\t\t\t\t\t\tDFA dfa,\n\t\t\t\t\t\t\t\tint startIndex,\n\t\t\t\t\t\t\t\tint stopIndex,\n\t\t\t\t\t\t\t\tboolean exact,\n\t\t\t\t\t\t\t\t@Nullable BitSet ambigAlts,\n\t\t\t\t\t\t\t\t@NotNull ATNConfigSet configs)\n\t{\n\t\tif (exactOnly && !exact) {\n\t\t\treturn;\n\t\t}\n\n\t\tString format = \"reportAmbiguity d=%s: ambigAlts=%s, input='%s'\";\n\t\tString decision = getDecisionDescription(recognizer, dfa);\n\t\tBitSet conflictingAlts = getConflictingAlts(ambigAlts, configs);\n\t\tString text = recognizer.getTokenStream().getText(Interval.of(startIndex, stopIndex));\n\t\tString message = String.format(format, decision, conflictingAlts, text);\n\t\trecognizer.notifyErrorListeners(message);\n\t}",
        "Extra": ""
    },
    {
        "\ufeffID": "L3692",
        "Parent": "L3660",
        "commitID_before": "ad9bac95199736c270940c4037b7ee7174bacca6",
        "commitID_after": "3468a5fbd868ce63c4cb61782e9baddac2ed24ae",
        "Project": "https://github.com/antlr/antlr4",
        "Type": "INTRODUCE_EXPLAINING_VARIABLE",
        "Fowler_type": "Extract Variable",
        "path_before": "runtime\\Java\\src\\org\\antlr\\v4\\runtime\\DiagnosticErrorListener.java",
        "path_after": "runtime\\Java\\src\\org\\antlr\\v4\\runtime\\DiagnosticErrorListener.java",
        "name": "void reportContextSensitivity(Parser recognizer, DFA dfa, int startIndex, int stopIndex, int prediction, ATNConfigSet configs)",
        "LongName": "org.antlr.v4.runtime.DiagnosticErrorListener.reportContextSensitivity(Lorg/antlr/v4/runtime/Parser;Lorg/antlr/v4/runtime/dfa/DFA;IIILorg/antlr/v4/runtime/atn/ATNConfigSet;)V",
        "b_StartLine": "",
        "b_StartColumn": "",
        "b_EndLine": "",
        "b_EndColumn": "",
        "a_StartLine": "125",
        "a_StartColumn": "2",
        "a_EndLine": "137",
        "a_EndColumn": "3",
        "BeforeRefact": "public void reportContextSensitivity(@NotNull Parser recognizer,\n\t\t\t\t\t\t\t\t\t\t @NotNull DFA dfa,\n                                         int startIndex, int stopIndex,\n\t\t\t\t\t\t\t\t\t\t @NotNull ATNConfigSet configs)\n    {\n        recognizer.notifyErrorListeners(\"reportContextSensitivity d=\" +\n\t\t\tdfa.decision + \", input='\" +\n\t\t\trecognizer.getTokenStream().getText(Interval.of(startIndex, stopIndex)) + \"'\");\n    }\n}",
        "AfterRefact": "public void reportContextSensitivity(@NotNull Parser recognizer,\n\t\t\t\t\t\t\t\t\t\t @NotNull DFA dfa,\n\t\t\t\t\t\t\t\t\t\t int startIndex,\n\t\t\t\t\t\t\t\t\t\t int stopIndex,\n\t\t\t\t\t\t\t\t\t\t int prediction,\n\t\t\t\t\t\t\t\t\t\t @NotNull ATNConfigSet configs)\n\t{\n\t\tString format = \"reportContextSensitivity d=%s, input='%s'\";\n\t\tString decision = getDecisionDescription(recognizer, dfa);\n\t\tString text = recognizer.getTokenStream().getText(Interval.of(startIndex, stopIndex));\n\t\tString message = String.format(format, decision, text);\n\t\trecognizer.notifyErrorListeners(message);\n\t}",
        "Extra": ""
    },
    {
        "\ufeffID": "L7413",
        "Parent": "L7392",
        "commitID_before": "ad9bac95199736c270940c4037b7ee7174bacca6",
        "commitID_after": "3468a5fbd868ce63c4cb61782e9baddac2ed24ae",
        "Project": "https://github.com/antlr/antlr4",
        "Type": "INTRODUCE_ASSERTION",
        "Fowler_type": "Introduce Assertion",
        "path_before": "tool\\src\\org\\antlr\\v4\\analysis\\AnalysisPipeline.java",
        "path_after": "tool\\src\\org\\antlr\\v4\\analysis\\AnalysisPipeline.java",
        "name": "void processParser()",
        "LongName": "org.antlr.v4.analysis.AnalysisPipeline.processParser()V",
        "b_StartLine": "",
        "b_StartColumn": "",
        "b_EndLine": "",
        "b_EndColumn": "",
        "a_StartLine": "82",
        "a_StartColumn": "2",
        "a_EndLine": "101",
        "a_EndColumn": "3",
        "BeforeRefact": "protected void processParser() {\n\t\tg.decisionLOOK = new ArrayList<IntervalSet[]>(g.atn.getNumberOfDecisions()+1);\n\t\tfor (DecisionState s : g.atn.decisionToState) {\n            g.tool.log(\"LL1\", \"\\nDECISION \"+s.decision+\" in rule \"+g.getRule(s.ruleIndex).name);\n\t\t\tIntervalSet[] look;\n\t\t\tif ( s.nonGreedy ) { // nongreedy decisions can't be LL(1)\n\t\t\t\tlook = new IntervalSet[s.getNumberOfTransitions()+1];\n\t\t\t}\n\t\t\telse {\n\t\t\t\tLL1Analyzer anal = new LL1Analyzer(g.atn);\n\t\t\t\tlook = anal.getDecisionLookahead(s);\n\t\t\t\tg.tool.log(\"LL1\", \"look=\" + Arrays.toString(look));\n\t\t\t}\n\t\t\tUtils.setSize(g.decisionLOOK, s.decision+1);\n\t\t\tg.decisionLOOK.set(s.decision, look);\n\t\t\tg.tool.log(\"LL1\", \"LL(1)? \" + disjoint(look));\n\t\t}\n\t}",
        "AfterRefact": "protected void processParser() {\n\t\tg.decisionLOOK = new ArrayList<IntervalSet[]>(g.atn.getNumberOfDecisions()+1);\n\t\tfor (DecisionState s : g.atn.decisionToState) {\n            g.tool.log(\"LL1\", \"\\nDECISION \"+s.decision+\" in rule \"+g.getRule(s.ruleIndex).name);\n\t\t\tIntervalSet[] look;\n\t\t\tif ( s.nonGreedy ) { // nongreedy decisions can't be LL(1)\n\t\t\t\tlook = new IntervalSet[s.getNumberOfTransitions()+1];\n\t\t\t}\n\t\t\telse {\n\t\t\t\tLL1Analyzer anal = new LL1Analyzer(g.atn);\n\t\t\t\tlook = anal.getDecisionLookahead(s);\n\t\t\t\tg.tool.log(\"LL1\", \"look=\" + Arrays.toString(look));\n\t\t\t}\n\n\t\t\tassert s.decision + 1 >= g.decisionLOOK.size();\n\t\t\tUtils.setSize(g.decisionLOOK, s.decision+1);\n\t\t\tg.decisionLOOK.set(s.decision, look);\n\t\t\tg.tool.log(\"LL1\", \"LL(1)? \" + disjoint(look));\n\t\t}\n\t}",
        "Extra": ""
    },
    {
        "\ufeffID": "L10037",
        "Parent": "L10036",
        "commitID_before": "ad9bac95199736c270940c4037b7ee7174bacca6",
        "commitID_after": "3468a5fbd868ce63c4cb61782e9baddac2ed24ae",
        "Project": "https://github.com/antlr/antlr4",
        "Type": "INTRODUCE_ASSERTION",
        "Fowler_type": "Introduce Assertion",
        "path_before": "tool\\src\\org\\antlr\\v4\\codegen\\model\\LL1StarBlockSingleAlt.java",
        "path_after": "tool\\src\\org\\antlr\\v4\\codegen\\model\\LL1StarBlockSingleAlt.java",
        "name": "LL1StarBlockSingleAlt(OutputModelFactory factory, GrammarAST starRoot, List<CodeBlockForAlt> alts)",
        "LongName": "org.antlr.v4.codegen.model.LL1StarBlockSingleAlt.<init>(Lorg/antlr/v4/codegen/OutputModelFactory;Lorg/antlr/v4/tool/ast/GrammarAST;Ljava/util/List;)V",
        "b_StartLine": "",
        "b_StartColumn": "",
        "b_EndLine": "",
        "b_EndColumn": "",
        "a_StartLine": "42",
        "a_StartColumn": "2",
        "a_EndLine": "53",
        "a_EndColumn": "3",
        "BeforeRefact": "public LL1StarBlockSingleAlt(OutputModelFactory factory, GrammarAST starRoot, List<CodeBlockForAlt> alts) {\n\t\tsuper(factory, starRoot, alts);\n\n\t\tStarLoopEntryState star = (StarLoopEntryState)starRoot.atnState;\n\t\tloopBackStateNumber = star.loopBackState.stateNumber;\n\t\tthis.decision = star.decision;\n\t\tIntervalSet[] altLookSets = factory.getGrammar().decisionLOOK.get(decision);\n\t\tIntervalSet enterLook = altLookSets[1];\n\t\tIntervalSet exitLook = altLookSets[2];\n\t\tloopExpr = addCodeForLoopLookaheadTempVar(enterLook);\n\t}",
        "AfterRefact": "public LL1StarBlockSingleAlt(OutputModelFactory factory, GrammarAST starRoot, List<CodeBlockForAlt> alts) {\n\t\tsuper(factory, starRoot, alts);\n\n\t\tStarLoopEntryState star = (StarLoopEntryState)starRoot.atnState;\n\t\tloopBackStateNumber = star.loopBackState.stateNumber;\n\t\tthis.decision = star.decision;\n\t\tIntervalSet[] altLookSets = factory.getGrammar().decisionLOOK.get(decision);\n\t\tassert altLookSets.length == 2;\n\t\tIntervalSet enterLook = altLookSets[0];\n\t\tIntervalSet exitLook = altLookSets[1];\n\t\tloopExpr = addCodeForLoopLookaheadTempVar(enterLook);\n\t}",
        "Extra": ""
    },
    {
        "\ufeffID": "L1927",
        "Parent": "L1833",
        "commitID_before": "ad9bac95199736c270940c4037b7ee7174bacca6",
        "commitID_after": "3468a5fbd868ce63c4cb61782e9baddac2ed24ae",
        "Project": "https://github.com/antlr/antlr4",
        "Type": "EXTRACT_METHOD",
        "Fowler_type": "Extract Function",
        "path_before": "runtime\\Java\\src\\org\\antlr\\v4\\runtime\\atn\\LexerATNSimulator.java",
        "path_after": "runtime\\Java\\src\\org\\antlr\\v4\\runtime\\atn\\LexerATNSimulator.java",
        "name": "int execATN(@NotNull CharStream input, @NotNull DFAState ds0)",
        "LongName": "org.antlr.v4.runtime.atn.LexerATNSimulator. execATN(Lorg/antlr/v4/runtime/dfa/DFAState;I)Lorg/antlr/v4/runtime/dfa/DFAState;",
        "b_StartLine": "197",
        "b_StartColumn": "",
        "b_EndLine": "282",
        "b_EndColumn": "",
        "a_StartLine": "187",
        "a_StartColumn": "2",
        "a_EndLine": "302",
        "a_EndColumn": "3",
        "BeforeRefact": "protected int execATN(@NotNull CharStream input, @NotNull DFAState ds0) {\n\t\t//System.out.println(\"enter exec index \"+input.index()+\" from \"+ds0.configs);\n\t\tif ( debug ) {\n\t\t\tSystem.out.format(\"start state closure=%s\\n\", ds0.configs);\n\t\t}\n\n\t\tint t = input.LA(1);\n\t\t@NotNull\n\t\tDFAState s = ds0; // s is current/from DFA state\n\n\t\twhile ( true ) { // while more work\n\t\t\tif ( debug ) {\n\t\t\t\tSystem.out.format(\"execATN loop starting closure: %s\\n\", s.configs);\n\t\t\t}\n\n\t\t\t// As we move src->trg, src->trg, we keep track of the previous trg to\n\t\t\t// avoid looking up the DFA state again, which is expensive.\n\t\t\t// If the previous target was already part of the DFA, we might\n\t\t\t// be able to avoid doing a reach operation upon t. If s!=null,\n\t\t\t// it means that semantic predicates didn't prevent us from\n\t\t\t// creating a DFA state. Once we know s!=null, we check to see if\n\t\t\t// the DFA state has an edge already for t. If so, we can just reuse\n\t\t\t// it's configuration set; there's no point in re-computing it.\n\t\t\t// This is kind of like doing DFA simulation within the ATN\n\t\t\t// simulation because DFA simulation is really just a way to avoid\n\t\t\t// computing reach/closure sets. Technically, once we know that\n\t\t\t// we have a previously added DFA state, we could jump over to\n\t\t\t// the DFA simulator. But, that would mean popping back and forth\n\t\t\t// a lot and making things more complicated algorithmically.\n\t\t\t// This optimization makes a lot of sense for loops within DFA.\n\t\t\t// A character will take us back to an existing DFA state\n\t\t\t// that already has lots of edges out of it. e.g., .* in comments.\n\t\t\tATNConfigSet closure = s.configs;\n\t\t\tDFAState target = null;\n\t\t\tif ( s.edges != null && t >= MIN_DFA_EDGE && t <= MAX_DFA_EDGE ) {\n\t\t\t\ttarget = s.edges[t - MIN_DFA_EDGE];\n\t\t\t\tif (target == ERROR) {\n\t\t\t\t\tbreak;\n\t\t\t\t}\n\n\t\t\t\tif (debug && target != null) {\n\t\t\t\t\tSystem.out.println(\"reuse state \"+s.stateNumber+\n\t\t\t\t\t\t\t\t\t   \" edge to \"+target.stateNumber);\n\t\t\t\t}\n\t\t\t}\n\n\t\t\tif (target == null) {\n\t\t\t\tATNConfigSet reach = new OrderedATNConfigSet();\n\n\t\t\t\t// if we don't find an existing DFA state\n\t\t\t\t// Fill reach starting from closure, following t transitions\n\t\t\t\tgetReachableConfigSet(input, closure, reach, t);\n\n\t\t\t\tif ( reach.isEmpty() ) { // we got nowhere on t from s\n\t\t\t\t\t// we reached state associated with closure for sure, so\n\t\t\t\t\t// make sure it's defined. worst case, we define s0 from\n\t\t\t\t\t// start state configs.\n\t\t\t\t\t@NotNull\n\t\t\t\t\tDFAState from = s != null ? s : addDFAState(closure);\n\t\t\t\t\t// we got nowhere on t, don't throw out this knowledge; it'd\n\t\t\t\t\t// cause a failover from DFA later.\n\t\t\t\t\taddDFAEdge(from, t, ERROR);\n\t\t\t\t\tbreak; // stop when we can't match any more char\n\t\t\t\t}\n\n\t\t\t\t// Add an edge from s to target DFA found/created for reach\n\t\t\t\ttarget = addDFAEdge(s, t, reach);\n\t\t\t}\n\n\t\t\tif (target.isAcceptState) {\n\t\t\t\tcaptureSimState(prevAccept, input, target);\n\t\t\t\tif (t == IntStream.EOF) {\n\t\t\t\t\tbreak;\n\t\t\t\t}\n\t\t\t}\n\n\t\t\tif (t != IntStream.EOF) {\n\t\t\t\tconsume(input);\n\t\t\t\tt = input.LA(1);\n\t\t\t}\n\n\t\t\ts = target; // flip; current DFA target becomes new src/from state\n\t\t}\n\n\t\treturn failOrAccept(prevAccept, input, s.configs, t);\n\t}",
        "AfterRefact": "protected int execATN(@NotNull CharStream input, @NotNull DFAState ds0) {\n\t\t//System.out.println(\"enter exec index \"+input.index()+\" from \"+ds0.configs);\n\t\tif ( debug ) {\n\t\t\tSystem.out.format(Locale.getDefault(), \"start state closure=%s\\n\", ds0.configs);\n\t\t}\n\n\t\tint t = input.LA(1);\n\t\t@NotNull\n\t\tDFAState s = ds0; // s is current/from DFA state\n\n\t\twhile ( true ) { // while more work\n\t\t\tif ( debug ) {\n\t\t\t\tSystem.out.format(Locale.getDefault(), \"execATN loop starting closure: %s\\n\", s.configs);\n\t\t\t}\n\n\t\t\t// As we move src->trg, src->trg, we keep track of the previous trg to\n\t\t\t// avoid looking up the DFA state again, which is expensive.\n\t\t\t// If the previous target was already part of the DFA, we might\n\t\t\t// be able to avoid doing a reach operation upon t. If s!=null,\n\t\t\t// it means that semantic predicates didn't prevent us from\n\t\t\t// creating a DFA state. Once we know s!=null, we check to see if\n\t\t\t// the DFA state has an edge already for t. If so, we can just reuse\n\t\t\t// it's configuration set; there's no point in re-computing it.\n\t\t\t// This is kind of like doing DFA simulation within the ATN\n\t\t\t// simulation because DFA simulation is really just a way to avoid\n\t\t\t// computing reach/closure sets. Technically, once we know that\n\t\t\t// we have a previously added DFA state, we could jump over to\n\t\t\t// the DFA simulator. But, that would mean popping back and forth\n\t\t\t// a lot and making things more complicated algorithmically.\n\t\t\t// This optimization makes a lot of sense for loops within DFA.\n\t\t\t// A character will take us back to an existing DFA state\n\t\t\t// that already has lots of edges out of it. e.g., .* in comments.\n\t\t\tDFAState target = getExistingTargetState(s, t);\n\t\t\tif (target == null) {\n\t\t\t\ttarget = computeTargetState(input, s, t);\n\t\t\t}\n\n\t\t\tif (target == ERROR) {\n\t\t\t\tbreak;\n\t\t\t}\n\n\t\t\tif (target.isAcceptState) {\n\t\t\t\tcaptureSimState(prevAccept, input, target);\n\t\t\t\tif (t == IntStream.EOF) {\n\t\t\t\t\tbreak;\n\t\t\t\t}\n\t\t\t}\n\n\t\t\tif (t != IntStream.EOF) {\n\t\t\t\tconsume(input);\n\t\t\t\tt = input.LA(1);\n\t\t\t}\n\n\t\t\ts = target; // flip; current DFA target becomes new src/from state\n\t\t}\n\n\t\treturn failOrAccept(prevAccept, input, s.configs, t);\n\t}\n\n\t/**\n\t * Get an existing target state for an edge in the DFA. If the target state\n\t * for the edge has not yet been computed or is otherwise not available,\n\t * this method returns {@code null}.\n\t *\n\t * @param s The current DFA state\n\t * @param t The next input symbol\n\t * @return The existing target DFA state for the given input symbol\n\t * {@code t}, or {@code null} if the target state for this edge is not\n\t * already cached\n\t */\n\t@Nullable\n\tprotected DFAState getExistingTargetState(@NotNull DFAState s, int t) {\n\t\tif (s.edges == null || t < MIN_DFA_EDGE || t > MAX_DFA_EDGE) {\n\t\t\treturn null;\n\t\t}\n\t\t\n\t\tDFAState target = s.edges[t - MIN_DFA_EDGE];\n\t\tif (debug && target != null) {\n\t\t\tSystem.out.println(\"reuse state \"+s.stateNumber+\n\t\t\t\t\t\t\t   \" edge to \"+target.stateNumber);\n\t\t}\n\n\t\treturn target;\n\t}\n\n\t/**\n\t * Compute a target state for an edge in the DFA, and attempt to add the\n\t * computed state and corresponding edge to the DFA.\n\t *\n\t * @param input The input stream\n\t * @param s The current DFA state\n\t * @param t The next input symbol\n\t *\n\t * @return The computed target DFA state for the given input symbol\n\t * {@code t}. If {@code t} does not lead to a valid DFA state, this method\n\t * returns {@link #ERROR}.\n\t */\n\t@NotNull\n\tprotected DFAState computeTargetState(@NotNull CharStream input, @NotNull DFAState s, int t) {\n\t\tATNConfigSet reach = new OrderedATNConfigSet();\n\n\t\t// if we don't find an existing DFA state\n\t\t// Fill reach starting from closure, following t transitions\n\t\tgetReachableConfigSet(input, s.configs, reach, t);\n\n\t\tif ( reach.isEmpty() ) { // we got nowhere on t from s\n\t\t\t// we got nowhere on t, don't throw out this knowledge; it'd\n\t\t\t// cause a failover from DFA later.\n\t\t\taddDFAEdge(s, t, ERROR);\n\t\t\t// stop when we can't match any more char\n\t\t\treturn ERROR;\n\t\t}\n\n\t\t// Add an edge from s to target DFA found/created for reach\n\t\treturn addDFAEdge(s, t, reach);\n\t}",
        "Extra": ""
    },
    {
        "\ufeffID": "L540",
        "Parent": "L515",
        "commitID_before": "ad9bac95199736c270940c4037b7ee7174bacca6",
        "commitID_after": "3468a5fbd868ce63c4cb61782e9baddac2ed24ae",
        "Project": "https://github.com/antlr/antlr4",
        "Type": "ADD_PARAMETER",
        "Fowler_type": "Change Function Declaration",
        "path_before": "runtime\\Java\\src\\org\\antlr\\v4\\runtime\\ANTLRErrorListener.java",
        "path_after": "runtime\\Java\\src\\org\\antlr\\v4\\runtime\\ANTLRErrorListener.java",
        "name": "void reportAmbiguity(Parser recognizer, DFA dfa, int startIndex, int stopIndex, boolean exact, BitSet ambigAlts, ATNConfigSet configs)",
        "LongName": "org.antlr.v4.runtime.ANTLRErrorListener.reportAmbiguity(Lorg/antlr/v4/runtime/Parser;Lorg/antlr/v4/runtime/dfa/DFA;IIZLjava/util/BitSet;Lorg/antlr/v4/runtime/atn/ATNConfigSet;)V",
        "b_StartLine": "92",
        "b_StartColumn": "",
        "b_EndLine": "95",
        "b_EndColumn": "",
        "a_StartLine": "112",
        "a_StartColumn": "2",
        "a_EndLine": "118",
        "a_EndColumn": "39",
        "BeforeRefact": "void reportAmbiguity(@NotNull Parser recognizer,\n\t\t\t\t\t\t DFA dfa, int startIndex, int stopIndex,\n\t\t\t\t\t\t @NotNull BitSet ambigAlts,\n\t\t\t\t\t\t @NotNull ATNConfigSet configs);",
        "AfterRefact": "void reportAmbiguity(@NotNull Parser recognizer,\n\t\t\t\t\t\t @NotNull DFA dfa,\n\t\t\t\t\t\t int startIndex,\n\t\t\t\t\t\t int stopIndex,\n\t\t\t\t\t\t boolean exact,\n\t\t\t\t\t\t @NotNull BitSet ambigAlts,\n\t\t\t\t\t\t @NotNull ATNConfigSet configs);",
        "Extra": ""
    },
    {
        "\ufeffID": "L561",
        "Parent": "L515",
        "commitID_before": "ad9bac95199736c270940c4037b7ee7174bacca6",
        "commitID_after": "3468a5fbd868ce63c4cb61782e9baddac2ed24ae",
        "Project": "https://github.com/antlr/antlr4",
        "Type": "ADD_PARAMETER",
        "Fowler_type": "Change Function Declaration",
        "path_before": "runtime\\Java\\src\\org\\antlr\\v4\\runtime\\ANTLRErrorListener.java",
        "path_after": "runtime\\Java\\src\\org\\antlr\\v4\\runtime\\ANTLRErrorListener.java",
        "name": "void reportAttemptingFullContext(Parser recognizer, DFA dfa, int startIndex, int stopIndex, BitSet conflictingAlts, ATNConfigSet configs)",
        "LongName": "org.antlr.v4.runtime.ANTLRErrorListener.reportAttemptingFullContext(Lorg/antlr/v4/runtime/Parser;Lorg/antlr/v4/runtime/dfa/DFA;IILjava/util/BitSet;Lorg/antlr/v4/runtime/atn/ATNConfigSet;)V",
        "b_StartLine": "97",
        "b_StartColumn": "",
        "b_EndLine": "100",
        "b_EndColumn": "",
        "a_StartLine": "141",
        "a_StartColumn": "2",
        "a_EndLine": "146",
        "a_EndColumn": "42",
        "BeforeRefact": "void reportAttemptingFullContext(@NotNull Parser recognizer,\n\t\t\t\t\t\t\t\t\t @NotNull DFA dfa,\n\t\t\t\t\t\t\t\t\t int startIndex, int stopIndex,\n\t\t\t\t\t\t\t\t\t @NotNull ATNConfigSet configs);",
        "AfterRefact": "void reportAttemptingFullContext(@NotNull Parser recognizer,\n\t\t\t\t\t\t\t\t\t @NotNull DFA dfa,\n\t\t\t\t\t\t\t\t\t int startIndex,\n\t\t\t\t\t\t\t\t\t int stopIndex,\n\t\t\t\t\t\t\t\t\t @Nullable BitSet conflictingAlts,\n\t\t\t\t\t\t\t\t\t @NotNull ATNConfigSet configs);",
        "Extra": ""
    },
    {
        "\ufeffID": "L5431",
        "Parent": "L543",
        "commitID_before": "ad9bac95199736c270940c4037b7ee7174bacca6",
        "commitID_after": "3468a5fbd868ce63c4cb61782e9baddac2ed24ae",
        "Project": "https://github.com/antlr/antlr4",
        "Type": "CONSOLIDATE_COND_EXPRESSION",
        "Fowler_type": "Consolidate Conditional Expression",
        "path_before": "runtime\\Java\\src\\org\\antlr\\v4\\runtime\\Parser.java",
        "path_after": "runtime\\Java\\src\\org\\antlr\\v4\\runtime\\Parser.java",
        "name": "void unrollRecursionContexts(ParserRuleContext _parentctx)",
        "LongName": "org.antlr.v4.runtime.Parser.unrollRecursionContexts(Lorg/antlr/v4/runtime/ParserRuleContext;)V",
        "b_StartLine": "481",
        "b_StartColumn": "2",
        "b_EndLine": "498",
        "b_EndColumn": "3",
        "a_StartLine": "593",
        "a_StartColumn": "2",
        "a_EndLine": "615",
        "a_EndColumn": "3",
        "BeforeRefact": "public void unrollRecursionContexts(ParserRuleContext _parentctx) {\n\t\t_ctx.stop = _input.LT(-1);\n\t\tParserRuleContext retctx = _ctx; // save current ctx (return value)\n\n\t\t// unroll so _ctx is as it was before call to recursive method\n\t\tif ( _parseListeners != null ) {\n\t\t\twhile ( _ctx != _parentctx ) {\n\t\t\t\ttriggerExitRuleEvent();\n\t\t\t\t_ctx = (ParserRuleContext)_ctx.parent;\n\t\t\t}\n\t\t}\n\t\telse {\n\t\t\t_ctx = _parentctx;\n\t\t}\n\t\t// hook into tree\n\t\tretctx.parent = _parentctx;\n\t\tif (_buildParseTrees) _parentctx.addChild(retctx); // add return ctx into invoking rule's tree\n\t}",
        "AfterRefact": "public void unrollRecursionContexts(ParserRuleContext _parentctx) {\n\t\t_ctx.stop = _input.LT(-1);\n\t\tParserRuleContext retctx = _ctx; // save current ctx (return value)\n\n\t\t// unroll so _ctx is as it was before call to recursive method\n\t\tif ( _parseListeners != null ) {\n\t\t\twhile ( _ctx != _parentctx ) {\n\t\t\t\ttriggerExitRuleEvent();\n\t\t\t\t_ctx = (ParserRuleContext)_ctx.parent;\n\t\t\t}\n\t\t}\n\t\telse {\n\t\t\t_ctx = _parentctx;\n\t\t}\n\n\t\t// hook into tree\n\t\tretctx.parent = _parentctx;\n\n\t\tif (_buildParseTrees && _parentctx != null) {\n\t\t\t// add return ctx into invoking rule's tree\n\t\t\t_parentctx.addChild(retctx);\n\t\t}\n\t}",
        "Extra": ""
    },
    {
        "\ufeffID": "L3844",
        "Parent": "L3806",
        "commitID_before": "5e05b71e8b1cd52cf0e77559786cc4c18dc85c37",
        "commitID_after": "90a5aa469a09a9296fe3b9a25b37ed8ebd3d627f",
        "Project": "https://github.com/antlr/antlr4",
        "Type": "CONSOLIDATE_COND_EXPRESSION",
        "Fowler_type": "Consolidate Conditional Expression",
        "path_before": "runtime\\Java\\src\\org\\antlr\\v4\\runtime\\BufferedTokenStream.java",
        "path_after": "runtime\\Java\\src\\org\\antlr\\v4\\runtime\\BufferedTokenStream.java",
        "name": "void consume()",
        "LongName": "org.antlr.v4.runtime.BufferedTokenStream.consume()V",
        "b_StartLine": "132",
        "b_StartColumn": "2",
        "b_EndLine": "157",
        "b_EndColumn": "3",
        "a_StartLine": "132",
        "a_StartColumn": "5",
        "a_EndLine": "157",
        "a_EndColumn": "6",
        "BeforeRefact": "public void consume() {\n\t\tboolean skipEofCheck;\n\t\tif (p >= 0) {\n\t\t\tif (fetchedEOF) {\n\t\t\t\t// the last token in tokens is EOF. skip check if p indexes any\n\t\t\t\t// fetched token except the last.\n\t\t\t\tskipEofCheck = p < tokens.size() - 1;\n\t\t\t}\n\t\t\telse {\n\t\t\t\t// no EOF token in tokens. skip check if p indexes a fetched token.\n\t\t\t\tskipEofCheck = p < tokens.size();\n\t\t\t}\n\t\t}\n\t\telse {\n\t\t\t// not yet initialized\n\t\t\tskipEofCheck = false;\n\t\t}\n\n\t\tif (!skipEofCheck && LA(1) == EOF) {\n\t\t\tthrow new IllegalStateException(\"cannot consume EOF\");\n\t\t}\n\n\t\tif (sync(p + 1)) {\n\t\t\tp = adjustSeekIndex(p + 1);\n\t\t}\n    }",
        "AfterRefact": " public void consume() {\n\t\tboolean skipEofCheck;\n\t\tif (p >= 0) {\n\t\t\tif (fetchedEOF) {\n\t\t\t\t// the last token in tokens is EOF. skip check if p indexes any\n\t\t\t\t// fetched token except the last.\n\t\t\t\tskipEofCheck = p < tokens.size() - 1;\n\t\t\t}\n\t\t\telse {\n\t\t\t\t// no EOF token in tokens. skip check if p indexes a fetched token.\n\t\t\t\tskipEofCheck = p < tokens.size();\n\t\t\t}\n\t\t}\n\t\telse {\n\t\t\t// not yet initialized\n\t\t\tskipEofCheck = false;\n\t\t}\n\n\t\tif (!skipEofCheck && LA(1) == EOF) {\n\t\t\tthrow new IllegalStateException(\"cannot consume EOF\");\n\t\t}\n\n\t\tif (sync(p + 1)) {\n\t\t\tp = adjustSeekIndex(p + 1);\n\t\t}\n    }",
        "Extra": ""
    },
    {
        "\ufeffID": "L3168",
        "Parent": "L3038",
        "commitID_before": "5e05b71e8b1cd52cf0e77559786cc4c18dc85c37",
        "commitID_after": "90a5aa469a09a9296fe3b9a25b37ed8ebd3d627f",
        "Project": "https://github.com/antlr/antlr4",
        "Type": "CONSOLIDATE_COND_EXPRESSION",
        "Fowler_type": "Consolidate Conditional Expression",
        "path_before": "runtime\\Java\\src\\org\\antlr\\v4\\runtime\\atn\\ParserATNSimulator.java",
        "path_after": "runtime\\Java\\src\\org\\antlr\\v4\\runtime\\atn\\ParserATNSimulator.java",
        "name": "ATNConfigSet computeReachSet(ATNConfigSet closure, int t, boolean fullCtx)",
        "LongName": "org.antlr.v4.runtime.atn.ParserATNSimulator.computeReachSet(Lorg/antlr/v4/runtime/atn/ATNConfigSet;IZ)Lorg/antlr/v4/runtime/atn/ATNConfigSet;",
        "b_StartLine": "785",
        "b_StartColumn": "2",
        "b_EndLine": "912",
        "b_EndColumn": "3",
        "a_StartLine": "798",
        "a_StartColumn": "2",
        "a_EndLine": "926",
        "a_EndColumn": "3",
        "BeforeRefact": "protected ATNConfigSet computeReachSet(ATNConfigSet closure, int t,\n\t\t\t\t\t\t\t\t\t\t   boolean fullCtx)\n\t{\n\t\tif ( debug ) System.out.println(\"in computeReachSet, starting closure: \" + closure);\n\n\t\tif (mergeCache == null) {\n\t\t\tmergeCache = new DoubleKeyMap<PredictionContext, PredictionContext, PredictionContext>();\n\t\t}\n\n\t\tATNConfigSet intermediate = new ATNConfigSet(fullCtx);\n\n\t\t/* Configurations already in a rule stop state indicate reaching the end\n\t\t * of the decision rule (local context) or end of the start rule (full\n\t\t * context). Once reached, these configurations are never updated by a\n\t\t * closure operation, so they are handled separately for the performance\n\t\t * advantage of having a smaller intermediate set when calling closure.\n\t\t *\n\t\t * For full-context reach operations, separate handling is required to\n\t\t * ensure that the alternative matching the longest overall sequence is\n\t\t * chosen when multiple such configurations can match the input.\n\t\t */\n\t\tList<ATNConfig> skippedStopStates = null;\n\n\t\t// First figure out where we can reach on input t\n\t\tfor (ATNConfig c : closure) {\n\t\t\tif ( debug ) System.out.println(\"testing \"+getTokenName(t)+\" at \"+c.toString());\n\n\t\t\tif (c.state instanceof RuleStopState) {\n\t\t\t\tassert c.context.isEmpty();\n\t\t\t\tif (fullCtx || t == IntStream.EOF) {\n\t\t\t\t\tif (skippedStopStates == null) {\n\t\t\t\t\t\tskippedStopStates = new ArrayList<ATNConfig>();\n\t\t\t\t\t}\n\n\t\t\t\t\tskippedStopStates.add(c);\n\t\t\t\t}\n\n\t\t\t\tcontinue;\n\t\t\t}\n\n\t\t\tint n = c.state.getNumberOfTransitions();\n\t\t\tfor (int ti=0; ti<n; ti++) {               // for each transition\n\t\t\t\tTransition trans = c.state.transition(ti);\n\t\t\t\tATNState target = getReachableTarget(trans, t);\n\t\t\t\tif ( target!=null ) {\n\t\t\t\t\tintermediate.add(new ATNConfig(c, target), mergeCache);\n\t\t\t\t}\n\t\t\t}\n\t\t}\n\n\t\t// Now figure out where the reach operation can take us...\n\n\t\tATNConfigSet reach = null;\n\n\t\t/* This block optimizes the reach operation for intermediate sets which\n\t\t * trivially indicate a termination state for the overall\n\t\t * adaptivePredict operation.\n\t\t *\n\t\t * The conditions assume that intermediate\n\t\t * contains all configurations relevant to the reach set, but this\n\t\t * condition is not true when one or more configurations have been\n\t\t * withheld in skippedStopStates.\n\t\t */\n\t\tif (skippedStopStates == null) {\n\t\t\tif ( intermediate.size()==1 ) {\n\t\t\t\t// Don't pursue the closure if there is just one state.\n\t\t\t\t// It can only have one alternative; just add to result\n\t\t\t\t// Also don't pursue the closure if there is unique alternative\n\t\t\t\t// among the configurations.\n\t\t\t\treach = intermediate;\n\t\t\t}\n\t\t\telse if ( getUniqueAlt(intermediate)!=ATN.INVALID_ALT_NUMBER ) {\n\t\t\t\t// Also don't pursue the closure if there is unique alternative\n\t\t\t\t// among the configurations.\n\t\t\t\treach = intermediate;\n\t\t\t}\n\t\t}\n\n\t\t/* If the reach set could not be trivially determined, perform a closure\n\t\t * operation on the intermediate set to compute its initial value.\n\t\t */\n\t\tif (reach == null) {\n\t\t\treach = new ATNConfigSet(fullCtx);\n\t\t\tSet<ATNConfig> closureBusy = new HashSet<ATNConfig>();\n\t\t\tfor (ATNConfig c : intermediate) {\n\t\t\t\tclosure(c, reach, closureBusy, false, fullCtx);\n\t\t\t}\n\t\t}\n\n\t\tif (t == IntStream.EOF) {\n\t\t\t/* After consuming EOF no additional input is possible, so we are\n\t\t\t * only interested in configurations which reached the end of the\n\t\t\t * decision rule (local context) or end of the start rule (full\n\t\t\t * context). Update reach to contain only these configurations. This\n\t\t\t * handles both explicit EOF transitions in the grammar and implicit\n\t\t\t * EOF transitions following the end of the decision or start rule.\n\t\t\t *\n\t\t\t * When reach==intermediate, no closure operation was performed. In\n\t\t\t * this case, removeAllConfigsNotInRuleStopState needs to check for\n\t\t\t * reachable rule stop states as well as configurations already in\n\t\t\t * a rule stop state.\n\t\t\t *\n\t\t\t * This is handled before the configurations in skippedStopStates,\n\t\t\t * because any configurations potentially added from that list are\n\t\t\t * already guaranteed to meet this condition whether or not it's\n\t\t\t * required.\n\t\t\t */\n\t\t\treach = removeAllConfigsNotInRuleStopState(reach, reach == intermediate);\n\t\t}\n\n\t\t/* If skippedStopStates is not null, then it contains at least one\n\t\t * configuration. For full-context reach operations, these\n\t\t * configurations reached the end of the start rule, in which case we\n\t\t * only add them back to reach if no configuration during the current\n\t\t * closure operation reached such a state. This ensures adaptivePredict\n\t\t * chooses an alternative matching the longest overall sequence when\n\t\t * multiple alternatives are viable.\n\t\t */\n\t\tif (skippedStopStates != null && (!fullCtx || !PredictionMode.hasConfigInRuleStopState(reach))) {\n\t\t\tassert !skippedStopStates.isEmpty();\n\t\t\tfor (ATNConfig c : skippedStopStates) {\n\t\t\t\treach.add(c, mergeCache);\n\t\t\t}\n\t\t}\n\n\t\tif ( reach.isEmpty() ) return null;\n\t\treturn reach;\n\t}",
        "AfterRefact": "protected ATNConfigSet computeReachSet(ATNConfigSet closure, int t,\n\t\t\t\t\t\t\t\t\t\t   boolean fullCtx)\n\t{\n\t\tif ( debug ) System.out.println(\"in computeReachSet, starting closure: \" + closure);\n\n\t\tif (mergeCache == null) {\n\t\t\tmergeCache = new DoubleKeyMap<PredictionContext, PredictionContext, PredictionContext>();\n\t\t}\n\n\t\tATNConfigSet intermediate = new ATNConfigSet(fullCtx);\n\n\t\t/* Configurations already in a rule stop state indicate reaching the end\n\t\t * of the decision rule (local context) or end of the start rule (full\n\t\t * context). Once reached, these configurations are never updated by a\n\t\t * closure operation, so they are handled separately for the performance\n\t\t * advantage of having a smaller intermediate set when calling closure.\n\t\t *\n\t\t * For full-context reach operations, separate handling is required to\n\t\t * ensure that the alternative matching the longest overall sequence is\n\t\t * chosen when multiple such configurations can match the input.\n\t\t */\n\t\tList<ATNConfig> skippedStopStates = null;\n\n\t\t// First figure out where we can reach on input t\n\t\tfor (ATNConfig c : closure) {\n\t\t\tif ( debug ) System.out.println(\"testing \"+getTokenName(t)+\" at \"+c.toString());\n\n\t\t\tif (c.state instanceof RuleStopState) {\n\t\t\t\tassert c.context.isEmpty();\n\t\t\t\tif (fullCtx || t == IntStream.EOF) {\n\t\t\t\t\tif (skippedStopStates == null) {\n\t\t\t\t\t\tskippedStopStates = new ArrayList<ATNConfig>();\n\t\t\t\t\t}\n\n\t\t\t\t\tskippedStopStates.add(c);\n\t\t\t\t}\n\n\t\t\t\tcontinue;\n\t\t\t}\n\n\t\t\tint n = c.state.getNumberOfTransitions();\n\t\t\tfor (int ti=0; ti<n; ti++) {               // for each transition\n\t\t\t\tTransition trans = c.state.transition(ti);\n\t\t\t\tATNState target = getReachableTarget(trans, t);\n\t\t\t\tif ( target!=null ) {\n\t\t\t\t\tintermediate.add(new ATNConfig(c, target), mergeCache);\n\t\t\t\t}\n\t\t\t}\n\t\t}\n\n\t\t// Now figure out where the reach operation can take us...\n\n\t\tATNConfigSet reach = null;\n\n\t\t/* This block optimizes the reach operation for intermediate sets which\n\t\t * trivially indicate a termination state for the overall\n\t\t * adaptivePredict operation.\n\t\t *\n\t\t * The conditions assume that intermediate\n\t\t * contains all configurations relevant to the reach set, but this\n\t\t * condition is not true when one or more configurations have been\n\t\t * withheld in skippedStopStates, or when the current symbol is EOF.\n\t\t */\n\t\tif (skippedStopStates == null && t != Token.EOF) {\n\t\t\tif ( intermediate.size()==1 ) {\n\t\t\t\t// Don't pursue the closure if there is just one state.\n\t\t\t\t// It can only have one alternative; just add to result\n\t\t\t\t// Also don't pursue the closure if there is unique alternative\n\t\t\t\t// among the configurations.\n\t\t\t\treach = intermediate;\n\t\t\t}\n\t\t\telse if ( getUniqueAlt(intermediate)!=ATN.INVALID_ALT_NUMBER ) {\n\t\t\t\t// Also don't pursue the closure if there is unique alternative\n\t\t\t\t// among the configurations.\n\t\t\t\treach = intermediate;\n\t\t\t}\n\t\t}\n\n\t\t/* If the reach set could not be trivially determined, perform a closure\n\t\t * operation on the intermediate set to compute its initial value.\n\t\t */\n\t\tif (reach == null) {\n\t\t\treach = new ATNConfigSet(fullCtx);\n\t\t\tSet<ATNConfig> closureBusy = new HashSet<ATNConfig>();\n\t\t\tboolean treatEofAsEpsilon = t == Token.EOF;\n\t\t\tfor (ATNConfig c : intermediate) {\n\t\t\t\tclosure(c, reach, closureBusy, false, fullCtx, treatEofAsEpsilon);\n\t\t\t}\n\t\t}\n\n\t\tif (t == IntStream.EOF) {\n\t\t\t/* After consuming EOF no additional input is possible, so we are\n\t\t\t * only interested in configurations which reached the end of the\n\t\t\t * decision rule (local context) or end of the start rule (full\n\t\t\t * context). Update reach to contain only these configurations. This\n\t\t\t * handles both explicit EOF transitions in the grammar and implicit\n\t\t\t * EOF transitions following the end of the decision or start rule.\n\t\t\t *\n\t\t\t * When reach==intermediate, no closure operation was performed. In\n\t\t\t * this case, removeAllConfigsNotInRuleStopState needs to check for\n\t\t\t * reachable rule stop states as well as configurations already in\n\t\t\t * a rule stop state.\n\t\t\t *\n\t\t\t * This is handled before the configurations in skippedStopStates,\n\t\t\t * because any configurations potentially added from that list are\n\t\t\t * already guaranteed to meet this condition whether or not it's\n\t\t\t * required.\n\t\t\t */\n\t\t\treach = removeAllConfigsNotInRuleStopState(reach, reach == intermediate);\n\t\t}\n\n\t\t/* If skippedStopStates is not null, then it contains at least one\n\t\t * configuration. For full-context reach operations, these\n\t\t * configurations reached the end of the start rule, in which case we\n\t\t * only add them back to reach if no configuration during the current\n\t\t * closure operation reached such a state. This ensures adaptivePredict\n\t\t * chooses an alternative matching the longest overall sequence when\n\t\t * multiple alternatives are viable.\n\t\t */\n\t\tif (skippedStopStates != null && (!fullCtx || !PredictionMode.hasConfigInRuleStopState(reach))) {\n\t\t\tassert !skippedStopStates.isEmpty();\n\t\t\tfor (ATNConfig c : skippedStopStates) {\n\t\t\t\treach.add(c, mergeCache);\n\t\t\t}\n\t\t}\n\n\t\tif ( reach.isEmpty() ) return null;\n\t\treturn reach;\n\t}",
        "Extra": ""
    },
    {
        "\ufeffID": "L10263",
        "Parent": "L10252",
        "commitID_before": "5e05b71e8b1cd52cf0e77559786cc4c18dc85c37",
        "commitID_after": "90a5aa469a09a9296fe3b9a25b37ed8ebd3d627f",
        "Project": "https://github.com/antlr/antlr4",
        "Type": "CONSOLIDATE_DUPLICATE_COND_FRAGMENTS",
        "Fowler_type": "Slide Statements",
        "path_before": "tool\\src\\org\\antlr\\v4\\automata\\ATNPrinter.java",
        "path_after": "tool\\src\\org\\antlr\\v4\\automata\\ATNPrinter.java",
        "name": "String asString()",
        "LongName": "org.antlr.v4.automata.ATNPrinter.asString()Ljava/lang/String;",
        "b_StartLine": "69",
        "b_StartColumn": "2",
        "b_EndLine": "123",
        "b_EndColumn": "3",
        "a_StartLine": "69",
        "a_StartColumn": "2",
        "a_EndLine": "123",
        "a_EndColumn": "3",
        "BeforeRefact": "public String asString() {\n\t\tif ( start==null ) return null;\n\t\tmarked = new HashSet<ATNState>();\n\n\t\twork = new ArrayList<ATNState>();\n\t\twork.add(start);\n\n\t\tStringBuilder buf = new StringBuilder();\n\t\tATNState s;\n\n\t\twhile ( !work.isEmpty() ) {\n\t\t\ts = work.remove(0);\n\t\t\tif ( marked.contains(s) ) continue;\n\t\t\tint n = s.getNumberOfTransitions();\n//\t\t\tSystem.out.println(\"visit \"+s+\"; edges=\"+n);\n\t\t\tmarked.add(s);\n\t\t\tfor (int i=0; i<n; i++) {\n\t\t\t\tTransition t = s.transition(i);\n\t\t\t\tif ( !(s instanceof RuleStopState) ) { // don't add follow states to work\n\t\t\t\t\tif ( t instanceof RuleTransition ) work.add(((RuleTransition)t).followState);\n\t\t\t\t\telse work.add( t.target );\n\t\t\t\t}\n\t\t\t\tbuf.append(getStateString(s));\n\t\t\t\tif ( t instanceof EpsilonTransition ) {\n\t\t\t\t\tbuf.append(\"->\").append(getStateString(t.target)).append('\\n');\n\t\t\t\t}\n\t\t\t\telse if ( t instanceof RuleTransition ) {\n\t\t\t\t\tbuf.append(\"-\").append(g.getRule(((RuleTransition)t).ruleIndex).name).append(\"->\").append(getStateString(t.target)).append('\\n');\n\t\t\t\t}\n\t\t\t\telse if ( t instanceof ActionTransition ) {\n\t\t\t\t\tActionTransition a = (ActionTransition)t;\n\t\t\t\t\tbuf.append(\"-\").append(a.toString()).append(\"->\").append(getStateString(t.target)).append('\\n');\n\t\t\t\t}\n\t\t\t\telse if ( t instanceof SetTransition ) {\n\t\t\t\t\tSetTransition st = (SetTransition)t;\n\t\t\t\t\tboolean not = st instanceof NotSetTransition;\n\t\t\t\t\tif ( g.isLexer() ) {\n\t\t\t\t\t\tbuf.append(\"-\").append(not?\"~\":\"\").append(st.toString()).append(\"->\").append(getStateString(t.target)).append('\\n');\n\t\t\t\t\t}\n\t\t\t\t\telse {\n\t\t\t\t\t\tbuf.append(\"-\").append(not?\"~\":\"\").append(st.label().toString(g.getTokenNames())).append(\"->\").append(getStateString(t.target)).append('\\n');\n\t\t\t\t\t}\n\t\t\t\t}\n\t\t\t\telse if ( t instanceof AtomTransition ) {\n\t\t\t\t\tAtomTransition a = (AtomTransition)t;\n\t\t\t\t\tString label = g.getTokenDisplayName(a.label);\n\t\t\t\t\tbuf.append(\"-\").append(label).append(\"->\").append(getStateString(t.target)).append('\\n');\n\t\t\t\t}\n\t\t\t\telse {\n\t\t\t\t\tbuf.append(\"-\").append(t.toString()).append(\"->\").append(getStateString(t.target)).append('\\n');\n\t\t\t\t}\n\t\t\t}\n\t\t}\n\t\treturn buf.toString();\n\t}",
        "AfterRefact": "public String asString() {\n\t\tif ( start==null ) return null;\n\t\tmarked = new HashSet<ATNState>();\n\n\t\twork = new ArrayList<ATNState>();\n\t\twork.add(start);\n\n\t\tStringBuilder buf = new StringBuilder();\n\t\tATNState s;\n\n\t\twhile ( !work.isEmpty() ) {\n\t\t\ts = work.remove(0);\n\t\t\tif ( marked.contains(s) ) continue;\n\t\t\tint n = s.getNumberOfTransitions();\n//\t\t\tSystem.out.println(\"visit \"+s+\"; edges=\"+n);\n\t\t\tmarked.add(s);\n\t\t\tfor (int i=0; i<n; i++) {\n\t\t\t\tTransition t = s.transition(i);\n\t\t\t\tif ( !(s instanceof RuleStopState) ) { // don't add follow states to work\n\t\t\t\t\tif ( t instanceof RuleTransition ) work.add(((RuleTransition)t).followState);\n\t\t\t\t\telse work.add( t.target );\n\t\t\t\t}\n\t\t\t\tbuf.append(getStateString(s));\n\t\t\t\tif ( t instanceof EpsilonTransition ) {\n\t\t\t\t\tbuf.append(\"->\").append(getStateString(t.target)).append('\\n');\n\t\t\t\t}\n\t\t\t\telse if ( t instanceof RuleTransition ) {\n\t\t\t\t\tbuf.append(\"-\").append(g.getRule(((RuleTransition)t).ruleIndex).name).append(\"->\").append(getStateString(t.target)).append('\\n');\n\t\t\t\t}\n\t\t\t\telse if ( t instanceof ActionTransition ) {\n\t\t\t\t\tActionTransition a = (ActionTransition)t;\n\t\t\t\t\tbuf.append(\"-\").append(a.toString()).append(\"->\").append(getStateString(t.target)).append('\\n');\n\t\t\t\t}\n\t\t\t\telse if ( t instanceof SetTransition ) {\n\t\t\t\t\tSetTransition st = (SetTransition)t;\n\t\t\t\t\tboolean not = st instanceof NotSetTransition;\n\t\t\t\t\tif ( g.isLexer() ) {\n\t\t\t\t\t\tbuf.append(\"-\").append(not?\"~\":\"\").append(st.toString()).append(\"->\").append(getStateString(t.target)).append('\\n');\n\t\t\t\t\t}\n\t\t\t\t\telse {\n\t\t\t\t\t\tbuf.append(\"-\").append(not?\"~\":\"\").append(st.label().toString(g.getTokenDisplayNames())).append(\"->\").append(getStateString(t.target)).append('\\n');\n\t\t\t\t\t}\n\t\t\t\t}\n\t\t\t\telse if ( t instanceof AtomTransition ) {\n\t\t\t\t\tAtomTransition a = (AtomTransition)t;\n\t\t\t\t\tString label = g.getTokenDisplayName(a.label);\n\t\t\t\t\tbuf.append(\"-\").append(label).append(\"->\").append(getStateString(t.target)).append('\\n');\n\t\t\t\t}\n\t\t\t\telse {\n\t\t\t\t\tbuf.append(\"-\").append(t.toString()).append(\"->\").append(getStateString(t.target)).append('\\n');\n\t\t\t\t}\n\t\t\t}\n\t\t}\n\t\treturn buf.toString();\n\t}",
        "Extra": ""
    },
    {
        "\ufeffID": "L102630",
        "Parent": "L10252",
        "commitID_before": "5e05b71e8b1cd52cf0e77559786cc4c18dc85c37",
        "commitID_after": "90a5aa469a09a9296fe3b9a25b37ed8ebd3d627f",
        "Project": "https://github.com/antlr/antlr4",
        "Type": "CONSOLIDATE_DUPLICATE_COND_FRAGMENTS",
        "Fowler_type": "Slide Statements",
        "path_before": "tool\\src\\org\\antlr\\v4\\automata\\ATNPrinter.java",
        "path_after": "tool\\src\\org\\antlr\\v4\\automata\\ATNPrinter.java",
        "name": "String getStateString(ATNState s)",
        "LongName": "org.antlr.v4.automata.ATNPrinter.getStateString()Ljava/lang/String;",
        "b_StartLine": "125",
        "b_StartColumn": "2",
        "b_EndLine": "138",
        "b_EndColumn": "3",
        "a_StartLine": "125",
        "a_StartColumn": "2",
        "a_EndLine": "138",
        "a_EndColumn": "3",
        "BeforeRefact": "String getStateString(ATNState s) {\n\t\tint n = s.stateNumber;\n\t\tString stateStr = \"s\"+n;\n\t\tif ( s instanceof StarBlockStartState ) stateStr = \"StarBlockStart_\"+n;\n\t\telse if ( s instanceof PlusBlockStartState ) stateStr = \"PlusBlockStart_\"+n;\n\t\telse if ( s instanceof BlockStartState) stateStr = \"BlockStart_\"+n;\n\t\telse if ( s instanceof BlockEndState ) stateStr = \"BlockEnd_\"+n;\n\t\telse if ( s instanceof RuleStartState) stateStr = \"RuleStart_\"+g.getRule(s.ruleIndex).name+\"_\"+n;\n\t\telse if ( s instanceof RuleStopState ) stateStr = \"RuleStop_\"+g.getRule(s.ruleIndex).name+\"_\"+n;\n\t\telse if ( s instanceof PlusLoopbackState) stateStr = \"PlusLoopBack_\"+n;\n\t\telse if ( s instanceof StarLoopbackState) stateStr = \"StarLoopBack_\"+n;\n\t\telse if ( s instanceof StarLoopEntryState) stateStr = \"StarLoopEntry_\"+n;\n\t\treturn stateStr;\n\t}",
        "AfterRefact": "String getStateString(ATNState s) {\n\t\tint n = s.stateNumber;\n\t\tString stateStr = \"s\"+n;\n\t\tif ( s instanceof StarBlockStartState ) stateStr = \"StarBlockStart_\"+n;\n\t\telse if ( s instanceof PlusBlockStartState ) stateStr = \"PlusBlockStart_\"+n;\n\t\telse if ( s instanceof BlockStartState) stateStr = \"BlockStart_\"+n;\n\t\telse if ( s instanceof BlockEndState ) stateStr = \"BlockEnd_\"+n;\n\t\telse if ( s instanceof RuleStartState) stateStr = \"RuleStart_\"+g.getRule(s.ruleIndex).name+\"_\"+n;\n\t\telse if ( s instanceof RuleStopState ) stateStr = \"RuleStop_\"+g.getRule(s.ruleIndex).name+\"_\"+n;\n\t\telse if ( s instanceof PlusLoopbackState) stateStr = \"PlusLoopBack_\"+n;\n\t\telse if ( s instanceof StarLoopbackState) stateStr = \"StarLoopBack_\"+n;\n\t\telse if ( s instanceof StarLoopEntryState) stateStr = \"StarLoopEntry_\"+n;\n\t\treturn stateStr;\n\t}",
        "Extra": ""
    },
    {
        "\ufeffID": "L15668",
        "Parent": "L14958",
        "commitID_before": "5e05b71e8b1cd52cf0e77559786cc4c18dc85c37",
        "commitID_after": "90a5aa469a09a9296fe3b9a25b37ed8ebd3d627f",
        "Project": "https://github.com/antlr/antlr4",
        "Type": "CONSOLIDATE_DUPLICATE_COND_FRAGMENTS",
        "Fowler_type": "Slide Statements",
        "path_before": "tool\\src\\org\\antlr\\v4\\tool\\DOTGenerator.java",
        "path_after": "tool\\src\\org\\antlr\\v4\\tool\\DOTGenerator.java",
        "name": "String getDOT(DFA dfa, boolean isLexer)",
        "LongName": "org.antlr.v4.tool.DOTGenerator.getDOT(Lorg/antlr/v4/runtime/dfa/DFA;Z)Ljava/lang/String;",
        "b_StartLine": "83",
        "b_StartColumn": "2",
        "b_EndLine": "132",
        "b_EndColumn": "3",
        "a_StartLine": "83",
        "a_StartColumn": "2",
        "a_EndLine": "132",
        "a_EndColumn": "3",
        "BeforeRefact": "public String getDOT(DFA dfa, boolean isLexer) {\n\t\tif ( dfa.s0==null )\treturn null;\n\n\t\tST dot = stlib.getInstanceOf(\"dfa\");\n\t\tdot.add(\"name\", \"DFA\"+dfa.decision);\n\t\tdot.add(\"startState\", dfa.s0.stateNumber);\n//\t\tdot.add(\"useBox\", Tool.internalOption_ShowATNConfigsInDFA);\n\t\tdot.add(\"rankdir\", rankdir);\n\n\t\t// define stop states first; seems to be a bug in DOT where doublecircle\n\t\tfor (DFAState d : dfa.states.keySet()) {\n\t\t\tif ( !d.isAcceptState ) continue;\n\t\t\tST st = stlib.getInstanceOf(\"stopstate\");\n\t\t\tst.add(\"name\", \"s\"+d.stateNumber);\n\t\t\tst.add(\"label\", getStateLabel(d));\n\t\t\tdot.add(\"states\", st);\n\t\t}\n\n\t\tfor (DFAState d : dfa.states.keySet()) {\n\t\t\tif ( d.isAcceptState ) continue;\n\t\t\tif ( d.stateNumber == Integer.MAX_VALUE ) continue;\n\t\t\tST st = stlib.getInstanceOf(\"state\");\n\t\t\tst.add(\"name\", \"s\"+d.stateNumber);\n\t\t\tst.add(\"label\", getStateLabel(d));\n\t\t\tdot.add(\"states\", st);\n\t\t}\n\n\t\tfor (DFAState d : dfa.states.keySet()) {\n\t\t\tif ( d.edges!=null ) {\n\t\t\t\tfor (int i = 0; i < d.edges.length; i++) {\n\t\t\t\t\tDFAState target = d.edges[i];\n\t\t\t\t\tif ( target==null) continue;\n\t\t\t\t\tif ( target.stateNumber == Integer.MAX_VALUE ) continue;\n\t\t\t\t\tint ttype = i-1; // we shift up for EOF as -1 for parser\n\t\t\t\t\tString label = String.valueOf(ttype);\n\t\t\t\t\tif ( isLexer ) label = \"'\"+getEdgeLabel(String.valueOf((char) i))+\"'\";\n\t\t\t\t\telse if ( grammar!=null ) label = grammar.getTokenDisplayName(ttype);\n\t\t\t\t\tST st = stlib.getInstanceOf(\"edge\");\n\t\t\t\t\tst.add(\"label\", label);\n\t\t\t\t\tst.add(\"src\", \"s\"+d.stateNumber);\n\t\t\t\t\tst.add(\"target\", \"s\"+target.stateNumber);\n\t\t\t\t\tst.add(\"arrowhead\", arrowhead);\n\t\t\t\t\tdot.add(\"edges\", st);\n\t\t\t\t}\n\t\t\t}\n\t\t}\n\n\t\tString output = dot.render();\n\t\treturn Utils.sortLinesInString(output);\n\t}",
        "AfterRefact": "public String getDOT(DFA dfa, boolean isLexer) {\n\t\tif ( dfa.s0==null )\treturn null;\n\n\t\tST dot = stlib.getInstanceOf(\"dfa\");\n\t\tdot.add(\"name\", \"DFA\"+dfa.decision);\n\t\tdot.add(\"startState\", dfa.s0.stateNumber);\n//\t\tdot.add(\"useBox\", Tool.internalOption_ShowATNConfigsInDFA);\n\t\tdot.add(\"rankdir\", rankdir);\n\n\t\t// define stop states first; seems to be a bug in DOT where doublecircle\n\t\tfor (DFAState d : dfa.states.keySet()) {\n\t\t\tif ( !d.isAcceptState ) continue;\n\t\t\tST st = stlib.getInstanceOf(\"stopstate\");\n\t\t\tst.add(\"name\", \"s\"+d.stateNumber);\n\t\t\tst.add(\"label\", getStateLabel(d));\n\t\t\tdot.add(\"states\", st);\n\t\t}\n\n\t\tfor (DFAState d : dfa.states.keySet()) {\n\t\t\tif ( d.isAcceptState ) continue;\n\t\t\tif ( d.stateNumber == Integer.MAX_VALUE ) continue;\n\t\t\tST st = stlib.getInstanceOf(\"state\");\n\t\t\tst.add(\"name\", \"s\"+d.stateNumber);\n\t\t\tst.add(\"label\", getStateLabel(d));\n\t\t\tdot.add(\"states\", st);\n\t\t}\n\n\t\tfor (DFAState d : dfa.states.keySet()) {\n\t\t\tif ( d.edges!=null ) {\n\t\t\t\tfor (int i = 0; i < d.edges.length; i++) {\n\t\t\t\t\tDFAState target = d.edges[i];\n\t\t\t\t\tif ( target==null) continue;\n\t\t\t\t\tif ( target.stateNumber == Integer.MAX_VALUE ) continue;\n\t\t\t\t\tint ttype = i-1; // we shift up for EOF as -1 for parser\n\t\t\t\t\tString label = String.valueOf(ttype);\n\t\t\t\t\tif ( isLexer ) label = \"'\"+getEdgeLabel(String.valueOf((char) i))+\"'\";\n\t\t\t\t\telse if ( grammar!=null ) label = grammar.getTokenDisplayName(ttype);\n\t\t\t\t\tST st = stlib.getInstanceOf(\"edge\");\n\t\t\t\t\tst.add(\"label\", label);\n\t\t\t\t\tst.add(\"src\", \"s\"+d.stateNumber);\n\t\t\t\t\tst.add(\"target\", \"s\"+target.stateNumber);\n\t\t\t\t\tst.add(\"arrowhead\", arrowhead);\n\t\t\t\t\tdot.add(\"edges\", st);\n\t\t\t\t}\n\t\t\t}\n\t\t}\n\n\t\tString output = dot.render();\n\t\treturn Utils.sortLinesInString(output);\n\t}",
        "Extra": ""
    },
    {
        "\ufeffID": "L156680",
        "Parent": "L14958",
        "commitID_before": "5e05b71e8b1cd52cf0e77559786cc4c18dc85c37",
        "commitID_after": "90a5aa469a09a9296fe3b9a25b37ed8ebd3d627f",
        "Project": "https://github.com/antlr/antlr4",
        "Type": "CONSOLIDATE_COND_EXPRESSION",
        "Fowler_type": "Consolidate Conditional Expression",
        "path_before": "tool\\src\\org\\antlr\\v4\\tool\\DOTGenerator.java",
        "path_after": "tool\\src\\org\\antlr\\v4\\tool\\DOTGenerator.java",
        "name": "String getDOT(DFA dfa, boolean isLexer)",
        "LongName": "org.antlr.v4.tool.DOTGenerator.getDOT(Lorg/antlr/v4/runtime/dfa/DFA;Z)Ljava/lang/String;",
        "b_StartLine": "83",
        "b_StartColumn": "2",
        "b_EndLine": "132",
        "b_EndColumn": "3",
        "a_StartLine": "83",
        "a_StartColumn": "2",
        "a_EndLine": "132",
        "a_EndColumn": "3",
        "BeforeRefact": "public String getDOT(DFA dfa, boolean isLexer) {\n\t\tif ( dfa.s0==null )\treturn null;\n\n\t\tST dot = stlib.getInstanceOf(\"dfa\");\n\t\tdot.add(\"name\", \"DFA\"+dfa.decision);\n\t\tdot.add(\"startState\", dfa.s0.stateNumber);\n//\t\tdot.add(\"useBox\", Tool.internalOption_ShowATNConfigsInDFA);\n\t\tdot.add(\"rankdir\", rankdir);\n\n\t\t// define stop states first; seems to be a bug in DOT where doublecircle\n\t\tfor (DFAState d : dfa.states.keySet()) {\n\t\t\tif ( !d.isAcceptState ) continue;\n\t\t\tST st = stlib.getInstanceOf(\"stopstate\");\n\t\t\tst.add(\"name\", \"s\"+d.stateNumber);\n\t\t\tst.add(\"label\", getStateLabel(d));\n\t\t\tdot.add(\"states\", st);\n\t\t}\n\n\t\tfor (DFAState d : dfa.states.keySet()) {\n\t\t\tif ( d.isAcceptState ) continue;\n\t\t\tif ( d.stateNumber == Integer.MAX_VALUE ) continue;\n\t\t\tST st = stlib.getInstanceOf(\"state\");\n\t\t\tst.add(\"name\", \"s\"+d.stateNumber);\n\t\t\tst.add(\"label\", getStateLabel(d));\n\t\t\tdot.add(\"states\", st);\n\t\t}\n\n\t\tfor (DFAState d : dfa.states.keySet()) {\n\t\t\tif ( d.edges!=null ) {\n\t\t\t\tfor (int i = 0; i < d.edges.length; i++) {\n\t\t\t\t\tDFAState target = d.edges[i];\n\t\t\t\t\tif ( target==null) continue;\n\t\t\t\t\tif ( target.stateNumber == Integer.MAX_VALUE ) continue;\n\t\t\t\t\tint ttype = i-1; // we shift up for EOF as -1 for parser\n\t\t\t\t\tString label = String.valueOf(ttype);\n\t\t\t\t\tif ( isLexer ) label = \"'\"+getEdgeLabel(String.valueOf((char) i))+\"'\";\n\t\t\t\t\telse if ( grammar!=null ) label = grammar.getTokenDisplayName(ttype);\n\t\t\t\t\tST st = stlib.getInstanceOf(\"edge\");\n\t\t\t\t\tst.add(\"label\", label);\n\t\t\t\t\tst.add(\"src\", \"s\"+d.stateNumber);\n\t\t\t\t\tst.add(\"target\", \"s\"+target.stateNumber);\n\t\t\t\t\tst.add(\"arrowhead\", arrowhead);\n\t\t\t\t\tdot.add(\"edges\", st);\n\t\t\t\t}\n\t\t\t}\n\t\t}\n\n\t\tString output = dot.render();\n\t\treturn Utils.sortLinesInString(output);\n\t}",
        "AfterRefact": "public String getDOT(DFA dfa, boolean isLexer) {\n\t\tif ( dfa.s0==null )\treturn null;\n\n\t\tST dot = stlib.getInstanceOf(\"dfa\");\n\t\tdot.add(\"name\", \"DFA\"+dfa.decision);\n\t\tdot.add(\"startState\", dfa.s0.stateNumber);\n//\t\tdot.add(\"useBox\", Tool.internalOption_ShowATNConfigsInDFA);\n\t\tdot.add(\"rankdir\", rankdir);\n\n\t\t// define stop states first; seems to be a bug in DOT where doublecircle\n\t\tfor (DFAState d : dfa.states.keySet()) {\n\t\t\tif ( !d.isAcceptState ) continue;\n\t\t\tST st = stlib.getInstanceOf(\"stopstate\");\n\t\t\tst.add(\"name\", \"s\"+d.stateNumber);\n\t\t\tst.add(\"label\", getStateLabel(d));\n\t\t\tdot.add(\"states\", st);\n\t\t}\n\n\t\tfor (DFAState d : dfa.states.keySet()) {\n\t\t\tif ( d.isAcceptState ) continue;\n\t\t\tif ( d.stateNumber == Integer.MAX_VALUE ) continue;\n\t\t\tST st = stlib.getInstanceOf(\"state\");\n\t\t\tst.add(\"name\", \"s\"+d.stateNumber);\n\t\t\tst.add(\"label\", getStateLabel(d));\n\t\t\tdot.add(\"states\", st);\n\t\t}\n\n\t\tfor (DFAState d : dfa.states.keySet()) {\n\t\t\tif ( d.edges!=null ) {\n\t\t\t\tfor (int i = 0; i < d.edges.length; i++) {\n\t\t\t\t\tDFAState target = d.edges[i];\n\t\t\t\t\tif ( target==null) continue;\n\t\t\t\t\tif ( target.stateNumber == Integer.MAX_VALUE ) continue;\n\t\t\t\t\tint ttype = i-1; // we shift up for EOF as -1 for parser\n\t\t\t\t\tString label = String.valueOf(ttype);\n\t\t\t\t\tif ( isLexer ) label = \"'\"+getEdgeLabel(String.valueOf((char) i))+\"'\";\n\t\t\t\t\telse if ( grammar!=null ) label = grammar.getTokenDisplayName(ttype);\n\t\t\t\t\tST st = stlib.getInstanceOf(\"edge\");\n\t\t\t\t\tst.add(\"label\", label);\n\t\t\t\t\tst.add(\"src\", \"s\"+d.stateNumber);\n\t\t\t\t\tst.add(\"target\", \"s\"+target.stateNumber);\n\t\t\t\t\tst.add(\"arrowhead\", arrowhead);\n\t\t\t\t\tdot.add(\"edges\", st);\n\t\t\t\t}\n\t\t\t}\n\t\t}\n\n\t\tString output = dot.render();\n\t\treturn Utils.sortLinesInString(output);\n\t}",
        "Extra": ""
    },
    {
        "\ufeffID": "L3347",
        "Parent": "L3055",
        "commitID_before": "90a5aa469a09a9296fe3b9a25b37ed8ebd3d627f",
        "commitID_after": "e1e12f0b419461c4fc63461a2776024ad9f4fd54",
        "Project": "https://github.com/antlr/antlr4",
        "Type": "CONSOLIDATE_DUPLICATE_COND_FRAGMENTS",
        "Fowler_type": "Slide Statements",
        "path_before": "runtime\\Java\\src\\org\\antlr\\v4\\runtime\\atn\\ParserATNSimulator.java",
        "path_after": "runtime\\Java\\src\\org\\antlr\\v4\\runtime\\atn\\ParserATNSimulator.java",
        "name": "void closure_(ATNConfig config, ATNConfigSet configs, Set<ATNConfig> closureBusy, boolean collectPredicates, boolean fullCtx, int depth, boolean treatEofAsEpsilon)",
        "LongName": "org.antlr.v4.runtime.atn.ParserATNSimulator.closure_(Lorg/antlr/v4/runtime/atn/ATNConfig;Lorg/antlr/v4/runtime/atn/ATNConfigSet;Ljava/util/Set;ZZIZ)V",
        "b_StartLine": "1436",
        "b_StartColumn": "2",
        "b_EndLine": "1496",
        "b_EndColumn": "3",
        "a_StartLine": "1550",
        "a_StartColumn": "2",
        "a_EndLine": "1617",
        "a_EndColumn": "3",
        "BeforeRefact": "protected void closure_(@NotNull ATNConfig config,\n\t\t\t\t\t\t\t@NotNull ATNConfigSet configs,\n\t\t\t\t\t\t\t@NotNull Set<ATNConfig> closureBusy,\n\t\t\t\t\t\t\tboolean collectPredicates,\n\t\t\t\t\t\t\tboolean fullCtx,\n\t\t\t\t\t\t\tint depth,\n\t\t\t\t\t\t\tboolean treatEofAsEpsilon)\n\t{\n\t\tATNState p = config.state;\n\t\t// optimization\n\t\tif ( !p.onlyHasEpsilonTransitions() ) {\n            configs.add(config, mergeCache);\n\t\t\t// make sure to not return here, because EOF transitions can act as\n\t\t\t// both epsilon transitions and non-epsilon transitions.\n//            if ( debug ) System.out.println(\"added config \"+configs);\n        }\n\n\t\tfor (int i=0; i<p.getNumberOfTransitions(); i++) {\n\t\t\tTransition t = p.transition(i);\n\t\t\tboolean continueCollecting =\n\t\t\t\t!(t instanceof ActionTransition) && collectPredicates;\n\t\t\tATNConfig c = getEpsilonTarget(config, t, continueCollecting,\n\t\t\t\t\t\t\t\t\t\t   depth == 0, fullCtx, treatEofAsEpsilon);\n\t\t\tif ( c!=null ) {\n\t\t\t\tif (!t.isEpsilon() && !closureBusy.add(c)) {\n\t\t\t\t\t// avoid infinite recursion for EOF* and EOF+\n\t\t\t\t\tcontinue;\n\t\t\t\t}\n\n\t\t\t\tint newDepth = depth;\n\t\t\t\tif ( config.state instanceof RuleStopState) {\n\t\t\t\t\tassert !fullCtx;\n\t\t\t\t\t// target fell off end of rule; mark resulting c as having dipped into outer context\n\t\t\t\t\t// We can't get here if incoming config was rule stop and we had context\n\t\t\t\t\t// track how far we dip into outer context.  Might\n\t\t\t\t\t// come in handy and we avoid evaluating context dependent\n\t\t\t\t\t// preds if this is > 0.\n\n\t\t\t\t\tif (!closureBusy.add(c)) {\n\t\t\t\t\t\t// avoid infinite recursion for right-recursive rules\n\t\t\t\t\t\tcontinue;\n\t\t\t\t\t}\n\n\t\t\t\t\tc.reachesIntoOuterContext++;\n\t\t\t\t\tconfigs.dipsIntoOuterContext = true; // TODO: can remove? only care when we add to set per middle of this method\n\t\t\t\t\tassert newDepth > Integer.MIN_VALUE;\n\t\t\t\t\tnewDepth--;\n\t\t\t\t\tif ( debug ) System.out.println(\"dips into outer ctx: \"+c);\n\t\t\t\t}\n\t\t\t\telse if (t instanceof RuleTransition) {\n\t\t\t\t\t// latch when newDepth goes negative - once we step out of the entry context we can't return\n\t\t\t\t\tif (newDepth >= 0) {\n\t\t\t\t\t\tnewDepth++;\n\t\t\t\t\t}\n\t\t\t\t}\n\n\t\t\t\tclosureCheckingStopState(c, configs, closureBusy, continueCollecting,\n\t\t\t\t\t\t\t\t\t\t fullCtx, newDepth, treatEofAsEpsilon);\n\t\t\t}\n\t\t}\n\t}",
        "AfterRefact": "protected void closure_(ATNConfig config,\n\t\t\t\t\t\t\tATNConfigSet configs,\n\t\t\t\t\t\t\tSet<ATNConfig> closureBusy,\n\t\t\t\t\t\t\tboolean collectPredicates,\n\t\t\t\t\t\t\tboolean fullCtx,\n\t\t\t\t\t\t\tint depth,\n\t\t\t\t\t\t\tboolean treatEofAsEpsilon)\n\t{\n\t\tATNState p = config.state;\n\t\t// optimization\n\t\tif ( !p.onlyHasEpsilonTransitions() ) {\n            configs.add(config, mergeCache);\n\t\t\t// make sure to not return here, because EOF transitions can act as\n\t\t\t// both epsilon transitions and non-epsilon transitions.\n//            if ( debug ) System.out.println(\"added config \"+configs);\n        }\n\n\t\tfor (int i=0; i<p.getNumberOfTransitions(); i++) {\n\t\t\tTransition t = p.transition(i);\n\t\t\tboolean continueCollecting =\n\t\t\t\t!(t instanceof ActionTransition) && collectPredicates;\n\t\t\tATNConfig c = getEpsilonTarget(config, t, continueCollecting,\n\t\t\t\t\t\t\t\t\t\t   depth == 0, fullCtx, treatEofAsEpsilon);\n\t\t\tif ( c!=null ) {\n\t\t\t\tif (!t.isEpsilon() && !closureBusy.add(c)) {\n\t\t\t\t\t// avoid infinite recursion for EOF* and EOF+\n\t\t\t\t\tcontinue;\n\t\t\t\t}\n\n\t\t\t\tint newDepth = depth;\n\t\t\t\tif ( config.state instanceof RuleStopState) {\n\t\t\t\t\tassert !fullCtx;\n\t\t\t\t\t// target fell off end of rule; mark resulting c as having dipped into outer context\n\t\t\t\t\t// We can't get here if incoming config was rule stop and we had context\n\t\t\t\t\t// track how far we dip into outer context.  Might\n\t\t\t\t\t// come in handy and we avoid evaluating context dependent\n\t\t\t\t\t// preds if this is > 0.\n\n\t\t\t\t\tif (!closureBusy.add(c)) {\n\t\t\t\t\t\t// avoid infinite recursion for right-recursive rules\n\t\t\t\t\t\tcontinue;\n\t\t\t\t\t}\n\n\t\t\t\t\tif (_dfa != null && _dfa.isPrecedenceDfa()) {\n\t\t\t\t\t\tint outermostPrecedenceReturn = ((EpsilonTransition)t).outermostPrecedenceReturn();\n\t\t\t\t\t\tif (outermostPrecedenceReturn == _dfa.atnStartState.ruleIndex) {\n\t\t\t\t\t\t\tc.setPrecedenceFilterSuppressed(true);\n\t\t\t\t\t\t}\n\t\t\t\t\t}\n\n\t\t\t\t\tc.reachesIntoOuterContext++;\n\t\t\t\t\tconfigs.dipsIntoOuterContext = true; // TODO: can remove? only care when we add to set per middle of this method\n\t\t\t\t\tassert newDepth > Integer.MIN_VALUE;\n\t\t\t\t\tnewDepth--;\n\t\t\t\t\tif ( debug ) System.out.println(\"dips into outer ctx: \"+c);\n\t\t\t\t}\n\t\t\t\telse if (t instanceof RuleTransition) {\n\t\t\t\t\t// latch when newDepth goes negative - once we step out of the entry context we can't return\n\t\t\t\t\tif (newDepth >= 0) {\n\t\t\t\t\t\tnewDepth++;\n\t\t\t\t\t}\n\t\t\t\t}\n\n\t\t\t\tclosureCheckingStopState(c, configs, closureBusy, continueCollecting,\n\t\t\t\t\t\t\t\t\t\t fullCtx, newDepth, treatEofAsEpsilon);\n\t\t\t}\n\t\t}\n\t}",
        "Extra": ""
    },
    {
        "\ufeffID": "L2755",
        "Parent": "L1039",
        "commitID_before": "3468a5fbd868ce63c4cb61782e9baddac2ed24ae",
        "commitID_after": "5e05b71e8b1cd52cf0e77559786cc4c18dc85c37",
        "Project": "https://github.com/antlr/antlr4",
        "Type": "CONSOLIDATE_DUPLICATE_COND_FRAGMENTS",
        "Fowler_type": "Slide Statements",
        "path_before": "runtime\\Java\\src\\org\\antlr\\v4\\runtime\\atn\\LL1Analyzer.java",
        "path_after": "runtime\\Java\\src\\org\\antlr\\v4\\runtime\\atn\\LL1Analyzer.java",
        "name": "void _LOOK(ATNState s, ATNState stopState, PredictionContext ctx, IntervalSet look, Set<ATNConfig> lookBusy, BitSet calledRuleStack, boolean seeThruPreds, boolean addEOF)",
        "LongName": "org.antlr.v4.runtime.atn.LL1Analyzer._LOOK(Lorg/antlr/v4/runtime/atn/ATNState;Lorg/antlr/v4/runtime/atn/ATNState;Lorg/antlr/v4/runtime/atn/PredictionContext;Lorg/antlr/v4/runtime/misc/IntervalSet;Ljava/util/Set;Ljava/util/BitSet;ZZ)V",
        "b_StartLine": "166",
        "b_StartColumn": "5",
        "b_EndLine": "262",
        "b_EndColumn": "3",
        "a_StartLine": "166",
        "a_StartColumn": "5",
        "a_EndLine": "262",
        "a_EndColumn": "3",
        "BeforeRefact": " protected void _LOOK(@NotNull ATNState s,\n\t\t\t\t\t\t @Nullable ATNState stopState,\n\t\t\t\t\t\t @Nullable PredictionContext ctx,\n\t\t\t\t\t\t @NotNull IntervalSet look,\n                         @NotNull Set<ATNConfig> lookBusy,\n\t\t\t\t\t\t @NotNull BitSet calledRuleStack,\n\t\t\t\t\t\t boolean seeThruPreds, boolean addEOF)\n\t{\n//\t\tSystem.out.println(\"_LOOK(\"+s.stateNumber+\", ctx=\"+ctx);\n        ATNConfig c = new ATNConfig(s, 0, ctx);\n        if ( !lookBusy.add(c) ) return;\n\n\t\tif (s == stopState) {\n\t\t\tif (ctx == null) {\n\t\t\t\tlook.add(Token.EPSILON);\n\t\t\t\treturn;\n\t\t\t} else if (ctx.isEmpty() && addEOF) {\n\t\t\t\tlook.add(Token.EOF);\n\t\t\t\treturn;\n\t\t\t}\n\t\t}\n\n        if ( s instanceof RuleStopState ) {\n            if ( ctx==null ) {\n                look.add(Token.EPSILON);\n                return;\n            } else if (ctx.isEmpty() && addEOF) {\n\t\t\t\tlook.add(Token.EOF);\n\t\t\t\treturn;\n\t\t\t}\n\n\t\t\tif ( ctx != PredictionContext.EMPTY ) {\n\t\t\t\t// run thru all possible stack tops in ctx\n\t\t\t\tfor (int i = 0; i < ctx.size(); i++) {\n\t\t\t\t\tATNState returnState = atn.states.get(ctx.getReturnState(i));\n//\t\t\t\t\tSystem.out.println(\"popping back to \"+retState);\n\n\t\t\t\t\tboolean removed = calledRuleStack.get(returnState.ruleIndex);\n\t\t\t\t\ttry {\n\t\t\t\t\t\tcalledRuleStack.clear(returnState.ruleIndex);\n\t\t\t\t\t\t_LOOK(returnState, stopState, ctx.getParent(i), look, lookBusy, calledRuleStack, seeThruPreds, addEOF);\n\t\t\t\t\t}\n\t\t\t\t\tfinally {\n\t\t\t\t\t\tif (removed) {\n\t\t\t\t\t\t\tcalledRuleStack.set(returnState.ruleIndex);\n\t\t\t\t\t\t}\n\t\t\t\t\t}\n\t\t\t\t}\n\t\t\t\treturn;\n\t\t\t}\n        }\n\n        int n = s.getNumberOfTransitions();\n        for (int i=0; i<n; i++) {\n\t\t\tTransition t = s.transition(i);\n\t\t\tif ( t.getClass() == RuleTransition.class ) {\n\t\t\t\tif (calledRuleStack.get(((RuleTransition)t).target.ruleIndex)) {\n\t\t\t\t\tcontinue;\n\t\t\t\t}\n\n\t\t\t\tPredictionContext newContext =\n\t\t\t\t\tSingletonPredictionContext.create(ctx, ((RuleTransition)t).followState.stateNumber);\n\n\t\t\t\ttry {\n\t\t\t\t\tcalledRuleStack.set(((RuleTransition)t).target.ruleIndex);\n\t\t\t\t\t_LOOK(t.target, stopState, newContext, look, lookBusy, calledRuleStack, seeThruPreds, addEOF);\n\t\t\t\t}\n\t\t\t\tfinally {\n\t\t\t\t\tcalledRuleStack.clear(((RuleTransition)t).target.ruleIndex);\n\t\t\t\t}\n\t\t\t}\n\t\t\telse if ( t instanceof PredicateTransition ) {\n\t\t\t\tif ( seeThruPreds ) {\n\t\t\t\t\t_LOOK(t.target, stopState, ctx, look, lookBusy, calledRuleStack, seeThruPreds, addEOF);\n\t\t\t\t}\n\t\t\t\telse {\n\t\t\t\t\tlook.add(HIT_PRED);\n\t\t\t\t}\n\t\t\t}\n\t\t\telse if ( t.isEpsilon() ) {\n\t\t\t\t_LOOK(t.target, stopState, ctx, look, lookBusy, calledRuleStack, seeThruPreds, addEOF);\n\t\t\t}\n\t\t\telse if ( t.getClass() == WildcardTransition.class ) {\n\t\t\t\tlook.addAll( IntervalSet.of(Token.MIN_USER_TOKEN_TYPE, atn.maxTokenType) );\n\t\t\t}\n\t\t\telse {\n//\t\t\t\tSystem.out.println(\"adding \"+ t);\n\t\t\t\tIntervalSet set = t.label();\n\t\t\t\tif (set != null) {\n\t\t\t\t\tif (t instanceof NotSetTransition) {\n\t\t\t\t\t\tset = set.complement(IntervalSet.of(Token.MIN_USER_TOKEN_TYPE, atn.maxTokenType));\n\t\t\t\t\t}\n\t\t\t\t\tlook.addAll(set);\n\t\t\t\t}\n\t\t\t}\n\t\t}\n\t}",
        "AfterRefact": " protected void _LOOK(@NotNull ATNState s,\n\t\t\t\t\t\t @Nullable ATNState stopState,\n\t\t\t\t\t\t @Nullable PredictionContext ctx,\n\t\t\t\t\t\t @NotNull IntervalSet look,\n                         @NotNull Set<ATNConfig> lookBusy,\n\t\t\t\t\t\t @NotNull BitSet calledRuleStack,\n\t\t\t\t\t\t boolean seeThruPreds, boolean addEOF)\n\t{\n//\t\tSystem.out.println(\"_LOOK(\"+s.stateNumber+\", ctx=\"+ctx);\n        ATNConfig c = new ATNConfig(s, 0, ctx);\n        if ( !lookBusy.add(c) ) return;\n\n\t\tif (s == stopState) {\n\t\t\tif (ctx == null) {\n\t\t\t\tlook.add(Token.EPSILON);\n\t\t\t\treturn;\n\t\t\t} else if (ctx.isEmpty() && addEOF) {\n\t\t\t\tlook.add(Token.EOF);\n\t\t\t\treturn;\n\t\t\t}\n\t\t}\n\n        if ( s instanceof RuleStopState ) {\n            if ( ctx==null ) {\n                look.add(Token.EPSILON);\n                return;\n            } else if (ctx.isEmpty() && addEOF) {\n\t\t\t\tlook.add(Token.EOF);\n\t\t\t\treturn;\n\t\t\t}\n\n\t\t\tif ( ctx != PredictionContext.EMPTY ) {\n\t\t\t\t// run thru all possible stack tops in ctx\n\t\t\t\tfor (int i = 0; i < ctx.size(); i++) {\n\t\t\t\t\tATNState returnState = atn.states.get(ctx.getReturnState(i));\n//\t\t\t\t\tSystem.out.println(\"popping back to \"+retState);\n\n\t\t\t\t\tboolean removed = calledRuleStack.get(returnState.ruleIndex);\n\t\t\t\t\ttry {\n\t\t\t\t\t\tcalledRuleStack.clear(returnState.ruleIndex);\n\t\t\t\t\t\t_LOOK(returnState, stopState, ctx.getParent(i), look, lookBusy, calledRuleStack, seeThruPreds, addEOF);\n\t\t\t\t\t}\n\t\t\t\t\tfinally {\n\t\t\t\t\t\tif (removed) {\n\t\t\t\t\t\t\tcalledRuleStack.set(returnState.ruleIndex);\n\t\t\t\t\t\t}\n\t\t\t\t\t}\n\t\t\t\t}\n\t\t\t\treturn;\n\t\t\t}\n        }\n\n        int n = s.getNumberOfTransitions();\n        for (int i=0; i<n; i++) {\n\t\t\tTransition t = s.transition(i);\n\t\t\tif ( t.getClass() == RuleTransition.class ) {\n\t\t\t\tif (calledRuleStack.get(((RuleTransition)t).target.ruleIndex)) {\n\t\t\t\t\tcontinue;\n\t\t\t\t}\n\n\t\t\t\tPredictionContext newContext =\n\t\t\t\t\tSingletonPredictionContext.create(ctx, ((RuleTransition)t).followState.stateNumber);\n\n\t\t\t\ttry {\n\t\t\t\t\tcalledRuleStack.set(((RuleTransition)t).target.ruleIndex);\n\t\t\t\t\t_LOOK(t.target, stopState, newContext, look, lookBusy, calledRuleStack, seeThruPreds, addEOF);\n\t\t\t\t}\n\t\t\t\tfinally {\n\t\t\t\t\tcalledRuleStack.clear(((RuleTransition)t).target.ruleIndex);\n\t\t\t\t}\n\t\t\t}\n\t\t\telse if ( t instanceof AbstractPredicateTransition ) {\n\t\t\t\tif ( seeThruPreds ) {\n\t\t\t\t\t_LOOK(t.target, stopState, ctx, look, lookBusy, calledRuleStack, seeThruPreds, addEOF);\n\t\t\t\t}\n\t\t\t\telse {\n\t\t\t\t\tlook.add(HIT_PRED);\n\t\t\t\t}\n\t\t\t}\n\t\t\telse if ( t.isEpsilon() ) {\n\t\t\t\t_LOOK(t.target, stopState, ctx, look, lookBusy, calledRuleStack, seeThruPreds, addEOF);\n\t\t\t}\n\t\t\telse if ( t.getClass() == WildcardTransition.class ) {\n\t\t\t\tlook.addAll( IntervalSet.of(Token.MIN_USER_TOKEN_TYPE, atn.maxTokenType) );\n\t\t\t}\n\t\t\telse {\n//\t\t\t\tSystem.out.println(\"adding \"+ t);\n\t\t\t\tIntervalSet set = t.label();\n\t\t\t\tif (set != null) {\n\t\t\t\t\tif (t instanceof NotSetTransition) {\n\t\t\t\t\t\tset = set.complement(IntervalSet.of(Token.MIN_USER_TOKEN_TYPE, atn.maxTokenType));\n\t\t\t\t\t}\n\t\t\t\t\tlook.addAll(set);\n\t\t\t\t}\n\t\t\t}\n\t\t}\n\t}",
        "Extra": ""
    },
    {
        "\ufeffID": "L13228",
        "Parent": "L13220",
        "commitID_before": "3468a5fbd868ce63c4cb61782e9baddac2ed24ae",
        "commitID_after": "5e05b71e8b1cd52cf0e77559786cc4c18dc85c37",
        "Project": "https://github.com/antlr/antlr4",
        "Type": "CONSOLIDATE_DUPLICATE_COND_FRAGMENTS",
        "Fowler_type": "Slide Statements",
        "path_before": "tool\\src\\org\\antlr\\v4\\parse\\TokenVocabParser.java",
        "path_after": "tool\\src\\org\\antlr\\v4\\parse\\TokenVocabParser.java",
        "name": "Map<String, Integer> load()",
        "LongName": "org.antlr.v4.parse.TokenVocabParser.load()Ljava/util/Map;",
        "b_StartLine": "58",
        "b_StartColumn": "2",
        "b_EndLine": "106",
        "b_EndColumn": "3",
        "a_StartLine": "59",
        "a_StartColumn": "2",
        "a_EndLine": "123",
        "a_EndColumn": "3",
        "BeforeRefact": "public Map<String,Integer> load() {\n\t\tMap<String,Integer> tokens = new LinkedHashMap<String,Integer>();\n\t\tint maxTokenType = -1;\n\t\tFile fullFile = getImportedVocabFile();\n\t\ttry {\n\t\t\tPattern tokenDefPattern = Pattern.compile(\"([^\\n]+?)[ \\\\t]*?=[ \\\\t]*?([0-9]+)\");\n\t\t\tFileReader fr = new FileReader(fullFile);\n\t\t\tBufferedReader br = new BufferedReader(fr);\n\t\t\tString tokenDef = br.readLine();\n\t\t\tint lineNum = 1;\n\t\t\twhile ( tokenDef!=null ) {\n\t\t\t\tMatcher matcher = tokenDefPattern.matcher(tokenDef);\n\t\t\t\tif ( matcher.find() ) {\n\t\t\t\t\tString tokenID = matcher.group(1);\n\t\t\t\t\tString tokenTypeS = matcher.group(2);\n\t\t\t\t\tint tokenType = Integer.valueOf(tokenTypeS);\n\t\t\t\t\ttool.log(\"grammar\", \"import \"+tokenID+\"=\"+tokenType);\n\t\t\t\t\ttokens.put(tokenID, tokenType);\n\t\t\t\t\tmaxTokenType = Math.max(maxTokenType,tokenType);\n\t\t\t\t\tlineNum++;\n\t\t\t\t}\n\t\t\t\telse {\n\t\t\t\t\tif ( tokenDef.length()>0 ) { // ignore blank lines\n\t\t\t\t\t\ttool.errMgr.toolError(ErrorType.TOKENS_FILE_SYNTAX_ERROR,\n\t\t\t\t\t\t\t\t\t\t\t  vocabName + CodeGenerator.VOCAB_FILE_EXTENSION,\n\t\t\t\t\t\t\t\t\t\t\t  \" bad token def: \"+tokenDef,\n\t\t\t\t\t\t\t\t\t\t\t  lineNum);\n\t\t\t\t\t}\n\t\t\t\t}\n\t\t\t\ttokenDef = br.readLine();\n\t\t\t}\n\t\t\tbr.close();\n\t\t}\n\t\tcatch (FileNotFoundException fnfe) {\n\t\t\ttool.errMgr.toolError(ErrorType.CANNOT_FIND_TOKENS_FILE,\n\t\t\t\t\t\t\t\t  fullFile);\n\t\t}\n\t\tcatch (IOException ioe) {\n\t\t\ttool.errMgr.toolError(ErrorType.ERROR_READING_TOKENS_FILE,\n\t\t\t\t\t\t\t\t  fullFile,\n\t\t\t\t\t\t\t\t  ioe);\n\t\t}\n\t\tcatch (Exception e) {\n\t\t\ttool.errMgr.toolError(ErrorType.ERROR_READING_TOKENS_FILE,\n\t\t\t\t\t\t\t\t  fullFile,\n\t\t\t\t\t\t\t\t  e);\n\t\t}\n\t\treturn tokens;\n\t}",
        "AfterRefact": "public Map<String,Integer> load() {\n\t\tMap<String,Integer> tokens = new LinkedHashMap<String,Integer>();\n\t\tint maxTokenType = -1;\n\t\tFile fullFile = getImportedVocabFile();\n\t\tFileReader fr = null;\n\t\tBufferedReader br = null;\n\t\ttry {\n\t\t\tPattern tokenDefPattern = Pattern.compile(\"([^\\n]+?)[ \\\\t]*?=[ \\\\t]*?([0-9]+)\");\n\t\t\tfr = new FileReader(fullFile);\n\t\t\tbr = new BufferedReader(fr);\n\t\t\tString tokenDef = br.readLine();\n\t\t\tint lineNum = 1;\n\t\t\twhile ( tokenDef!=null ) {\n\t\t\t\tMatcher matcher = tokenDefPattern.matcher(tokenDef);\n\t\t\t\tif ( matcher.find() ) {\n\t\t\t\t\tString tokenID = matcher.group(1);\n\t\t\t\t\tString tokenTypeS = matcher.group(2);\n\t\t\t\t\tint tokenType;\n\t\t\t\t\ttry {\n\t\t\t\t\t\ttokenType = Integer.valueOf(tokenTypeS);\n\t\t\t\t\t}\n\t\t\t\t\tcatch (NumberFormatException nfe) {\n\t\t\t\t\t\ttool.errMgr.toolError(ErrorType.TOKENS_FILE_SYNTAX_ERROR,\n\t\t\t\t\t\t\t\t\t\t\t  vocabName + CodeGenerator.VOCAB_FILE_EXTENSION,\n\t\t\t\t\t\t\t\t\t\t\t  \" bad token type: \"+tokenTypeS,\n\t\t\t\t\t\t\t\t\t\t\t  lineNum);\n\t\t\t\t\t\ttokenType = Token.INVALID_TOKEN_TYPE;\n\t\t\t\t\t}\n\t\t\t\t\ttool.log(\"grammar\", \"import \"+tokenID+\"=\"+tokenType);\n\t\t\t\t\ttokens.put(tokenID, tokenType);\n\t\t\t\t\tmaxTokenType = Math.max(maxTokenType,tokenType);\n\t\t\t\t\tlineNum++;\n\t\t\t\t}\n\t\t\t\telse {\n\t\t\t\t\tif ( tokenDef.length()>0 ) { // ignore blank lines\n\t\t\t\t\t\ttool.errMgr.toolError(ErrorType.TOKENS_FILE_SYNTAX_ERROR,\n\t\t\t\t\t\t\t\t\t\t\t  vocabName + CodeGenerator.VOCAB_FILE_EXTENSION,\n\t\t\t\t\t\t\t\t\t\t\t  \" bad token def: \"+tokenDef,\n\t\t\t\t\t\t\t\t\t\t\t  lineNum);\n\t\t\t\t\t}\n\t\t\t\t}\n\t\t\t\ttokenDef = br.readLine();\n\t\t\t}\n\t\t}\n\t\tcatch (FileNotFoundException fnfe) {\n\t\t\ttool.errMgr.toolError(ErrorType.CANNOT_FIND_TOKENS_FILE,\n\t\t\t\t\t\t\t\t  fullFile);\n\t\t}\n\t\tcatch (Exception e) {\n\t\t\ttool.errMgr.toolError(ErrorType.ERROR_READING_TOKENS_FILE,\n\t\t\t\t\t\t\t\t  fullFile,\n\t\t\t\t\t\t\t\t  e);\n\t\t}\n\t\tfinally {\n\t\t\ttry {\n\t\t\t\tif ( br!=null ) br.close();\n\t\t\t}\n\t\t\tcatch (IOException ioe) {\n\t\t\t\ttool.errMgr.toolError(ErrorType.ERROR_READING_TOKENS_FILE,\n\t\t\t\t\t\t\t\t\t  fullFile,\n\t\t\t\t\t\t\t\t\t  ioe);\n\t\t\t}\n\t\t}\n\t\treturn tokens;\n\t}",
        "Extra": ""
    },
    {
        "\ufeffID": "L8024",
        "Parent": "L7991",
        "commitID_before": "ad9bac95199736c270940c4037b7ee7174bacca6",
        "commitID_after": "3468a5fbd868ce63c4cb61782e9baddac2ed24ae",
        "Project": "https://github.com/antlr/antlr4",
        "Type": "CONSOLIDATE_DUPLICATE_COND_FRAGMENTS",
        "Fowler_type": "Slide Statements",
        "path_before": "tool\\src\\org\\antlr\\v4\\automata\\ATNSerializer.java",
        "path_after": "tool\\src\\org\\antlr\\v4\\automata\\ATNSerializer.java",
        "name": "String decode(char[] data)",
        "LongName": "org.antlr.v4.automata.ATNSerializer.decode([C)Ljava/lang/String;",
        "b_StartLine": "273",
        "b_StartColumn": "2",
        "b_EndLine": "361",
        "b_EndColumn": "3",
        "a_StartLine": "334",
        "a_StartColumn": "2",
        "a_EndLine": "444",
        "a_EndColumn": "3",
        "BeforeRefact": "public String decode(char[] data) {\n\t\tdata = data.clone();\n\t\t// don't adjust the first value since that's the version number\n\t\tfor (int i = 1; i < data.length; i++) {\n\t\t\tdata[i] = (char)(data[i] - 2);\n\t\t}\n\n\t\tStringBuilder buf = new StringBuilder();\n\t\tint p = 0;\n\t\tint version = ATNSimulator.toInt(data[p++]);\n\t\tif (version != ATNSimulator.SERIALIZED_VERSION) {\n\t\t\tString reason = String.format(\"Could not deserialize ATN with version %d (expected %d).\", version, ATNSimulator.SERIALIZED_VERSION);\n\t\t\tthrow new UnsupportedOperationException(new InvalidClassException(ATN.class.getName(), reason));\n\t\t}\n\n\t\tint grammarType = ATNSimulator.toInt(data[p++]);\n\t\tint maxType = ATNSimulator.toInt(data[p++]);\n\t\tbuf.append(\"max type \").append(maxType).append(\"\\n\");\n\t\tint nstates = ATNSimulator.toInt(data[p++]);\n\t\tfor (int i=1; i<=nstates; i++) {\n\t\t\tint stype = ATNSimulator.toInt(data[p++]);\n            if ( stype==ATNState.INVALID_TYPE ) continue; // ignore bad type of states\n\t\t\tint ruleIndex = ATNSimulator.toInt(data[p++]);\n\t\t\tString arg = \"\";\n\t\t\tif ( stype == ATNState.LOOP_END ) {\n\t\t\t\tint loopBackStateNumber = ATNSimulator.toInt(data[p++]);\n\t\t\t\targ = \" \"+loopBackStateNumber;\n\t\t\t}\n\t\t\telse if ( stype == ATNState.PLUS_BLOCK_START || stype == ATNState.STAR_BLOCK_START || stype == ATNState.BLOCK_START ) {\n\t\t\t\tint endStateNumber = ATNSimulator.toInt(data[p++]);\n\t\t\t\targ = \" \"+endStateNumber;\n\t\t\t}\n\t\t\tbuf.append(i - 1).append(\":\")\n\t\t\t\t.append(ATNState.serializationNames.get(stype)).append(\" \")\n\t\t\t\t.append(ruleIndex).append(arg).append(\"\\n\");\n\t\t}\n\t\tint numNonGreedyStates = ATNSimulator.toInt(data[p++]);\n\t\tfor (int i = 0; i < numNonGreedyStates; i++) {\n\t\t\tint stateNumber = ATNSimulator.toInt(data[p++]);\n\t\t}\n\t\tint nrules = ATNSimulator.toInt(data[p++]);\n\t\tfor (int i=0; i<nrules; i++) {\n\t\t\tint s = ATNSimulator.toInt(data[p++]);\n            if ( g.isLexer() ) {\n                int arg1 = ATNSimulator.toInt(data[p++]);\n                int arg2 = ATNSimulator.toInt(data[p++]);\n                buf.append(\"rule \").append(i).append(\":\").append(s).append(\" \").append(arg1).append(\",\").append(arg2).append('\\n');\n            }\n            else {\n                buf.append(\"rule \").append(i).append(\":\").append(s).append('\\n');\n            }\n\t\t}\n\t\tint nmodes = ATNSimulator.toInt(data[p++]);\n\t\tfor (int i=0; i<nmodes; i++) {\n\t\t\tint s = ATNSimulator.toInt(data[p++]);\n\t\t\tbuf.append(\"mode \").append(i).append(\":\").append(s).append('\\n');\n\t\t}\n\t\tint nsets = ATNSimulator.toInt(data[p++]);\n\t\tfor (int i=1; i<=nsets; i++) {\n\t\t\tint nintervals = ATNSimulator.toInt(data[p++]);\n\t\t\tbuf.append(i-1).append(\":\");\n\t\t\tfor (int j=1; j<=nintervals; j++) {\n\t\t\t\tif ( j>1 ) buf.append(\", \");\n\t\t\t\tbuf.append(getTokenName(ATNSimulator.toInt(data[p]))).append(\"..\").append(getTokenName(ATNSimulator.toInt(data[p + 1])));\n\t\t\t\tp += 2;\n\t\t\t}\n\t\t\tbuf.append(\"\\n\");\n\t\t}\n\t\tint nedges = ATNSimulator.toInt(data[p++]);\n\t\tfor (int i=1; i<=nedges; i++) {\n\t\t\tint src = ATNSimulator.toInt(data[p]);\n\t\t\tint trg = ATNSimulator.toInt(data[p + 1]);\n\t\t\tint ttype = ATNSimulator.toInt(data[p + 2]);\n\t\t\tint arg1 = ATNSimulator.toInt(data[p + 3]);\n\t\t\tint arg2 = ATNSimulator.toInt(data[p + 4]);\n\t\t\tint arg3 = ATNSimulator.toInt(data[p + 5]);\n\t\t\tbuf.append(src).append(\"->\").append(trg)\n\t\t\t\t.append(\" \").append(Transition.serializationNames.get(ttype))\n\t\t\t\t.append(\" \").append(arg1).append(\",\").append(arg2).append(\",\").append(arg3)\n\t\t\t\t.append(\"\\n\");\n\t\t\tp += 6;\n\t\t}\n\t\tint ndecisions = ATNSimulator.toInt(data[p++]);\n\t\tfor (int i=1; i<=ndecisions; i++) {\n\t\t\tint s = ATNSimulator.toInt(data[p++]);\n\t\t\tbuf.append(i-1).append(\":\").append(s).append(\"\\n\");\n\t\t}\n\t\treturn buf.toString();\n\t}",
        "AfterRefact": "public String decode(char[] data) {\n\t\tdata = data.clone();\n\t\t// don't adjust the first value since that's the version number\n\t\tfor (int i = 1; i < data.length; i++) {\n\t\t\tdata[i] = (char)(data[i] - 2);\n\t\t}\n\n\t\tStringBuilder buf = new StringBuilder();\n\t\tint p = 0;\n\t\tint version = ATNSimulator.toInt(data[p++]);\n\t\tif (version != ATNSimulator.SERIALIZED_VERSION) {\n\t\t\tString reason = String.format(\"Could not deserialize ATN with version %d (expected %d).\", version, ATNSimulator.SERIALIZED_VERSION);\n\t\t\tthrow new UnsupportedOperationException(new InvalidClassException(ATN.class.getName(), reason));\n\t\t}\n\n\t\tUUID uuid = ATNSimulator.toUUID(data, p);\n\t\tp += 8;\n\t\tif (!uuid.equals(ATNSimulator.SERIALIZED_UUID)) {\n\t\t\tString reason = String.format(Locale.getDefault(), \"Could not deserialize ATN with UUID %s (expected %s).\", uuid, ATNSimulator.SERIALIZED_UUID);\n\t\t\tthrow new UnsupportedOperationException(new InvalidClassException(ATN.class.getName(), reason));\n\t\t}\n\n\t\tint grammarType = ATNSimulator.toInt(data[p++]);\n\t\tint maxType = ATNSimulator.toInt(data[p++]);\n\t\tbuf.append(\"max type \").append(maxType).append(\"\\n\");\n\t\tint nstates = ATNSimulator.toInt(data[p++]);\n\t\tfor (int i=0; i<nstates; i++) {\n\t\t\tint stype = ATNSimulator.toInt(data[p++]);\n            if ( stype==ATNState.INVALID_TYPE ) continue; // ignore bad type of states\n\t\t\tint ruleIndex = ATNSimulator.toInt(data[p++]);\n\t\t\tif (ruleIndex == Character.MAX_VALUE) {\n\t\t\t\truleIndex = -1;\n\t\t\t}\n\n\t\t\tString arg = \"\";\n\t\t\tif ( stype == ATNState.LOOP_END ) {\n\t\t\t\tint loopBackStateNumber = ATNSimulator.toInt(data[p++]);\n\t\t\t\targ = \" \"+loopBackStateNumber;\n\t\t\t}\n\t\t\telse if ( stype == ATNState.PLUS_BLOCK_START || stype == ATNState.STAR_BLOCK_START || stype == ATNState.BLOCK_START ) {\n\t\t\t\tint endStateNumber = ATNSimulator.toInt(data[p++]);\n\t\t\t\targ = \" \"+endStateNumber;\n\t\t\t}\n\t\t\tbuf.append(i).append(\":\")\n\t\t\t\t.append(ATNState.serializationNames.get(stype)).append(\" \")\n\t\t\t\t.append(ruleIndex).append(arg).append(\"\\n\");\n\t\t}\n\t\tint numNonGreedyStates = ATNSimulator.toInt(data[p++]);\n\t\tfor (int i = 0; i < numNonGreedyStates; i++) {\n\t\t\tint stateNumber = ATNSimulator.toInt(data[p++]);\n\t\t}\n\t\tint nrules = ATNSimulator.toInt(data[p++]);\n\t\tfor (int i=0; i<nrules; i++) {\n\t\t\tint s = ATNSimulator.toInt(data[p++]);\n            if ( g.isLexer() ) {\n                int arg1 = ATNSimulator.toInt(data[p++]);\n                int arg2 = ATNSimulator.toInt(data[p++]);\n\t\t\t\tif (arg2 == Character.MAX_VALUE) {\n\t\t\t\t\targ2 = -1;\n\t\t\t\t}\n                buf.append(\"rule \").append(i).append(\":\").append(s).append(\" \").append(arg1).append(\",\").append(arg2).append('\\n');\n            }\n            else {\n                buf.append(\"rule \").append(i).append(\":\").append(s).append('\\n');\n            }\n\t\t}\n\t\tint nmodes = ATNSimulator.toInt(data[p++]);\n\t\tfor (int i=0; i<nmodes; i++) {\n\t\t\tint s = ATNSimulator.toInt(data[p++]);\n\t\t\tbuf.append(\"mode \").append(i).append(\":\").append(s).append('\\n');\n\t\t}\n\t\tint nsets = ATNSimulator.toInt(data[p++]);\n\t\tfor (int i=0; i<nsets; i++) {\n\t\t\tint nintervals = ATNSimulator.toInt(data[p++]);\n\t\t\tbuf.append(i).append(\":\");\n\t\t\tboolean containsEof = data[p++] != 0;\n\t\t\tif (containsEof) {\n\t\t\t\tbuf.append(getTokenName(Token.EOF));\n\t\t\t}\n\n\t\t\tfor (int j=0; j<nintervals; j++) {\n\t\t\t\tif ( containsEof || j>0 ) {\n\t\t\t\t\tbuf.append(\", \");\n\t\t\t\t}\n\n\t\t\t\tbuf.append(getTokenName(ATNSimulator.toInt(data[p]))).append(\"..\").append(getTokenName(ATNSimulator.toInt(data[p + 1])));\n\t\t\t\tp += 2;\n\t\t\t}\n\t\t\tbuf.append(\"\\n\");\n\t\t}\n\t\tint nedges = ATNSimulator.toInt(data[p++]);\n\t\tfor (int i=0; i<nedges; i++) {\n\t\t\tint src = ATNSimulator.toInt(data[p]);\n\t\t\tint trg = ATNSimulator.toInt(data[p + 1]);\n\t\t\tint ttype = ATNSimulator.toInt(data[p + 2]);\n\t\t\tint arg1 = ATNSimulator.toInt(data[p + 3]);\n\t\t\tint arg2 = ATNSimulator.toInt(data[p + 4]);\n\t\t\tint arg3 = ATNSimulator.toInt(data[p + 5]);\n\t\t\tbuf.append(src).append(\"->\").append(trg)\n\t\t\t\t.append(\" \").append(Transition.serializationNames.get(ttype))\n\t\t\t\t.append(\" \").append(arg1).append(\",\").append(arg2).append(\",\").append(arg3)\n\t\t\t\t.append(\"\\n\");\n\t\t\tp += 6;\n\t\t}\n\t\tint ndecisions = ATNSimulator.toInt(data[p++]);\n\t\tfor (int i=0; i<ndecisions; i++) {\n\t\t\tint s = ATNSimulator.toInt(data[p++]);\n\t\t\tbuf.append(i).append(\":\").append(s).append(\"\\n\");\n\t\t}\n\t\treturn buf.toString();\n\t}",
        "Extra": ""
    },
    {
        "\ufeffID": "L9806",
        "Parent": "L8817",
        "commitID_before": "ad9bac95199736c270940c4037b7ee7174bacca6",
        "commitID_after": "3468a5fbd868ce63c4cb61782e9baddac2ed24ae",
        "Project": "https://github.com/antlr/antlr4",
        "Type": "CONSOLIDATE_DUPLICATE_COND_FRAGMENTS",
        "Fowler_type": "Slide Statements",
        "path_before": "tool\\src\\org\\antlr\\v4\\codegen\\ParserFactory.java",
        "path_after": "tool\\src\\org\\antlr\\v4\\codegen\\ParserFactory.java",
        "name": "void defineImplicitLabel(GrammarAST ast, LabeledOp op)",
        "LongName": "org.antlr.v4.codegen.ParserFactory.defineImplicitLabel(Lorg/antlr/v4/tool/ast/GrammarAST;Lorg/antlr/v4/codegen/model/LabeledOp;)V",
        "b_StartLine": "330",
        "b_StartColumn": "2",
        "b_EndLine": "354",
        "b_EndColumn": "3",
        "a_StartLine": "334",
        "a_StartColumn": "2",
        "a_EndLine": "358",
        "a_EndColumn": "3",
        "BeforeRefact": "public void defineImplicitLabel(GrammarAST ast, LabeledOp op) {\n\t\tDecl d;\n\t\tif ( ast.getType()==ANTLRParser.SET || ast.getType()==ANTLRParser.WILDCARD ) {\n\t\t\tString implLabel =\n\t\t\t\tgen.target.getImplicitSetLabel(String.valueOf(ast.token.getTokenIndex()));\n\t\t\td = getTokenLabelDecl(implLabel);\n\t\t\t((TokenDecl)d).isImplicit = true;\n\t\t}\n\t\telse if ( ast.getType()==ANTLRParser.RULE_REF ) { // a rule reference?\n\t\t\tRule r = g.getRule(ast.getText());\n\t\t\tString implLabel = gen.target.getImplicitRuleLabel(ast.getText());\n\t\t\tString ctxName =\n\t\t\t\tgen.target.getRuleFunctionContextStructName(r);\n\t\t\td = new RuleContextDecl(this, implLabel, ctxName);\n\t\t\t((RuleContextDecl)d).isImplicit = true;\n\t\t}\n\t\telse {\n\t\t\tString implLabel = gen.target.getImplicitTokenLabel(ast.getText());\n\t\t\td = getTokenLabelDecl(implLabel);\n\t\t\t((TokenDecl)d).isImplicit = true;\n\t\t}\n\t\top.getLabels().add(d);\n\t\t// all labels must be in scope struct in case we exec action out of context\n\t\tgetCurrentRuleFunction().addContextDecl(ast.getAltLabel(), d);\n\t}",
        "AfterRefact": "public void defineImplicitLabel(GrammarAST ast, LabeledOp op) {\n\t\tDecl d;\n\t\tif ( ast.getType()==ANTLRParser.SET || ast.getType()==ANTLRParser.WILDCARD ) {\n\t\t\tString implLabel =\n\t\t\t\tgen.getTarget().getImplicitSetLabel(String.valueOf(ast.token.getTokenIndex()));\n\t\t\td = getTokenLabelDecl(implLabel);\n\t\t\t((TokenDecl)d).isImplicit = true;\n\t\t}\n\t\telse if ( ast.getType()==ANTLRParser.RULE_REF ) { // a rule reference?\n\t\t\tRule r = g.getRule(ast.getText());\n\t\t\tString implLabel = gen.getTarget().getImplicitRuleLabel(ast.getText());\n\t\t\tString ctxName =\n\t\t\t\tgen.getTarget().getRuleFunctionContextStructName(r);\n\t\t\td = new RuleContextDecl(this, implLabel, ctxName);\n\t\t\t((RuleContextDecl)d).isImplicit = true;\n\t\t}\n\t\telse {\n\t\t\tString implLabel = gen.getTarget().getImplicitTokenLabel(ast.getText());\n\t\t\td = getTokenLabelDecl(implLabel);\n\t\t\t((TokenDecl)d).isImplicit = true;\n\t\t}\n\t\top.getLabels().add(d);\n\t\t// all labels must be in scope struct in case we exec action out of context\n\t\tgetCurrentRuleFunction().addContextDecl(ast.getAltLabel(), d);\n\t}",
        "Extra": ""
    },
    {
        "\ufeffID": "L1506",
        "Parent": "L807",
        "commitID_before": "ad9bac95199736c270940c4037b7ee7174bacca6",
        "commitID_after": "3468a5fbd868ce63c4cb61782e9baddac2ed24ae",
        "Project": "https://github.com/antlr/antlr4",
        "Type": "CONSOLIDATE_COND_EXPRESSION",
        "Fowler_type": "Consolidate Conditional Expression",
        "path_before": "runtime\\Java\\src\\org\\antlr\\v4\\runtime\\atn\\ATNState.java",
        "path_after": "runtime\\Java\\src\\org\\antlr\\v4\\runtime\\atn\\ATNState.java",
        "name": "void addTransition(Transition e)",
        "LongName": "org.antlr.v4.runtime.atn.ATNState.addTransition(Lorg/antlr/v4/runtime/atn/Transition;)V",
        "b_StartLine": "180",
        "b_StartColumn": "2",
        "b_EndLine": "190",
        "b_EndColumn": "3",
        "a_StartLine": "181",
        "a_StartColumn": "2",
        "a_EndLine": "183",
        "a_EndColumn": "3",
        "BeforeRefact": "public void addTransition(Transition e) {\n\t\tif (transitions.isEmpty()) {\n\t\t\tepsilonOnlyTransitions = e.isEpsilon();\n\t\t}\n\t\telse if (epsilonOnlyTransitions != e.isEpsilon()) {\n\t\t\tSystem.err.format(\"ATN state %d has both epsilon and non-epsilon transitions.\\n\", stateNumber);\n\t\t\tepsilonOnlyTransitions = false;\n\t\t}\n\n\t\ttransitions.add(e);\n\t}",
        "AfterRefact": "public void addTransition(Transition e) {\n\t\taddTransition(transitions.size(), e);\n\t}\n\n\tpublic void addTransition(int index, Transition e) {\n\t\tif (transitions.isEmpty()) {\n\t\t\tepsilonOnlyTransitions = e.isEpsilon();\n\t\t}\n\t\telse if (epsilonOnlyTransitions != e.isEpsilon()) {\n\t\t\tSystem.err.format(Locale.getDefault(), \"ATN state %d has both epsilon and non-epsilon transitions.\\n\", stateNumber);\n\t\t\tepsilonOnlyTransitions = false;\n\t\t}\n\n\t\ttransitions.add(index, e);\n\t}",
        "Extra": ""
    },
    {
        "\ufeffID": "L1991",
        "Parent": "L1833",
        "commitID_before": "ad9bac95199736c270940c4037b7ee7174bacca6",
        "commitID_after": "3468a5fbd868ce63c4cb61782e9baddac2ed24ae",
        "Project": "https://github.com/antlr/antlr4",
        "Type": "REPLACE_NESTED_COND_WITH_GUARD_CLAUSES",
        "Fowler_type": "Replace Nested Conditional with Guard Clauses",
        "path_before": "runtime\\Java\\src\\org\\antlr\\v4\\runtime\\atn\\LexerATNSimulator.java",
        "path_after": "runtime\\Java\\src\\org\\antlr\\v4\\runtime\\atn\\LexerATNSimulator.java",
        "name": "boolean closure(CharStream input, LexerATNConfig config, ATNConfigSet configs, boolean currentAltReachedAcceptState, boolean speculative)",
        "LongName": "org.antlr.v4.runtime.atn.LexerATNSimulator.closure(Lorg/antlr/v4/runtime/CharStream;Lorg/antlr/v4/runtime/atn/LexerATNConfig;Lorg/antlr/v4/runtime/atn/ATNConfigSet;ZZ)Z",
        "b_StartLine": "389",
        "b_StartColumn": "2",
        "b_EndLine": "456",
        "b_EndColumn": "3",
        "a_StartLine": "409",
        "a_StartColumn": "2",
        "a_EndLine": "466",
        "a_EndColumn": "3",
        "BeforeRefact": "protected boolean closure(@NotNull CharStream input, @NotNull LexerATNConfig config, @NotNull ATNConfigSet configs, boolean currentAltReachedAcceptState, boolean speculative) {\n\t\tif ( debug ) {\n\t\t\tSystem.out.println(\"closure(\"+config.toString(recog, true)+\")\");\n\t\t}\n\n\t\tif ( config.state instanceof RuleStopState ) {\n\t\t\tif ( debug ) {\n\t\t\t\tif ( recog!=null ) {\n\t\t\t\t\tSystem.out.format(\"closure at %s rule stop %s\\n\", recog.getRuleNames()[config.state.ruleIndex], config);\n\t\t\t\t}\n\t\t\t\telse {\n\t\t\t\t\tSystem.out.format(\"closure at rule stop %s\\n\", config);\n\t\t\t\t}\n\t\t\t}\n\n\t\t\tif ( config.context == null || config.context.hasEmptyPath() ) {\n\t\t\t\tif (config.context == null || config.context.isEmpty()) {\n\t\t\t\t\tconfigs.add(config);\n\t\t\t\t\treturn true;\n\t\t\t\t}\n\t\t\t\telse {\n\t\t\t\t\tconfigs.add(new LexerATNConfig(config, config.state, PredictionContext.EMPTY));\n\t\t\t\t\tcurrentAltReachedAcceptState = true;\n\t\t\t\t}\n\t\t\t}\n\n\t\t\tif ( config.context!=null && !config.context.isEmpty() ) {\n\t\t\t\tfor (SingletonPredictionContext ctx : config.context) {\n\t\t\t\t\tif ( !ctx.isEmpty() ) {\n\t\t\t\t\t\tPredictionContext newContext = ctx.parent; // \"pop\" return state\n\t\t\t\t\t\tif ( ctx.returnState==PredictionContext.EMPTY_RETURN_STATE ) {\n\t\t\t\t\t\t\t// we have no context info. Don't pursue but\n\t\t\t\t\t\t\t// record a config that indicates how we hit end\n\t\t\t\t\t\t\tLexerATNConfig c = new LexerATNConfig(config, config.state, ctx);\n\t\t\t\t\t\t\tif ( debug ) System.out.println(\"FALLING off token \"+\n\t\t\t\t\t\t\t\t\t\t\t\t\t\t    recog.getRuleNames()[config.state.ruleIndex]+\n\t\t\t\t\t\t\t\t\t\t\t\t\t\t    \" record \"+c);\n\t\t\t\t\t\t\tconfigs.add(c);\n\t\t\t\t\t\t\tcontinue;\n\t\t\t\t\t\t}\n\t\t\t\t\t\tATNState returnState = atn.states.get(ctx.returnState);\n\t\t\t\t\t\tLexerATNConfig c = new LexerATNConfig(returnState, config.alt, newContext);\n\t\t\t\t\t\tcurrentAltReachedAcceptState = closure(input, c, configs, currentAltReachedAcceptState, speculative);\n\t\t\t\t\t}\n\t\t\t\t}\n\t\t\t}\n\n\t\t\treturn currentAltReachedAcceptState;\n\t\t}\n\n\t\t// optimization\n\t\tif ( !config.state.onlyHasEpsilonTransitions() ) {\n\t\t\tif (!currentAltReachedAcceptState || !config.hasPassedThroughNonGreedyDecision()) {\n\t\t\t\tconfigs.add(config);\n\t\t\t}\n\t\t}\n\n\t\tATNState p = config.state;\n\t\tfor (int i=0; i<p.getNumberOfTransitions(); i++) {\n\t\t\tTransition t = p.transition(i);\n\t\t\tLexerATNConfig c = getEpsilonTarget(input, config, t, configs, speculative);\n\t\t\tif ( c!=null ) {\n\t\t\t\tcurrentAltReachedAcceptState = closure(input, c, configs, currentAltReachedAcceptState, speculative);\n\t\t\t}\n\t\t}\n\n\t\treturn currentAltReachedAcceptState;\n\t}",
        "AfterRefact": "protected boolean closure(@NotNull CharStream input, @NotNull LexerATNConfig config, @NotNull ATNConfigSet configs, boolean currentAltReachedAcceptState, boolean speculative) {\n\t\tif ( debug ) {\n\t\t\tSystem.out.println(\"closure(\"+config.toString(recog, true)+\")\");\n\t\t}\n\n\t\tif ( config.state instanceof RuleStopState ) {\n\t\t\tif ( debug ) {\n\t\t\t\tif ( recog!=null ) {\n\t\t\t\t\tSystem.out.format(Locale.getDefault(), \"closure at %s rule stop %s\\n\", recog.getRuleNames()[config.state.ruleIndex], config);\n\t\t\t\t}\n\t\t\t\telse {\n\t\t\t\t\tSystem.out.format(Locale.getDefault(), \"closure at rule stop %s\\n\", config);\n\t\t\t\t}\n\t\t\t}\n\n\t\t\tif ( config.context == null || config.context.hasEmptyPath() ) {\n\t\t\t\tif (config.context == null || config.context.isEmpty()) {\n\t\t\t\t\tconfigs.add(config);\n\t\t\t\t\treturn true;\n\t\t\t\t}\n\t\t\t\telse {\n\t\t\t\t\tconfigs.add(new LexerATNConfig(config, config.state, PredictionContext.EMPTY));\n\t\t\t\t\tcurrentAltReachedAcceptState = true;\n\t\t\t\t}\n\t\t\t}\n\n\t\t\tif ( config.context!=null && !config.context.isEmpty() ) {\n\t\t\t\tfor (int i = 0; i < config.context.size(); i++) {\n\t\t\t\t\tif (config.context.getReturnState(i) != PredictionContext.EMPTY_RETURN_STATE) {\n\t\t\t\t\t\tPredictionContext newContext = config.context.getParent(i); // \"pop\" return state\n\t\t\t\t\t\tATNState returnState = atn.states.get(config.context.getReturnState(i));\n\t\t\t\t\t\tLexerATNConfig c = new LexerATNConfig(returnState, config.alt, newContext);\n\t\t\t\t\t\tcurrentAltReachedAcceptState = closure(input, c, configs, currentAltReachedAcceptState, speculative);\n\t\t\t\t\t}\n\t\t\t\t}\n\t\t\t}\n\n\t\t\treturn currentAltReachedAcceptState;\n\t\t}\n\n\t\t// optimization\n\t\tif ( !config.state.onlyHasEpsilonTransitions() ) {\n\t\t\tif (!currentAltReachedAcceptState || !config.hasPassedThroughNonGreedyDecision()) {\n\t\t\t\tconfigs.add(config);\n\t\t\t}\n\t\t}\n\n\t\tATNState p = config.state;\n\t\tfor (int i=0; i<p.getNumberOfTransitions(); i++) {\n\t\t\tTransition t = p.transition(i);\n\t\t\tLexerATNConfig c = getEpsilonTarget(input, config, t, configs, speculative);\n\t\t\tif ( c!=null ) {\n\t\t\t\tcurrentAltReachedAcceptState = closure(input, c, configs, currentAltReachedAcceptState, speculative);\n\t\t\t}\n\t\t}\n\n\t\treturn currentAltReachedAcceptState;\n\t}",
        "Extra": ""
    },
    {
        "\ufeffID": "L19910",
        "Parent": "L1833",
        "commitID_before": "ad9bac95199736c270940c4037b7ee7174bacca6",
        "commitID_after": "3468a5fbd868ce63c4cb61782e9baddac2ed24ae",
        "Project": "https://github.com/antlr/antlr4",
        "Type": "INTRODUCE_NULL_OBJECT",
        "Fowler_type": "Introduce Special Case",
        "path_before": "runtime\\Java\\src\\org\\antlr\\v4\\runtime\\atn\\LexerATNSimulator.java",
        "path_after": "runtime\\Java\\src\\org\\antlr\\v4\\runtime\\atn\\LexerATNSimulator.java",
        "name": "boolean closure(CharStream input, LexerATNConfig config, ATNConfigSet configs, boolean currentAltReachedAcceptState, boolean speculative)",
        "LongName": "org.antlr.v4.runtime.atn.LexerATNSimulator.closure(Lorg/antlr/v4/runtime/CharStream;Lorg/antlr/v4/runtime/atn/LexerATNConfig;Lorg/antlr/v4/runtime/atn/ATNConfigSet;ZZ)Z",
        "b_StartLine": "389",
        "b_StartColumn": "2",
        "b_EndLine": "456",
        "b_EndColumn": "3",
        "a_StartLine": "409",
        "a_StartColumn": "2",
        "a_EndLine": "466",
        "a_EndColumn": "3",
        "BeforeRefact": "protected boolean closure(@NotNull CharStream input, @NotNull LexerATNConfig config, @NotNull ATNConfigSet configs, boolean currentAltReachedAcceptState, boolean speculative) {\n\t\tif ( debug ) {\n\t\t\tSystem.out.println(\"closure(\"+config.toString(recog, true)+\")\");\n\t\t}\n\n\t\tif ( config.state instanceof RuleStopState ) {\n\t\t\tif ( debug ) {\n\t\t\t\tif ( recog!=null ) {\n\t\t\t\t\tSystem.out.format(\"closure at %s rule stop %s\\n\", recog.getRuleNames()[config.state.ruleIndex], config);\n\t\t\t\t}\n\t\t\t\telse {\n\t\t\t\t\tSystem.out.format(\"closure at rule stop %s\\n\", config);\n\t\t\t\t}\n\t\t\t}\n\n\t\t\tif ( config.context == null || config.context.hasEmptyPath() ) {\n\t\t\t\tif (config.context == null || config.context.isEmpty()) {\n\t\t\t\t\tconfigs.add(config);\n\t\t\t\t\treturn true;\n\t\t\t\t}\n\t\t\t\telse {\n\t\t\t\t\tconfigs.add(new LexerATNConfig(config, config.state, PredictionContext.EMPTY));\n\t\t\t\t\tcurrentAltReachedAcceptState = true;\n\t\t\t\t}\n\t\t\t}\n\n\t\t\tif ( config.context!=null && !config.context.isEmpty() ) {\n\t\t\t\tfor (SingletonPredictionContext ctx : config.context) {\n\t\t\t\t\tif ( !ctx.isEmpty() ) {\n\t\t\t\t\t\tPredictionContext newContext = ctx.parent; // \"pop\" return state\n\t\t\t\t\t\tif ( ctx.returnState==PredictionContext.EMPTY_RETURN_STATE ) {\n\t\t\t\t\t\t\t// we have no context info. Don't pursue but\n\t\t\t\t\t\t\t// record a config that indicates how we hit end\n\t\t\t\t\t\t\tLexerATNConfig c = new LexerATNConfig(config, config.state, ctx);\n\t\t\t\t\t\t\tif ( debug ) System.out.println(\"FALLING off token \"+\n\t\t\t\t\t\t\t\t\t\t\t\t\t\t    recog.getRuleNames()[config.state.ruleIndex]+\n\t\t\t\t\t\t\t\t\t\t\t\t\t\t    \" record \"+c);\n\t\t\t\t\t\t\tconfigs.add(c);\n\t\t\t\t\t\t\tcontinue;\n\t\t\t\t\t\t}\n\t\t\t\t\t\tATNState returnState = atn.states.get(ctx.returnState);\n\t\t\t\t\t\tLexerATNConfig c = new LexerATNConfig(returnState, config.alt, newContext);\n\t\t\t\t\t\tcurrentAltReachedAcceptState = closure(input, c, configs, currentAltReachedAcceptState, speculative);\n\t\t\t\t\t}\n\t\t\t\t}\n\t\t\t}\n\n\t\t\treturn currentAltReachedAcceptState;\n\t\t}\n\n\t\t// optimization\n\t\tif ( !config.state.onlyHasEpsilonTransitions() ) {\n\t\t\tif (!currentAltReachedAcceptState || !config.hasPassedThroughNonGreedyDecision()) {\n\t\t\t\tconfigs.add(config);\n\t\t\t}\n\t\t}\n\n\t\tATNState p = config.state;\n\t\tfor (int i=0; i<p.getNumberOfTransitions(); i++) {\n\t\t\tTransition t = p.transition(i);\n\t\t\tLexerATNConfig c = getEpsilonTarget(input, config, t, configs, speculative);\n\t\t\tif ( c!=null ) {\n\t\t\t\tcurrentAltReachedAcceptState = closure(input, c, configs, currentAltReachedAcceptState, speculative);\n\t\t\t}\n\t\t}\n\n\t\treturn currentAltReachedAcceptState;\n\t}",
        "AfterRefact": "protected boolean closure(@NotNull CharStream input, @NotNull LexerATNConfig config, @NotNull ATNConfigSet configs, boolean currentAltReachedAcceptState, boolean speculative) {\n\t\tif ( debug ) {\n\t\t\tSystem.out.println(\"closure(\"+config.toString(recog, true)+\")\");\n\t\t}\n\n\t\tif ( config.state instanceof RuleStopState ) {\n\t\t\tif ( debug ) {\n\t\t\t\tif ( recog!=null ) {\n\t\t\t\t\tSystem.out.format(Locale.getDefault(), \"closure at %s rule stop %s\\n\", recog.getRuleNames()[config.state.ruleIndex], config);\n\t\t\t\t}\n\t\t\t\telse {\n\t\t\t\t\tSystem.out.format(Locale.getDefault(), \"closure at rule stop %s\\n\", config);\n\t\t\t\t}\n\t\t\t}\n\n\t\t\tif ( config.context == null || config.context.hasEmptyPath() ) {\n\t\t\t\tif (config.context == null || config.context.isEmpty()) {\n\t\t\t\t\tconfigs.add(config);\n\t\t\t\t\treturn true;\n\t\t\t\t}\n\t\t\t\telse {\n\t\t\t\t\tconfigs.add(new LexerATNConfig(config, config.state, PredictionContext.EMPTY));\n\t\t\t\t\tcurrentAltReachedAcceptState = true;\n\t\t\t\t}\n\t\t\t}\n\n\t\t\tif ( config.context!=null && !config.context.isEmpty() ) {\n\t\t\t\tfor (int i = 0; i < config.context.size(); i++) {\n\t\t\t\t\tif (config.context.getReturnState(i) != PredictionContext.EMPTY_RETURN_STATE) {\n\t\t\t\t\t\tPredictionContext newContext = config.context.getParent(i); // \"pop\" return state\n\t\t\t\t\t\tATNState returnState = atn.states.get(config.context.getReturnState(i));\n\t\t\t\t\t\tLexerATNConfig c = new LexerATNConfig(returnState, config.alt, newContext);\n\t\t\t\t\t\tcurrentAltReachedAcceptState = closure(input, c, configs, currentAltReachedAcceptState, speculative);\n\t\t\t\t\t}\n\t\t\t\t}\n\t\t\t}\n\n\t\t\treturn currentAltReachedAcceptState;\n\t\t}\n\n\t\t// optimization\n\t\tif ( !config.state.onlyHasEpsilonTransitions() ) {\n\t\t\tif (!currentAltReachedAcceptState || !config.hasPassedThroughNonGreedyDecision()) {\n\t\t\t\tconfigs.add(config);\n\t\t\t}\n\t\t}\n\n\t\tATNState p = config.state;\n\t\tfor (int i=0; i<p.getNumberOfTransitions(); i++) {\n\t\t\tTransition t = p.transition(i);\n\t\t\tLexerATNConfig c = getEpsilonTarget(input, config, t, configs, speculative);\n\t\t\tif ( c!=null ) {\n\t\t\t\tcurrentAltReachedAcceptState = closure(input, c, configs, currentAltReachedAcceptState, speculative);\n\t\t\t}\n\t\t}\n\n\t\treturn currentAltReachedAcceptState;\n\t}",
        "Extra": ""
    },
    {
        "\ufeffID": "L2113",
        "Parent": "L981",
        "commitID_before": "ad9bac95199736c270940c4037b7ee7174bacca6",
        "commitID_after": "3468a5fbd868ce63c4cb61782e9baddac2ed24ae",
        "Project": "https://github.com/antlr/antlr4",
        "Type": "REPLACE_NESTED_COND_WITH_GUARD_CLAUSES",
        "Fowler_type": "Replace Nested Conditional with Guard Clauses",
        "path_before": "runtime\\Java\\src\\org\\antlr\\v4\\runtime\\atn\\LL1Analyzer.java",
        "path_after": "runtime\\Java\\src\\org\\antlr\\v4\\runtime\\atn\\LL1Analyzer.java",
        "name": "void _LOOK(ATNState s, ATNState stopState, PredictionContext ctx, IntervalSet look, Set<ATNConfig> lookBusy, BitSet calledRuleStack, boolean seeThruPreds, boolean addEOF)",
        "LongName": "org.antlr.v4.runtime.atn.LL1Analyzer._LOOK(Lorg/antlr/v4/runtime/atn/ATNState;Lorg/antlr/v4/runtime/atn/ATNState;Lorg/antlr/v4/runtime/atn/PredictionContext;Lorg/antlr/v4/runtime/misc/IntervalSet;Ljava/util/Set;Ljava/util/BitSet;ZZ)V",
        "b_StartLine": "104",
        "b_StartColumn": "2",
        "b_EndLine": "167",
        "b_EndColumn": "3",
        "a_StartLine": "166",
        "a_StartColumn": "5",
        "a_EndLine": "262",
        "a_EndColumn": "3",
        "BeforeRefact": "protected void _LOOK(@NotNull ATNState s, @Nullable PredictionContext ctx,\n\t\t\t\t\t\t @NotNull IntervalSet look,\n                         @NotNull Set<ATNConfig> lookBusy,\n\t\t\t\t\t\t boolean seeThruPreds, boolean addEOF)\n\t{\n//\t\tSystem.out.println(\"_LOOK(\"+s.stateNumber+\", ctx=\"+ctx);\n        ATNConfig c = new ATNConfig(s, 0, ctx);\n        if ( !lookBusy.add(c) ) return;\n\n        if ( s instanceof RuleStopState ) {\n            if ( ctx==null ) {\n                look.add(Token.EPSILON);\n                return;\n            } else if (ctx.isEmpty() && addEOF) {\n\t\t\t\tlook.add(Token.EOF);\n\t\t\t\treturn;\n\t\t\t}\n\n\t\t\tif ( ctx != PredictionContext.EMPTY ) {\n\t\t\t\t// run thru all possible stack tops in ctx\n\t\t\t\tfor (SingletonPredictionContext p : ctx) {\n\t\t\t\t\tATNState returnState = atn.states.get(p.returnState);\n//\t\t\t\t\tSystem.out.println(\"popping back to \"+retState);\n\t\t\t\t\t_LOOK(returnState, p.parent, look, lookBusy, seeThruPreds, addEOF);\n\t\t\t\t}\n\t\t\t\treturn;\n\t\t\t}\n        }\n\n        int n = s.getNumberOfTransitions();\n        for (int i=0; i<n; i++) {\n\t\t\tTransition t = s.transition(i);\n\t\t\tif ( t.getClass() == RuleTransition.class ) {\n\t\t\t\tPredictionContext newContext =\n\t\t\t\t\tSingletonPredictionContext.create(ctx, ((RuleTransition)t).followState.stateNumber);\n\t\t\t\t_LOOK(t.target, newContext, look, lookBusy, seeThruPreds, addEOF);\n\t\t\t}\n\t\t\telse if ( t instanceof PredicateTransition ) {\n\t\t\t\tif ( seeThruPreds ) {\n\t\t\t\t\t_LOOK(t.target, ctx, look, lookBusy, seeThruPreds, addEOF);\n\t\t\t\t}\n\t\t\t\telse {\n\t\t\t\t\tlook.add(HIT_PRED);\n\t\t\t\t}\n\t\t\t}\n\t\t\telse if ( t.isEpsilon() ) {\n\t\t\t\t_LOOK(t.target, ctx, look, lookBusy, seeThruPreds, addEOF);\n\t\t\t}\n\t\t\telse if ( t.getClass() == WildcardTransition.class ) {\n\t\t\t\tlook.addAll( IntervalSet.of(Token.MIN_USER_TOKEN_TYPE, atn.maxTokenType) );\n\t\t\t}\n\t\t\telse {\n//\t\t\t\tSystem.out.println(\"adding \"+ t);\n\t\t\t\tIntervalSet set = t.label();\n\t\t\t\tif (set != null) {\n\t\t\t\t\tif (t instanceof NotSetTransition) {\n\t\t\t\t\t\tset = set.complement(IntervalSet.of(Token.MIN_USER_TOKEN_TYPE, atn.maxTokenType));\n\t\t\t\t\t}\n\t\t\t\t\tlook.addAll(set);\n\t\t\t\t}\n\t\t\t}\n\t\t}\n\t}\n}",
        "AfterRefact": "protected void _LOOK(@NotNull ATNState s,\n\t\t\t\t\t\t @Nullable ATNState stopState,\n\t\t\t\t\t\t @Nullable PredictionContext ctx,\n\t\t\t\t\t\t @NotNull IntervalSet look,\n                         @NotNull Set<ATNConfig> lookBusy,\n\t\t\t\t\t\t @NotNull BitSet calledRuleStack,\n\t\t\t\t\t\t boolean seeThruPreds, boolean addEOF)\n\t{\n//\t\tSystem.out.println(\"_LOOK(\"+s.stateNumber+\", ctx=\"+ctx);\n        ATNConfig c = new ATNConfig(s, 0, ctx);\n        if ( !lookBusy.add(c) ) return;\n\n\t\tif (s == stopState) {\n\t\t\tif (ctx == null) {\n\t\t\t\tlook.add(Token.EPSILON);\n\t\t\t\treturn;\n\t\t\t} else if (ctx.isEmpty() && addEOF) {\n\t\t\t\tlook.add(Token.EOF);\n\t\t\t\treturn;\n\t\t\t}\n\t\t}\n\n        if ( s instanceof RuleStopState ) {\n            if ( ctx==null ) {\n                look.add(Token.EPSILON);\n                return;\n            } else if (ctx.isEmpty() && addEOF) {\n\t\t\t\tlook.add(Token.EOF);\n\t\t\t\treturn;\n\t\t\t}\n\n\t\t\tif ( ctx != PredictionContext.EMPTY ) {\n\t\t\t\t// run thru all possible stack tops in ctx\n\t\t\t\tfor (int i = 0; i < ctx.size(); i++) {\n\t\t\t\t\tATNState returnState = atn.states.get(ctx.getReturnState(i));\n//\t\t\t\t\tSystem.out.println(\"popping back to \"+retState);\n\n\t\t\t\t\tboolean removed = calledRuleStack.get(returnState.ruleIndex);\n\t\t\t\t\ttry {\n\t\t\t\t\t\tcalledRuleStack.clear(returnState.ruleIndex);\n\t\t\t\t\t\t_LOOK(returnState, stopState, ctx.getParent(i), look, lookBusy, calledRuleStack, seeThruPreds, addEOF);\n\t\t\t\t\t}\n\t\t\t\t\tfinally {\n\t\t\t\t\t\tif (removed) {\n\t\t\t\t\t\t\tcalledRuleStack.set(returnState.ruleIndex);\n\t\t\t\t\t\t}\n\t\t\t\t\t}\n\t\t\t\t}\n\t\t\t\treturn;\n\t\t\t}\n        }\n\n        int n = s.getNumberOfTransitions();\n        for (int i=0; i<n; i++) {\n\t\t\tTransition t = s.transition(i);\n\t\t\tif ( t.getClass() == RuleTransition.class ) {\n\t\t\t\tif (calledRuleStack.get(((RuleTransition)t).target.ruleIndex)) {\n\t\t\t\t\tcontinue;\n\t\t\t\t}\n\n\t\t\t\tPredictionContext newContext =\n\t\t\t\t\tSingletonPredictionContext.create(ctx, ((RuleTransition)t).followState.stateNumber);\n\n\t\t\t\ttry {\n\t\t\t\t\tcalledRuleStack.set(((RuleTransition)t).target.ruleIndex);\n\t\t\t\t\t_LOOK(t.target, stopState, newContext, look, lookBusy, calledRuleStack, seeThruPreds, addEOF);\n\t\t\t\t}\n\t\t\t\tfinally {\n\t\t\t\t\tcalledRuleStack.clear(((RuleTransition)t).target.ruleIndex);\n\t\t\t\t}\n\t\t\t}\n\t\t\telse if ( t instanceof PredicateTransition ) {\n\t\t\t\tif ( seeThruPreds ) {\n\t\t\t\t\t_LOOK(t.target, stopState, ctx, look, lookBusy, calledRuleStack, seeThruPreds, addEOF);\n\t\t\t\t}\n\t\t\t\telse {\n\t\t\t\t\tlook.add(HIT_PRED);\n\t\t\t\t}\n\t\t\t}\n\t\t\telse if ( t.isEpsilon() ) {\n\t\t\t\t_LOOK(t.target, stopState, ctx, look, lookBusy, calledRuleStack, seeThruPreds, addEOF);\n\t\t\t}\n\t\t\telse if ( t.getClass() == WildcardTransition.class ) {\n\t\t\t\tlook.addAll( IntervalSet.of(Token.MIN_USER_TOKEN_TYPE, atn.maxTokenType) );\n\t\t\t}\n\t\t\telse {\n//\t\t\t\tSystem.out.println(\"adding \"+ t);\n\t\t\t\tIntervalSet set = t.label();\n\t\t\t\tif (set != null) {\n\t\t\t\t\tif (t instanceof NotSetTransition) {\n\t\t\t\t\t\tset = set.complement(IntervalSet.of(Token.MIN_USER_TOKEN_TYPE, atn.maxTokenType));\n\t\t\t\t\t}\n\t\t\t\t\tlook.addAll(set);\n\t\t\t\t}\n\t\t\t}\n\t\t}\n\t}\n}",
        "Extra": ""
    },
    {
        "\ufeffID": "L2427",
        "Parent": "L2178",
        "commitID_before": "ad9bac95199736c270940c4037b7ee7174bacca6",
        "commitID_after": "3468a5fbd868ce63c4cb61782e9baddac2ed24ae",
        "Project": "https://github.com/antlr/antlr4",
        "Type": "REPLACE_NESTED_COND_WITH_GUARD_CLAUSES",
        "Fowler_type": "Replace Nested Conditional with Guard Clauses",
        "path_before": "runtime\\Java\\src\\org\\antlr\\v4\\runtime\\atn\\ParserATNSimulator.java",
        "path_after": "runtime\\Java\\src\\org\\antlr\\v4\\runtime\\atn\\ParserATNSimulator.java",
        "name": "void closure_(ATNConfig config, ATNConfigSet configs, Set<ATNConfig> closureBusy, boolean collectPredicates, boolean fullCtx, int depth)",
        "LongName": "org.antlr.v4.runtime.atn.ParserATNSimulator.closure_(Lorg/antlr/v4/runtime/atn/ATNConfig;Lorg/antlr/v4/runtime/atn/ATNConfigSet;Ljava/util/Set;ZZI)V",
        "b_StartLine": "1283",
        "b_StartColumn": "2",
        "b_EndLine": "1329",
        "b_EndColumn": "3",
        "a_StartLine": "1116",
        "a_StartColumn": "2",
        "a_EndLine": "1168",
        "a_EndColumn": "3",
        "BeforeRefact": "protected void closure_(@NotNull ATNConfig config,\n\t\t\t\t\t\t\t@NotNull ATNConfigSet configs,\n\t\t\t\t\t\t\t@NotNull Set<ATNConfig> closureBusy,\n\t\t\t\t\t\t\tboolean collectPredicates,\n\t\t\t\t\t\t\tboolean fullCtx,\n\t\t\t\t\t\t\tint depth)\n\t{\n\t\tATNState p = config.state;\n\t\t// optimization\n\t\tif ( !p.onlyHasEpsilonTransitions() ) {\n            configs.add(config, mergeCache);\n//            if ( debug ) System.out.println(\"added config \"+configs);\n        }\n\n\t\tfor (int i=0; i<p.getNumberOfTransitions(); i++) {\n\t\t\tTransition t = p.transition(i);\n\t\t\tboolean continueCollecting =\n\t\t\t\t!(t instanceof ActionTransition) && collectPredicates;\n\t\t\tATNConfig c = getEpsilonTarget(config, t, continueCollecting,\n\t\t\t\t\t\t\t\t\t\t   depth == 0, fullCtx);\n\t\t\tif ( c!=null ) {\n\t\t\t\tint newDepth = depth;\n\t\t\t\tif ( config.state instanceof RuleStopState) {\n\t\t\t\t\tassert !fullCtx;\n\t\t\t\t\t// target fell off end of rule; mark resulting c as having dipped into outer context\n\t\t\t\t\t// We can't get here if incoming config was rule stop and we had context\n\t\t\t\t\t// track how far we dip into outer context.  Might\n\t\t\t\t\t// come in handy and we avoid evaluating context dependent\n\t\t\t\t\t// preds if this is > 0.\n\t\t\t\t\tc.reachesIntoOuterContext++;\n\t\t\t\t\tconfigs.dipsIntoOuterContext = true; // TODO: can remove? only care when we add to set per middle of this method\n\t\t\t\t\tassert newDepth > Integer.MIN_VALUE;\n\t\t\t\t\tnewDepth--;\n\t\t\t\t\tif ( debug ) System.out.println(\"dips into outer ctx: \"+c);\n\t\t\t\t}\n\t\t\t\telse if (t instanceof RuleTransition) {\n\t\t\t\t\t// latch when newDepth goes negative - once we step out of the entry context we can't return\n\t\t\t\t\tif (newDepth >= 0) {\n\t\t\t\t\t\tnewDepth++;\n\t\t\t\t\t}\n\t\t\t\t}\n\n\t\t\t\tclosureCheckingStopState(c, configs, closureBusy, continueCollecting,\n\t\t\t\t\t\t\t\t\t\t fullCtx, newDepth);\n\t\t\t}\n\t\t}\n\t}",
        "AfterRefact": "protected void closure_(@NotNull ATNConfig config,\n\t\t\t\t\t\t\t@NotNull ATNConfigSet configs,\n\t\t\t\t\t\t\t@NotNull Set<ATNConfig> closureBusy,\n\t\t\t\t\t\t\tboolean collectPredicates,\n\t\t\t\t\t\t\tboolean fullCtx,\n\t\t\t\t\t\t\tint depth)\n\t{\n\t\tATNState p = config.state;\n\t\t// optimization\n\t\tif ( !p.onlyHasEpsilonTransitions() ) {\n            configs.add(config, mergeCache);\n//            if ( debug ) System.out.println(\"added config \"+configs);\n        }\n\n\t\tfor (int i=0; i<p.getNumberOfTransitions(); i++) {\n\t\t\tTransition t = p.transition(i);\n\t\t\tboolean continueCollecting =\n\t\t\t\t!(t instanceof ActionTransition) && collectPredicates;\n\t\t\tATNConfig c = getEpsilonTarget(config, t, continueCollecting,\n\t\t\t\t\t\t\t\t\t\t   depth == 0, fullCtx);\n\t\t\tif ( c!=null ) {\n\t\t\t\tint newDepth = depth;\n\t\t\t\tif ( config.state instanceof RuleStopState) {\n\t\t\t\t\tassert !fullCtx;\n\t\t\t\t\t// target fell off end of rule; mark resulting c as having dipped into outer context\n\t\t\t\t\t// We can't get here if incoming config was rule stop and we had context\n\t\t\t\t\t// track how far we dip into outer context.  Might\n\t\t\t\t\t// come in handy and we avoid evaluating context dependent\n\t\t\t\t\t// preds if this is > 0.\n\n\t\t\t\t\tif (!closureBusy.add(c)) {\n\t\t\t\t\t\t// avoid infinite recursion for right-recursive rules\n\t\t\t\t\t\tcontinue;\n\t\t\t\t\t}\n\n\t\t\t\t\tc.reachesIntoOuterContext++;\n\t\t\t\t\tconfigs.dipsIntoOuterContext = true; // TODO: can remove? only care when we add to set per middle of this method\n\t\t\t\t\tassert newDepth > Integer.MIN_VALUE;\n\t\t\t\t\tnewDepth--;\n\t\t\t\t\tif ( debug ) System.out.println(\"dips into outer ctx: \"+c);\n\t\t\t\t}\n\t\t\t\telse if (t instanceof RuleTransition) {\n\t\t\t\t\t// latch when newDepth goes negative - once we step out of the entry context we can't return\n\t\t\t\t\tif (newDepth >= 0) {\n\t\t\t\t\t\tnewDepth++;\n\t\t\t\t\t}\n\t\t\t\t}\n\n\t\t\t\tclosureCheckingStopState(c, configs, closureBusy, continueCollecting,\n\t\t\t\t\t\t\t\t\t\t fullCtx, newDepth);\n\t\t\t}\n\t\t}\n\t}",
        "Extra": ""
    },
    {
        "\ufeffID": "L9795",
        "Parent": "L9790",
        "commitID_before": "ad9bac95199736c270940c4037b7ee7174bacca6",
        "commitID_after": "3468a5fbd868ce63c4cb61782e9baddac2ed24ae",
        "Project": "https://github.com/antlr/antlr4",
        "Type": "CONSOLIDATE_DUPLICATE_COND_FRAGMENTS",
        "Fowler_type": "Slide Statements",
        "path_before": "tool\\src\\org\\antlr\\v4\\codegen\\model\\InvokeRule.java",
        "path_after": "tool\\src\\org\\antlr\\v4\\codegen\\model\\InvokeRule.java",
        "name": "InvokeRule(ParserFactory factory, GrammarAST ast, GrammarAST labelAST)",
        "LongName": "org.antlr.v4.codegen.model.InvokeRule.<init>(Lorg/antlr/v4/codegen/ParserFactory;Lorg/antlr/v4/tool/ast/GrammarAST;Lorg/antlr/v4/tool/ast/GrammarAST;)V",
        "b_StartLine": "57",
        "b_StartColumn": "2",
        "b_EndLine": "98",
        "b_EndColumn": "3",
        "a_StartLine": "57",
        "a_StartColumn": "2",
        "a_EndLine": "98",
        "a_EndColumn": "3",
        "BeforeRefact": "public InvokeRule(ParserFactory factory, GrammarAST ast, GrammarAST labelAST) {\n\t\tsuper(factory, ast);\n\t\tif ( ast.atnState!=null ) {\n\t\t\tRuleTransition ruleTrans = (RuleTransition)ast.atnState.transition(0);\n\t\t\tstateNumber = ast.atnState.stateNumber;\n\t\t}\n\n\t\tthis.name = ast.getText();\n\t\tCodeGenerator gen = factory.getGenerator();\n\t\tRule r = factory.getGrammar().getRule(name);\n\t\tctxName = gen.target.getRuleFunctionContextStructName(r);\n\n\t\t// TODO: move to factory\n\t\tRuleFunction rf = factory.getCurrentRuleFunction();\n\t\tif ( labelAST!=null ) {\n\t\t\t// for x=r, define <rule-context-type> x and list_x\n\t\t\tString label = labelAST.getText();\n\t\t\tif ( labelAST.parent.getType() == ANTLRParser.PLUS_ASSIGN  ) {\n\t\t\t\tfactory.defineImplicitLabel(ast, this);\n\t\t\t\tString listLabel = gen.target.getListLabel(label);\n\t\t\t\tRuleContextListDecl l = new RuleContextListDecl(factory, listLabel, ctxName);\n\t\t\t\trf.addContextDecl(ast.getAltLabel(), l);\n\t\t\t}\n\t\t\telse {\n\t\t\t\tRuleContextDecl d = new RuleContextDecl(factory,label,ctxName);\n\t\t\t\tlabels.add(d);\n\t\t\t\trf.addContextDecl(ast.getAltLabel(), d);\n\t\t\t}\n\t\t}\n\t\tif ( ast.getChildCount()>0 ) {\n\t\t\tActionAST arg = (ActionAST)ast.getChild(0);\n\t\t\targExprsChunks = ActionTranslator.translateAction(factory, rf, arg.token, arg);\n\t\t}\n\n\t\t// If action refs rule as rulename not label, we need to define implicit label\n\t\tif ( factory.getCurrentOuterMostAlt().ruleRefsInActions.containsKey(ast.getText()) ) {\n\t\t\tString label = gen.target.getImplicitRuleLabel(ast.getText());\n\t\t\tRuleContextDecl d = new RuleContextDecl(factory,label,ctxName);\n\t\t\tlabels.add(d);\n\t\t\trf.addContextDecl(ast.getAltLabel(), d);\n\t\t}\n\t}",
        "AfterRefact": "public InvokeRule(ParserFactory factory, GrammarAST ast, GrammarAST labelAST) {\n\t\tsuper(factory, ast);\n\t\tif ( ast.atnState!=null ) {\n\t\t\tRuleTransition ruleTrans = (RuleTransition)ast.atnState.transition(0);\n\t\t\tstateNumber = ast.atnState.stateNumber;\n\t\t}\n\n\t\tthis.name = ast.getText();\n\t\tCodeGenerator gen = factory.getGenerator();\n\t\tRule r = factory.getGrammar().getRule(name);\n\t\tctxName = gen.getTarget().getRuleFunctionContextStructName(r);\n\n\t\t// TODO: move to factory\n\t\tRuleFunction rf = factory.getCurrentRuleFunction();\n\t\tif ( labelAST!=null ) {\n\t\t\t// for x=r, define <rule-context-type> x and list_x\n\t\t\tString label = labelAST.getText();\n\t\t\tif ( labelAST.parent.getType() == ANTLRParser.PLUS_ASSIGN  ) {\n\t\t\t\tfactory.defineImplicitLabel(ast, this);\n\t\t\t\tString listLabel = gen.getTarget().getListLabel(label);\n\t\t\t\tRuleContextListDecl l = new RuleContextListDecl(factory, listLabel, ctxName);\n\t\t\t\trf.addContextDecl(ast.getAltLabel(), l);\n\t\t\t}\n\t\t\telse {\n\t\t\t\tRuleContextDecl d = new RuleContextDecl(factory,label,ctxName);\n\t\t\t\tlabels.add(d);\n\t\t\t\trf.addContextDecl(ast.getAltLabel(), d);\n\t\t\t}\n\t\t}\n\t\tif ( ast.getChildCount()>0 ) {\n\t\t\tActionAST arg = (ActionAST)ast.getChild(0);\n\t\t\targExprsChunks = ActionTranslator.translateAction(factory, rf, arg.token, arg);\n\t\t}\n\n\t\t// If action refs rule as rulename not label, we need to define implicit label\n\t\tif ( factory.getCurrentOuterMostAlt().ruleRefsInActions.containsKey(ast.getText()) ) {\n\t\t\tString label = gen.getTarget().getImplicitRuleLabel(ast.getText());\n\t\t\tRuleContextDecl d = new RuleContextDecl(factory,label,ctxName);\n\t\t\tlabels.add(d);\n\t\t\trf.addContextDecl(ast.getAltLabel(), d);\n\t\t}\n\t}",
        "Extra": ""
    },
    {
        "\ufeffID": "L9861",
        "Parent": "L8698",
        "commitID_before": "ad9bac95199736c270940c4037b7ee7174bacca6",
        "commitID_after": "3468a5fbd868ce63c4cb61782e9baddac2ed24ae",
        "Project": "https://github.com/antlr/antlr4",
        "Type": "REPLACE_NESTED_COND_WITH_GUARD_CLAUSES",
        "Fowler_type": "Slide Statements",
        "path_before": "tool\\src\\org\\antlr\\v4\\codegen\\model\\Lexer.java",
        "path_after": "tool\\src\\org\\antlr\\v4\\codegen\\model\\Lexer.java",
        "name": "Lexer(OutputModelFactory factory, LexerFile file)",
        "LongName": "org.antlr.v4.codegen.model.Lexer.<init>(Lorg/antlr/v4/codegen/OutputModelFactory;Lorg/antlr/v4/codegen/model/LexerFile;)V",
        "b_StartLine": "64",
        "b_StartColumn": "2",
        "b_EndLine": "104",
        "b_EndColumn": "3",
        "a_StartLine": "64",
        "a_StartColumn": "2",
        "a_EndLine": "104",
        "a_EndColumn": "3",
        "BeforeRefact": "public Lexer(OutputModelFactory factory, LexerFile file) {\n\t\tthis.factory = factory;\n\t\tthis.file = file; // who contains us?\n\t\tGrammar g = factory.getGrammar();\n\t\tgrammarFileName = new File(g.fileName).getName();\n\t\tname = g.getRecognizerName();\n\t\ttokens = new LinkedHashMap<String,Integer>();\n\t\tLexerGrammar lg = (LexerGrammar)g;\n\t\tatn = new SerializedATN(factory, lg.atn);\n\t\tmodes = lg.modes.keySet();\n\n\t\tfor (String t : g.tokenNameToTypeMap.keySet()) {\n\t\t\tInteger ttype = g.tokenNameToTypeMap.get(t);\n\t\t\tif ( ttype>0 ) tokens.put(t, ttype);\n\t\t}\n\n\t\ttokenNames = g.getTokenDisplayNames();\n        for (int i = 0; i < tokenNames.length; i++) {\n            if ( tokenNames[i]==null ) continue;\n            CodeGenerator gen = factory.getGenerator();\n            if ( tokenNames[i].charAt(0)=='\\'' ) {\n\t\t\t\tboolean addQuotes = false;\n\t\t\t\ttokenNames[i] =\n\t\t\t\t\tgen.target.getTargetStringLiteralFromANTLRStringLiteral(gen,\n\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\ttokenNames[i],\n\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\taddQuotes);\n\t\t\t\ttokenNames[i] = \"\\\"'\"+tokenNames[i]+\"'\\\"\";\n            }\n            else {\n                tokenNames[i] = gen.target.getTargetStringLiteralFromString(tokenNames[i], true);\n            }\n        }\n\t\truleNames = g.rules.keySet();\n\n\t\tif (g.getOptionString(\"superClass\") != null) {\n\t\t\tsuperClass = new ActionText(null, g.getOptionString(\"superClass\"));\n\t\t}\n\t\telse {\n\t\t\tsuperClass = new DefaultLexerSuperClass();\n\t\t}\n\t}\n\n}",
        "AfterRefact": "public Lexer(OutputModelFactory factory, LexerFile file) {\n\t\tthis.factory = factory;\n\t\tthis.file = file; // who contains us?\n\t\tGrammar g = factory.getGrammar();\n\t\tgrammarFileName = new File(g.fileName).getName();\n\t\tname = g.getRecognizerName();\n\t\ttokens = new LinkedHashMap<String,Integer>();\n\t\tLexerGrammar lg = (LexerGrammar)g;\n\t\tatn = new SerializedATN(factory, lg.atn);\n\t\tmodes = lg.modes.keySet();\n\n\t\tfor (String t : g.tokenNameToTypeMap.keySet()) {\n\t\t\tInteger ttype = g.tokenNameToTypeMap.get(t);\n\t\t\tif ( ttype>0 ) tokens.put(t, ttype);\n\t\t}\n\n\t\ttokenNames = g.getTokenDisplayNames();\n        for (int i = 0; i < tokenNames.length; i++) {\n            if ( tokenNames[i]==null ) continue;\n            CodeGenerator gen = factory.getGenerator();\n            if ( tokenNames[i].charAt(0)=='\\'' ) {\n\t\t\t\tboolean addQuotes = false;\n\t\t\t\ttokenNames[i] =\n\t\t\t\t\tgen.getTarget().getTargetStringLiteralFromANTLRStringLiteral(gen,\n\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\ttokenNames[i],\n\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\taddQuotes);\n\t\t\t\ttokenNames[i] = \"\\\"'\"+tokenNames[i]+\"'\\\"\";\n            }\n            else {\n                tokenNames[i] = gen.getTarget().getTargetStringLiteralFromString(tokenNames[i], true);\n            }\n        }\n\t\truleNames = g.rules.keySet();\n\n\t\tif (g.getOptionString(\"superClass\") != null) {\n\t\t\tsuperClass = new ActionText(null, g.getOptionString(\"superClass\"));\n\t\t}\n\t\telse {\n\t\t\tsuperClass = new DefaultLexerSuperClass();\n\t\t}\n\t}\n\n}",
        "Extra": ""
    },
    {
        "\ufeffID": "L7413",
        "Parent": "L7392",
        "commitID_before": "ad9bac95199736c270940c4037b7ee7174bacca6",
        "commitID_after": "3468a5fbd868ce63c4cb61782e9baddac2ed24ae",
        "Project": "https://github.com/antlr/antlr4",
        "Type": "INTRODUCE_ASSERTION",
        "Fowler_type": "Introduce Assertion",
        "path_before": "tool\\src\\org\\antlr\\v4\\analysis\\AnalysisPipeline.java",
        "path_after": "tool\\src\\org\\antlr\\v4\\analysis\\AnalysisPipeline.java",
        "name": "void processParser()",
        "LongName": "org.antlr.v4.analysis.AnalysisPipeline.processParser()V",
        "b_StartLine": "82",
        "b_StartColumn": "2",
        "b_EndLine": "99",
        "b_EndColumn": "3",
        "a_StartLine": "82",
        "a_StartColumn": "2",
        "a_EndLine": "101",
        "a_EndColumn": "3",
        "BeforeRefact": "protected void processParser() {\n\t\tg.decisionLOOK = new ArrayList<IntervalSet[]>(g.atn.getNumberOfDecisions()+1);\n\t\tfor (DecisionState s : g.atn.decisionToState) {\n            g.tool.log(\"LL1\", \"\\nDECISION \"+s.decision+\" in rule \"+g.getRule(s.ruleIndex).name);\n\t\t\tIntervalSet[] look;\n\t\t\tif ( s.nonGreedy ) { // nongreedy decisions can't be LL(1)\n\t\t\t\tlook = new IntervalSet[s.getNumberOfTransitions()+1];\n\t\t\t}\n\t\t\telse {\n\t\t\t\tLL1Analyzer anal = new LL1Analyzer(g.atn);\n\t\t\t\tlook = anal.getDecisionLookahead(s);\n\t\t\t\tg.tool.log(\"LL1\", \"look=\" + Arrays.toString(look));\n\t\t\t}\n\t\t\tUtils.setSize(g.decisionLOOK, s.decision+1);\n\t\t\tg.decisionLOOK.set(s.decision, look);\n\t\t\tg.tool.log(\"LL1\", \"LL(1)? \" + disjoint(look));\n\t\t}\n\t}",
        "AfterRefact": "protected void processParser() {\n\t\tg.decisionLOOK = new ArrayList<IntervalSet[]>(g.atn.getNumberOfDecisions()+1);\n\t\tfor (DecisionState s : g.atn.decisionToState) {\n            g.tool.log(\"LL1\", \"\\nDECISION \"+s.decision+\" in rule \"+g.getRule(s.ruleIndex).name);\n\t\t\tIntervalSet[] look;\n\t\t\tif ( s.nonGreedy ) { // nongreedy decisions can't be LL(1)\n\t\t\t\tlook = new IntervalSet[s.getNumberOfTransitions()+1];\n\t\t\t}\n\t\t\telse {\n\t\t\t\tLL1Analyzer anal = new LL1Analyzer(g.atn);\n\t\t\t\tlook = anal.getDecisionLookahead(s);\n\t\t\t\tg.tool.log(\"LL1\", \"look=\" + Arrays.toString(look));\n\t\t\t}\n\n\t\t\tassert s.decision + 1 >= g.decisionLOOK.size();\n\t\t\tUtils.setSize(g.decisionLOOK, s.decision+1);\n\t\t\tg.decisionLOOK.set(s.decision, look);\n\t\t\tg.tool.log(\"LL1\", \"LL(1)? \" + disjoint(look));\n\t\t}\n\t}",
        "Extra": ""
    },
    {
        "\ufeffID": "L25880",
        "Parent": "L832",
        "commitID_before": "ad9bac95199736c270940c4037b7ee7174bacca6",
        "commitID_after": "3468a5fbd868ce63c4cb61782e9baddac2ed24ae",
        "Project": "https://github.com/antlr/antlr4",
        "Type": "REPLACE_MAGIC_NUMBER_WITH_CONSTANT",
        "Fowler_type": "Replace Magic Literal",
        "path_before": "runtime\\Java\\src\\org\\antlr\\v4\\runtime\\atn\\PredictionContext.java",
        "path_after": "runtime\\Java\\src\\org\\antlr\\v4\\runtime\\atn\\PredictionContext.java",
        "name": "int calculateHashCode(PredictionContext parent, int returnState)",
        "LongName": "org.antlr.v4.runtime.atn.PredictionContext.calculateHashCode(Lorg/antlr/v4/runtime/atn/PredictionContext;I)I",
        "b_StartLine": "124",
        "b_StartColumn": "2",
        "b_EndLine": "126",
        "b_EndColumn": "3",
        "a_StartLine": "147",
        "a_StartColumn": "2",
        "a_EndLine": "153",
        "a_EndColumn": "3",
        "BeforeRefact": "protected static int calculateHashCode(int parentHashCode, int returnStateHashCode) {\n\t\treturn 5 * 5 * 7 + 5 * parentHashCode + returnStateHashCode;\n\t}",
        "AfterRefact": "protected static int calculateHashCode(PredictionContext parent, int returnState) {\n\t\tint hash = MurmurHash.initialize(INITIAL_HASH);\n\t\thash = MurmurHash.update(hash, parent);\n\t\thash = MurmurHash.update(hash, returnState);\n\t\thash = MurmurHash.finish(hash, 2);\n\t\treturn hash;\n\t}",
        "Extra": ""
    },
    {
        "\ufeffID": "L3650",
        "Parent": "L1370",
        "commitID_before": "ad9bac95199736c270940c4037b7ee7174bacca6",
        "commitID_after": "3468a5fbd868ce63c4cb61782e9baddac2ed24ae",
        "Project": "https://github.com/antlr/antlr4",
        "Type": "REPLACE_MAGIC_NUMBER_WITH_CONSTANT",
        "Fowler_type": "Replace Magic Literal",
        "path_before": "runtime\\Java\\src\\org\\antlr\\v4\\runtime\\dfa\\DFAState.java",
        "path_after": "runtime\\Java\\src\\org\\antlr\\v4\\runtime\\dfa\\DFAState.java",
        "name": "int hashCode()",
        "LongName": "org.antlr.v4.runtime.dfa.DFAState.hashCode()I",
        "b_StartLine": "152",
        "b_StartColumn": "2",
        "b_EndLine": "161",
        "b_EndColumn": "3",
        "a_StartLine": "152",
        "a_StartColumn": "2",
        "a_EndLine": "158",
        "a_EndColumn": "3",
        "BeforeRefact": "public int hashCode() {\n\t\tint h = 7;\n\t\tif ( configs!=null ) {\n\t\t\tfor (ATNConfig c : configs) {\n\t\t\t\th = h * 31 ^ c.alt;\n\t\t\t\th = h * 31 ^ c.state.stateNumber;\n\t\t\t}\n\t\t}\n\t\treturn h;\n\t}",
        "AfterRefact": "public int hashCode() {\n\t\tint hash = MurmurHash.initialize(7);\n\t\thash = MurmurHash.update(hash, configs.hashCode());\n\t\thash = MurmurHash.finish(hash, 1);\n\t\treturn hash;\n\t}",
        "Extra": ""
    },
    {
        "\ufeffID": "L2093",
        "Parent": "L1307",
        "commitID_before": "3468a5fbd868ce63c4cb61782e9baddac2ed24ae",
        "commitID_after": "5e05b71e8b1cd52cf0e77559786cc4c18dc85c37",
        "Project": "https://github.com/antlr/antlr4",
        "Type": "REPLACE_METHOD_WITH_METHOD_OBJECT",
        "Fowler_type": "Replace Function with Command",
        "path_before": "runtime\\Java\\src\\org\\antlr\\v4\\runtime\\atn\\ATNSimulator.java",
        "path_after": "runtime\\Java\\src\\org\\antlr\\v4\\runtime\\atn\\ATNSimulator.java",
        "name": "ATNState stateFactory(int type, int ruleIndex)",
        "LongName": "org.antlr.v4.runtime.atn.ATNSimulator.stateFactory(II)Lorg/antlr/v4/runtime/atn/ATNState;",
        "b_StartLine": "478",
        "b_StartColumn": "2",
        "b_EndLine": "501",
        "b_EndColumn": "3",
        "a_StartLine": "191",
        "a_StartColumn": "2",
        "a_EndLine": "194",
        "a_EndColumn": "3",
        "BeforeRefact": "public static ATNState stateFactory(int type, int ruleIndex) {\n\t\tATNState s;\n\t\tswitch (type) {\n\t\t\tcase ATNState.INVALID_TYPE: return null;\n\t\t\tcase ATNState.BASIC : s = new BasicState(); break;\n\t\t\tcase ATNState.RULE_START : s = new RuleStartState(); break;\n\t\t\tcase ATNState.BLOCK_START : s = new BasicBlockStartState(); break;\n\t\t\tcase ATNState.PLUS_BLOCK_START : s = new PlusBlockStartState(); break;\n\t\t\tcase ATNState.STAR_BLOCK_START : s = new StarBlockStartState(); break;\n\t\t\tcase ATNState.TOKEN_START : s = new TokensStartState(); break;\n\t\t\tcase ATNState.RULE_STOP : s = new RuleStopState(); break;\n\t\t\tcase ATNState.BLOCK_END : s = new BlockEndState(); break;\n\t\t\tcase ATNState.STAR_LOOP_BACK : s = new StarLoopbackState(); break;\n\t\t\tcase ATNState.STAR_LOOP_ENTRY : s = new StarLoopEntryState(); break;\n\t\t\tcase ATNState.PLUS_LOOP_BACK : s = new PlusLoopbackState(); break;\n\t\t\tcase ATNState.LOOP_END : s = new LoopEndState(); break;\n            default :\n\t\t\t\tString message = String.format(Locale.getDefault(), \"The specified state type %d is not valid.\", type);\n\t\t\t\tthrow new IllegalArgumentException(message);\n\t\t}\n\n\t\ts.ruleIndex = ruleIndex;\n\t\treturn s;\n\t}",
        "AfterRefact": "public static ATNState stateFactory(int type, int ruleIndex) {\n\t\treturn new ATNDeserializer().stateFactory(type, ruleIndex);\n\t}",
        "Extra": "public class ATNDeserializer {\nprotected ATNState stateFactory(int type, int ruleIndex) {\n\t\tATNState s;\n\t\tswitch (type) {\n\t\t\tcase ATNState.INVALID_TYPE: return null;\n\t\t\tcase ATNState.BASIC : s = new BasicState(); break;\n\t\t\tcase ATNState.RULE_START : s = new RuleStartState(); break;\n\t\t\tcase ATNState.BLOCK_START : s = new BasicBlockStartState(); break;\n\t\t\tcase ATNState.PLUS_BLOCK_START : s = new PlusBlockStartState(); break;\n\t\t\tcase ATNState.STAR_BLOCK_START : s = new StarBlockStartState(); break;\n\t\t\tcase ATNState.TOKEN_START : s = new TokensStartState(); break;\n\t\t\tcase ATNState.RULE_STOP : s = new RuleStopState(); break;\n\t\t\tcase ATNState.BLOCK_END : s = new BlockEndState(); break;\n\t\t\tcase ATNState.STAR_LOOP_BACK : s = new StarLoopbackState(); break;\n\t\t\tcase ATNState.STAR_LOOP_ENTRY : s = new StarLoopEntryState(); break;\n\t\t\tcase ATNState.PLUS_LOOP_BACK : s = new PlusLoopbackState(); break;\n\t\t\tcase ATNState.LOOP_END : s = new LoopEndState(); break;\n\t\t\tdefault :\n\t\t\t\tString message = String.format(Locale.getDefault(), \"The specified state type %d is not valid.\", type);\n\t\t\t\tthrow new IllegalArgumentException(message);\n\t\t}\n\n\t\ts.ruleIndex = ruleIndex;\n\t\treturn s;\n\t}\n}"
    },
    {
        "\ufeffID": "L2083",
        "Parent": "L1307",
        "commitID_before": "3468a5fbd868ce63c4cb61782e9baddac2ed24ae",
        "commitID_after": "5e05b71e8b1cd52cf0e77559786cc4c18dc85c37",
        "Project": "https://github.com/antlr/antlr4",
        "Type": "REPLACE_METHOD_WITH_METHOD_OBJECT",
        "Fowler_type": "Replace Function with Command",
        "path_before": "runtime\\Java\\src\\org\\antlr\\v4\\runtime\\atn\\ATNSimulator.java",
        "path_after": "runtime\\Java\\src\\org\\antlr\\v4\\runtime\\atn\\ATNSimulator.java",
        "name": "Transition edgeFactory(ATN atn, int type, int src, int trg, int arg1, int arg2, int arg3, List<IntervalSet> sets)",
        "LongName": "org.antlr.v4.runtime.atn.ATNSimulator.edgeFactory(Lorg/antlr/v4/runtime/atn/ATN;IIIIIILjava/util/List;)Lorg/antlr/v4/runtime/atn/Transition;",
        "b_StartLine": "439",
        "b_StartColumn": "2",
        "b_EndLine": "476",
        "b_EndColumn": "3",
        "a_StartLine": "180",
        "a_StartColumn": "2",
        "a_EndLine": "186",
        "a_EndColumn": "3",
        "BeforeRefact": "public static Transition edgeFactory(@NotNull ATN atn,\n\t\t\t\t\t\t\t\t\t\t int type, int src, int trg,\n\t\t\t\t\t\t\t\t\t\t int arg1, int arg2, int arg3,\n\t\t\t\t\t\t\t\t\t\t List<IntervalSet> sets)\n\t{\n\t\tATNState target = atn.states.get(trg);\n\t\tswitch (type) {\n\t\t\tcase Transition.EPSILON : return new EpsilonTransition(target);\n\t\t\tcase Transition.RANGE :\n\t\t\t\tif (arg3 != 0) {\n\t\t\t\t\treturn new RangeTransition(target, Token.EOF, arg2);\n\t\t\t\t}\n\t\t\t\telse {\n\t\t\t\t\treturn new RangeTransition(target, arg1, arg2);\n\t\t\t\t}\n\t\t\tcase Transition.RULE :\n\t\t\t\tRuleTransition rt = new RuleTransition((RuleStartState)atn.states.get(arg1), arg2, target);\n\t\t\t\treturn rt;\n\t\t\tcase Transition.PREDICATE :\n\t\t\t\tPredicateTransition pt = new PredicateTransition(target, arg1, arg2, arg3 != 0);\n\t\t\t\treturn pt;\n\t\t\tcase Transition.ATOM :\n\t\t\t\tif (arg3 != 0) {\n\t\t\t\t\treturn new AtomTransition(target, Token.EOF);\n\t\t\t\t}\n\t\t\t\telse {\n\t\t\t\t\treturn new AtomTransition(target, arg1);\n\t\t\t\t}\n\t\t\tcase Transition.ACTION :\n\t\t\t\tActionTransition a = new ActionTransition(target, arg1, arg2, arg3 != 0);\n\t\t\t\treturn a;\n\t\t\tcase Transition.SET : return new SetTransition(target, sets.get(arg1));\n\t\t\tcase Transition.NOT_SET : return new NotSetTransition(target, sets.get(arg1));\n\t\t\tcase Transition.WILDCARD : return new WildcardTransition(target);\n\t\t}\n\n\t\tthrow new IllegalArgumentException(\"The specified transition type is not valid.\");\n\t}",
        "AfterRefact": "public static Transition edgeFactory(@NotNull ATN atn,\n\t\t\t\t\t\t\t\t\t\t int type, int src, int trg,\n\t\t\t\t\t\t\t\t\t\t int arg1, int arg2, int arg3,\n\t\t\t\t\t\t\t\t\t\t List<IntervalSet> sets)\n\t{\n\t\treturn new ATNDeserializer().edgeFactory(atn, type, src, trg, arg1, arg2, arg3, sets);\n\t}",
        "Extra": "public class ATNDeserializer {\nprotected Transition edgeFactory(@NotNull ATN atn,\n\t\t\t\t\t\t\t\t\t\t int type, int src, int trg,\n\t\t\t\t\t\t\t\t\t\t int arg1, int arg2, int arg3,\n\t\t\t\t\t\t\t\t\t\t List<IntervalSet> sets)\n\t{\n\t\tATNState target = atn.states.get(trg);\n\t\tswitch (type) {\n\t\t\tcase Transition.EPSILON : return new EpsilonTransition(target);\n\t\t\tcase Transition.RANGE :\n\t\t\t\tif (arg3 != 0) {\n\t\t\t\t\treturn new RangeTransition(target, Token.EOF, arg2);\n\t\t\t\t}\n\t\t\t\telse {\n\t\t\t\t\treturn new RangeTransition(target, arg1, arg2);\n\t\t\t\t}\n\t\t\tcase Transition.RULE :\n\t\t\t\tRuleTransition rt = new RuleTransition((RuleStartState)atn.states.get(arg1), arg2, arg3, target);\n\t\t\t\treturn rt;\n\t\t\tcase Transition.PREDICATE :\n\t\t\t\tPredicateTransition pt = new PredicateTransition(target, arg1, arg2, arg3 != 0);\n\t\t\t\treturn pt;\n\t\t\tcase Transition.PRECEDENCE:\n\t\t\t\treturn new PrecedencePredicateTransition(target, arg1);\n\t\t\tcase Transition.ATOM :\n\t\t\t\tif (arg3 != 0) {\n\t\t\t\t\treturn new AtomTransition(target, Token.EOF);\n\t\t\t\t}\n\t\t\t\telse {\n\t\t\t\t\treturn new AtomTransition(target, arg1);\n\t\t\t\t}\n\t\t\tcase Transition.ACTION :\n\t\t\t\tActionTransition a = new ActionTransition(target, arg1, arg2, arg3 != 0);\n\t\t\t\treturn a;\n\t\t\tcase Transition.SET : return new SetTransition(target, sets.get(arg1));\n\t\t\tcase Transition.NOT_SET : return new NotSetTransition(target, sets.get(arg1));\n\t\t\tcase Transition.WILDCARD : return new WildcardTransition(target);\n\t\t}\n\n\t\tthrow new IllegalArgumentException(\"The specified transition type is not valid.\");\n\t}\n}"
    },
    {
        "\ufeffID": "L2079",
        "Parent": "L1307",
        "commitID_before": "3468a5fbd868ce63c4cb61782e9baddac2ed24ae",
        "commitID_after": "5e05b71e8b1cd52cf0e77559786cc4c18dc85c37",
        "Project": "https://github.com/antlr/antlr4",
        "Type": "REPLACE_METHOD_WITH_METHOD_OBJECT",
        "Fowler_type": "Replace Function with Command",
        "path_before": "runtime\\Java\\src\\org\\antlr\\v4\\runtime\\atn\\ATNSimulator.java",
        "path_after": "runtime\\Java\\src\\org\\antlr\\v4\\runtime\\atn\\ATNSimulator.java",
        "name": "UUID toUUID(char[] data, int offset)",
        "LongName": "org.antlr.v4.runtime.atn.ATNSimulator.toUUID([CI)Ljava/util/UUID;",
        "b_StartLine": "432",
        "b_StartColumn": "2",
        "b_EndLine": "436",
        "b_EndColumn": "3",
        "a_StartLine": "171",
        "a_StartColumn": "2",
        "a_EndLine": "173",
        "a_EndColumn": "3",
        "BeforeRefact": "public static UUID toUUID(char[] data, int offset) {\n\t\tlong leastSigBits = toLong(data, offset);\n\t\tlong mostSigBits = toLong(data, offset + 4);\n\t\treturn new UUID(mostSigBits, leastSigBits);\n\t}",
        "AfterRefact": "public static UUID toUUID(char[] data, int offset) {\n\t\treturn ATNDeserializer.toUUID(data, offset);\n\t}",
        "Extra": "protected static UUID toUUID(char[] data, int offset) {\n\t\tlong leastSigBits = toLong(data, offset);\n\t\tlong mostSigBits = toLong(data, offset + 4);\n\t\treturn new UUID(mostSigBits, leastSigBits);\n\t}"
    },
    {
        "\ufeffID": "L2075",
        "Parent": "L1307",
        "commitID_before": "3468a5fbd868ce63c4cb61782e9baddac2ed24ae",
        "commitID_after": "5e05b71e8b1cd52cf0e77559786cc4c18dc85c37",
        "Project": "https://github.com/antlr/antlr4",
        "Type": "REPLACE_METHOD_WITH_METHOD_OBJECT",
        "Fowler_type": "Replace Function with Command",
        "path_before": "runtime\\Java\\src\\org\\antlr\\v4\\runtime\\atn\\ATNSimulator.java",
        "path_after": "runtime\\Java\\src\\org\\antlr\\v4\\runtime\\atn\\ATNSimulator.java",
        "name": "long toLong(char[] data, int offset)",
        "LongName": "org.antlr.v4.runtime.atn.ATNSimulator.toLong([CI)J",
        "b_StartLine": "427",
        "b_StartColumn": "2",
        "b_EndLine": "430",
        "b_EndColumn": "3",
        "a_StartLine": "163",
        "a_StartColumn": "2",
        "a_EndLine": "165",
        "a_EndColumn": "3",
        "BeforeRefact": "public static long toLong(char[] data, int offset) {\n\t\tlong lowOrder = toInt32(data, offset) & 0x00000000FFFFFFFFL;\n\t\treturn lowOrder | ((long)toInt32(data, offset + 2) << 32);\n\t}",
        "AfterRefact": "public static long toLong(char[] data, int offset) {\n\t\treturn ATNDeserializer.toLong(data, offset);\n\t}",
        "Extra": "public class ATNDeserializer {\nprotected static long toLong(char[] data, int offset) {\n\t\tlong lowOrder = toInt32(data, offset) & 0x00000000FFFFFFFFL;\n\t\treturn lowOrder | ((long)toInt32(data, offset + 2) << 32);\n\t}\n}"
    },
    {
        "\ufeffID": "L1276",
        "Parent": "L886",
        "commitID_before": "3468a5fbd868ce63c4cb61782e9baddac2ed24ae",
        "commitID_after": "5e05b71e8b1cd52cf0e77559786cc4c18dc85c37",
        "Project": "https://github.com/antlr/antlr4",
        "Type": "INTRODUCE_ASSERTION",
        "Fowler_type": "Replace Function with Command",
        "path_before": "runtime\\Java\\src\\org\\antlr\\v4\\runtime\\atn\\PredictionContext.java",
        "path_after": "runtime\\Java\\src\\org\\antlr\\v4\\runtime\\atn\\PredictionContext.java",
        "name": "PredictionContext merge(PredictionContext a, PredictionContext b, boolean rootIsWildcard, DoubleKeyMap<PredictionContext, PredictionContext, PredictionContext> mergeCache)",
        "LongName": "org.antlr.v4.runtime.atn.PredictionContext.merge(Lorg/antlr/v4/runtime/atn/PredictionContext;Lorg/antlr/v4/runtime/atn/PredictionContext;ZLorg/antlr/v4/runtime/misc/DoubleKeyMap;)Lorg/antlr/v4/runtime/atn/PredictionContext;",
        "b_StartLine": "171",
        "b_StartColumn": "2",
        "b_EndLine": "201",
        "b_EndColumn": "3",
        "a_StartLine": "169",
        "a_StartColumn": "2",
        "a_EndLine": "201",
        "a_EndColumn": "3",
        "BeforeRefact": "public static PredictionContext merge(\n\t\tPredictionContext a, PredictionContext b,\n\t\tboolean rootIsWildcard,\n\t\tDoubleKeyMap<PredictionContext,PredictionContext,PredictionContext> mergeCache)\n\t{\n\t\t// share same graph if both same\n\t\tif ( (a==null&&b==null) || a==b || (a!=null&&a.equals(b)) ) return a;\n\n\t\tif ( a instanceof SingletonPredictionContext && b instanceof SingletonPredictionContext) {\n\t\t\treturn mergeSingletons((SingletonPredictionContext)a,\n\t\t\t\t\t\t\t\t   (SingletonPredictionContext)b,\n\t\t\t\t\t\t\t\t   rootIsWildcard, mergeCache);\n\t\t}\n\n\t\t// At least one of a or b is array\n\t\t// If one is $ and rootIsWildcard, return $ as * wildcard\n\t\tif ( rootIsWildcard ) {\n\t\t\tif ( a instanceof EmptyPredictionContext ) return a;\n\t\t\tif ( b instanceof EmptyPredictionContext ) return b;\n\t\t}\n\n\t\t// convert singleton so both are arrays to normalize\n\t\tif ( a instanceof SingletonPredictionContext ) {\n\t\t\ta = new ArrayPredictionContext((SingletonPredictionContext)a);\n\t\t}\n\t\tif ( b instanceof SingletonPredictionContext) {\n\t\t\tb = new ArrayPredictionContext((SingletonPredictionContext)b);\n\t\t}\n\t\treturn mergeArrays((ArrayPredictionContext) a, (ArrayPredictionContext) b,\n\t\t\t\t\t\t   rootIsWildcard, mergeCache);\n\t}",
        "AfterRefact": "public static PredictionContext merge(\n\t\tPredictionContext a, PredictionContext b,\n\t\tboolean rootIsWildcard,\n\t\tDoubleKeyMap<PredictionContext,PredictionContext,PredictionContext> mergeCache)\n\t{\n\t\tassert a!=null && b!=null; // must be empty context, never null\n\n\t\t// share same graph if both same\n\t\tif ( a==b || a.equals(b) ) return a;\n\n\t\tif ( a instanceof SingletonPredictionContext && b instanceof SingletonPredictionContext) {\n\t\t\treturn mergeSingletons((SingletonPredictionContext)a,\n\t\t\t\t\t\t\t\t   (SingletonPredictionContext)b,\n\t\t\t\t\t\t\t\t   rootIsWildcard, mergeCache);\n\t\t}\n\n\t\t// At least one of a or b is array\n\t\t// If one is $ and rootIsWildcard, return $ as * wildcard\n\t\tif ( rootIsWildcard ) {\n\t\t\tif ( a instanceof EmptyPredictionContext ) return a;\n\t\t\tif ( b instanceof EmptyPredictionContext ) return b;\n\t\t}\n\n\t\t// convert singleton so both are arrays to normalize\n\t\tif ( a instanceof SingletonPredictionContext ) {\n\t\t\ta = new ArrayPredictionContext((SingletonPredictionContext)a);\n\t\t}\n\t\tif ( b instanceof SingletonPredictionContext) {\n\t\t\tb = new ArrayPredictionContext((SingletonPredictionContext)b);\n\t\t}\n\t\treturn mergeArrays((ArrayPredictionContext) a, (ArrayPredictionContext) b,\n\t\t\t\t\t\t   rootIsWildcard, mergeCache);\n\t}",
        "Extra": ""
    },
    {
        "\ufeffID": "L7856",
        "Parent": "L7014",
        "commitID_before": "3468a5fbd868ce63c4cb61782e9baddac2ed24ae",
        "commitID_after": "5e05b71e8b1cd52cf0e77559786cc4c18dc85c37",
        "Project": "https://github.com/antlr/antlr4",
        "Type": "EXTRACT_METHOD",
        "Fowler_type": "Extract Function",
        "path_before": "runtime\\Java\\src\\org\\antlr\\v4\\runtime\\tree\\gui\\TreeViewer.java",
        "path_after": "runtime\\Java\\src\\org\\antlr\\v4\\runtime\\tree\\gui\\TreeViewer.java",
        "name": "void setRuleNames(List<String> ruleNames)",
        "LongName": "org.antlr.v4.runtime.tree.gui.TreeViewer.setRuleNames(Ljava/util/List;)V",
        "b_StartLine": "161",
        "b_StartColumn": "2",
        "b_EndLine": "172",
        "b_EndColumn": "3",
        "a_StartLine": "702",
        "a_StartColumn": "2",
        "a_EndLine": "704",
        "a_EndColumn": "3",
        "BeforeRefact": "public TreeViewer(@Nullable List<String> ruleNames, Tree tree) {\n\t\tsetTreeTextProvider(new DefaultTreeTextProvider(ruleNames));\n        boolean useIdentity = true; // compare node identity\n\t\tthis.treeLayout =\n\t\t\tnew TreeLayout<Tree>(new TreeLayoutAdaptor(tree),\n\t\t\t\t\t\t\t\t new TreeViewer.VariableExtentProvide(this),\n\t\t\t\t\t\t\t\t new DefaultConfiguration<Tree>(gapBetweenLevels,\n\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\tgapBetweenNodes),\n                                 useIdentity);\n\t\tupdatePreferredSize();\n\t\tsetFont(font);\n\t}",
        "AfterRefact": "public TreeViewer(@Nullable List<String> ruleNames, Tree tree) {\n\t\tsetRuleNames(ruleNames);\n\t\tif ( tree!=null ) {\n\t\t\tsetTree(tree);\n\t\t}\n\t\tsetFont(font);\n\t}\n\npublic void setTree(Tree root) {\n\t\tif ( root!=null ) {\n\t\t\tboolean useIdentity = true; // compare node identity\n\t\t\tthis.treeLayout =\n\t\t\t\tnew TreeLayout<Tree>(new TreeLayoutAdaptor(root),\n\t\t\t\t\t\t\t\t\t new TreeViewer.VariableExtentProvide(this),\n\t\t\t\t\t\t\t\t\t new DefaultConfiguration<Tree>(gapBetweenLevels,\n\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\tgapBetweenNodes),\n\t\t\t\t\t\t\t\t\t useIdentity);\n\t\t\t// Let the UI display this new AST.\n\t\t\tupdatePreferredSize();\n\t\t}\n\t\telse {\n\t\t\tthis.treeLayout = null;\n\t\t\trepaint();\n\t\t}\n\t}\npublic void setRuleNames(List<String> ruleNames) {\n\t\tsetTreeTextProvider(new DefaultTreeTextProvider(ruleNames));\n\t}",
        "Extra": ""
    },
    {
        "\ufeffID": "L3524",
        "Parent": "L1094",
        "commitID_before": "3468a5fbd868ce63c4cb61782e9baddac2ed24ae",
        "commitID_after": "5e05b71e8b1cd52cf0e77559786cc4c18dc85c37",
        "Project": "https://github.com/antlr/antlr4",
        "Type": "REMOVE_ASSIGNMENT_TO_PARAMETERS",
        "Fowler_type": "Split Variable",
        "path_before": "runtime\\Java\\src\\org\\antlr\\v4\\runtime\\atn\\RuleTransition.java",
        "path_after": "runtime\\Java\\src\\org\\antlr\\v4\\runtime\\atn\\RuleTransition.java",
        "name": "RuleTransition(RuleStartState ruleStart, int ruleIndex, ATNState followState)",
        "LongName": "org.antlr.v4.runtime.atn.RuleTransition.<init>(Lorg/antlr/v4/runtime/atn/RuleStartState;ILorg/antlr/v4/runtime/atn/ATNState;)V",
        "b_StartLine": "44",
        "b_StartColumn": "2",
        "b_EndLine": "51",
        "b_EndColumn": "3",
        "a_StartLine": "50",
        "a_StartColumn": "2",
        "a_EndLine": "56",
        "a_EndColumn": "3",
        "BeforeRefact": "\npublic RuleTransition(@NotNull RuleStartState ruleStart,\n\n\t\t\t\t\t\t  int ruleIndex,\n\n\t\t\t\t\t\t  @NotNull ATNState followState)\n\n\t{\n\n\t\tsuper(ruleStart);\n\n\t\tthis.ruleIndex = ruleIndex;\n\n\t\tthis.followState = followState;\n\n\t}",
        "AfterRefact": "public RuleTransition(@NotNull RuleStartState ruleStart,\n\n\t\t\t\t\t\t  int ruleIndex,\n\n\t\t\t\t\t\t  @NotNull ATNState followState)\n\n\t{\n\n\t\tthis(ruleStart, ruleIndex, 0, followState);\n\n\t}",
        "Extra": ""
    },
    {
        "\ufeffID": "L2447",
        "Parent": "L2315",
        "commitID_before": "3468a5fbd868ce63c4cb61782e9baddac2ed24ae",
        "commitID_after": "5e05b71e8b1cd52cf0e77559786cc4c18dc85c37",
        "Project": "https://github.com/antlr/antlr4",
        "Type": "ADD_PARAMETER",
        "Fowler_type": "Change Function Declaration",
        "path_before": "runtime\\Java\\src\\org\\antlr\\v4\\runtime\\atn\\LexerATNSimulator.java",
        "path_after": "runtime\\Java\\src\\org\\antlr\\v4\\runtime\\atn\\LexerATNSimulator.java",
        "name": "void accept(CharStream input, LexerActionExecutor lexerActionExecutor, int startIndex, int index, int line, int charPos)",
        "LongName": "org.antlr.v4.runtime.atn.LexerATNSimulator.accept(Lorg/antlr/v4/runtime/CharStream;Lorg/antlr/v4/runtime/atn/LexerActionExecutor;IIII)V",
        "b_StartLine": "358",
        "b_StartColumn": "2",
        "b_EndLine": "374",
        "b_EndColumn": "3",
        "a_StartLine": "365",
        "a_StartColumn": "2",
        "a_EndLine": "383",
        "a_EndColumn": "3",
        "BeforeRefact": "protected void accept(@NotNull CharStream input, int ruleIndex, int actionIndex,\n\t\t\t\t\t\t  int index, int line, int charPos)\n\t{\n\t\tif ( debug ) {\n\t\t\tSystem.out.format(Locale.getDefault(), \"ACTION %s:%d\\n\", recog != null ? recog.getRuleNames()[ruleIndex] : ruleIndex, actionIndex);\n\t\t}\n\n\t\tif ( actionIndex>=0 && recog!=null ) recog.action(null, ruleIndex, actionIndex);\n\n\t\t// seek to after last char in token\n\t\tinput.seek(index);\n\t\tthis.line = line;\n\t\tthis.charPositionInLine = charPos;\n\t\tif (input.LA(1) != IntStream.EOF) {\n\t\t\tconsume(input);\n\t\t}\n\t}",
        "AfterRefact": "protected void accept(@NotNull CharStream input, LexerActionExecutor lexerActionExecutor,\n\t\t\t\t\t\t  int startIndex, int index, int line, int charPos)\n\t{\n\t\tif ( debug ) {\n\t\t\tSystem.out.format(Locale.getDefault(), \"ACTION %s\\n\", lexerActionExecutor);\n\t\t}\n\n\t\t// seek to after last char in token\n\t\tinput.seek(index);\n\t\tthis.line = line;\n\t\tthis.charPositionInLine = charPos;\n\t\tif (input.LA(1) != IntStream.EOF) {\n\t\t\tconsume(input);\n\t\t}\n\n\t\tif (lexerActionExecutor != null && recog != null) {\n\t\t\tlexerActionExecutor.execute(recog, input, startIndex);\n\t\t}\n\t}",
        "Extra": ""
    },
    {
        "\ufeffID": "L24470",
        "Parent": "L2315",
        "commitID_before": "3468a5fbd868ce63c4cb61782e9baddac2ed24ae",
        "commitID_after": "5e05b71e8b1cd52cf0e77559786cc4c18dc85c37",
        "Project": "https://github.com/antlr/antlr4",
        "Type": "REMOVE_PARAMETER",
        "Fowler_type": "Change Function Declaration",
        "path_before": "runtime\\Java\\src\\org\\antlr\\v4\\runtime\\atn\\LexerATNSimulator.java",
        "path_after": "runtime\\Java\\src\\org\\antlr\\v4\\runtime\\atn\\LexerATNSimulator.java",
        "name": "void accept(CharStream input, LexerActionExecutor lexerActionExecutor, int startIndex, int index, int line, int charPos)",
        "LongName": "org.antlr.v4.runtime.atn.LexerATNSimulator.accept(Lorg/antlr/v4/runtime/CharStream;Lorg/antlr/v4/runtime/atn/LexerActionExecutor;IIII)V",
        "b_StartLine": "358",
        "b_StartColumn": "2",
        "b_EndLine": "374",
        "b_EndColumn": "3",
        "a_StartLine": "365",
        "a_StartColumn": "2",
        "a_EndLine": "383",
        "a_EndColumn": "3",
        "BeforeRefact": "protected void accept(@NotNull CharStream input, int ruleIndex, int actionIndex,\n\t\t\t\t\t\t  int index, int line, int charPos)\n\t{\n\t\tif ( debug ) {\n\t\t\tSystem.out.format(Locale.getDefault(), \"ACTION %s:%d\\n\", recog != null ? recog.getRuleNames()[ruleIndex] : ruleIndex, actionIndex);\n\t\t}\n\n\t\tif ( actionIndex>=0 && recog!=null ) recog.action(null, ruleIndex, actionIndex);\n\n\t\t// seek to after last char in token\n\t\tinput.seek(index);\n\t\tthis.line = line;\n\t\tthis.charPositionInLine = charPos;\n\t\tif (input.LA(1) != IntStream.EOF) {\n\t\t\tconsume(input);\n\t\t}\n\t}",
        "AfterRefact": "protected void accept(@NotNull CharStream input, LexerActionExecutor lexerActionExecutor,\n\t\t\t\t\t\t  int startIndex, int index, int line, int charPos)\n\t{\n\t\tif ( debug ) {\n\t\t\tSystem.out.format(Locale.getDefault(), \"ACTION %s\\n\", lexerActionExecutor);\n\t\t}\n\n\t\t// seek to after last char in token\n\t\tinput.seek(index);\n\t\tthis.line = line;\n\t\tthis.charPositionInLine = charPos;\n\t\tif (input.LA(1) != IntStream.EOF) {\n\t\t\tconsume(input);\n\t\t}\n\n\t\tif (lexerActionExecutor != null && recog != null) {\n\t\t\tlexerActionExecutor.execute(recog, input, startIndex);\n\t\t}\n\t}",
        "Extra": ""
    },
    {
        "\ufeffID": "L2288",
        "Parent": "L2178",
        "commitID_before": "ad9bac95199736c270940c4037b7ee7174bacca6",
        "commitID_after": "3468a5fbd868ce63c4cb61782e9baddac2ed24ae",
        "Project": "https://github.com/antlr/antlr4",
        "Type": "REMOVE_PARAMETER",
        "Fowler_type": "Change Function Declaration",
        "path_before": "runtime\\Java\\src\\org\\antlr\\v4\\runtime\\atn\\ParserATNSimulator.java",
        "path_after": "runtime\\Java\\src\\org\\antlr\\v4\\runtime\\atn\\ParserATNSimulator.java",
        "name": "int execATNWithFullContext(DFA dfa, DFAState D, ATNConfigSet s0, TokenStream input, int startIndex, ParserRuleContext outerContext)",
        "LongName": "runtime\\Java\\src\\org\\antlr\\v4\\runtime\\atn\\ParserATNSimulator.java",
        "b_StartLine": "776",
        "b_StartColumn": "2",
        "b_EndLine": "907",
        "b_EndColumn": "3",
        "a_StartLine": "596",
        "a_StartColumn": "2",
        "a_EndLine": "715",
        "a_EndColumn": "3",
        "BeforeRefact": "public int execATNWithFullContext(DFA dfa,\n\t\t\t\t\t\t\t\t\t  DFAState D, // how far we got before failing over\n\t\t\t\t\t\t\t\t\t  @NotNull ATNConfigSet s0,\n\t\t\t\t\t\t\t\t\t  @NotNull TokenStream input, int startIndex,\n\t\t\t\t\t\t\t\t\t  ParserRuleContext outerContext,\n\t\t\t\t\t\t\t\t\t  int SLL_min_alt) // todo: is this in D as min ambig alts?\n\t{\n\t\t// caller must have write lock on dfa\n\t\tretry_with_context++;\n\t\treportAttemptingFullContext(dfa, s0, startIndex, input.index());\n\n\t\tif ( debug || debug_list_atn_decisions ) {\n\t\t\tSystem.out.println(\"execATNWithFullContext \"+s0);\n\t\t}\n\t\tboolean fullCtx = true;\n\t\tboolean foundExactAmbig = false;\n\t\tATNConfigSet reach = null;\n\t\tATNConfigSet previous = s0;\n\t\tinput.seek(startIndex);\n\t\tint t = input.LA(1);\n\t\tint predictedAlt;\n\t\twhile (true) { // while more work\n//\t\t\tSystem.out.println(\"LL REACH \"+getLookaheadName(input)+\n//\t\t\t\t\t\t\t   \" from configs.size=\"+previous.size()+\n//\t\t\t\t\t\t\t   \" line \"+input.LT(1).getLine()+\":\"+input.LT(1).getCharPositionInLine());\n\t\t\treach = computeReachSet(previous, t, fullCtx);\n\t\t\tif ( reach==null ) {\n\t\t\t\t// if any configs in previous dipped into outer context, that\n\t\t\t\t// means that input up to t actually finished entry rule\n\t\t\t\t// at least for LL decision. Full LL doesn't dip into outer\n\t\t\t\t// so don't need special case.\n\t\t\t\t// We will get an error no matter what so delay until after\n\t\t\t\t// decision; better error message. Also, no reachable target\n\t\t\t\t// ATN states in SLL implies LL will also get nowhere.\n\t\t\t\t// If conflict in states that dip out, choose min since we\n\t\t\t\t// will get error no matter what.\n\t\t\t\tint alt = getAltThatFinishedDecisionEntryRule(previous);\n\t\t\t\tif ( alt!=ATN.INVALID_ALT_NUMBER ) {\n\t\t\t\t\treturn alt;\n\t\t\t\t}\n\t\t\t\tthrow noViableAlt(input, outerContext, previous, startIndex);\n\t\t\t}\n\n\t\t\tCollection<BitSet> altSubSets = PredictionMode.getConflictingAltSubsets(reach);\n\t\t\tif ( debug ) {\n\t\t\t\tSystem.out.println(\"LL altSubSets=\"+altSubSets+\n\t\t\t\t\t\t\t\t   \", predict=\"+PredictionMode.getUniqueAlt(altSubSets)+\n\t\t\t\t\t\t\t\t   \", resolvesToJustOneViableAlt=\"+\n\t\t\t\t\t\t\t\t\t   PredictionMode.resolvesToJustOneViableAlt(altSubSets));\n\t\t\t}\n\n//\t\t\tSystem.out.println(\"altSubSets: \"+altSubSets);\n\t\t\treach.uniqueAlt = getUniqueAlt(reach);\n\t\t\t// unique prediction?\n\t\t\tif ( reach.uniqueAlt!=ATN.INVALID_ALT_NUMBER ) {\n\t\t\t\tpredictedAlt = reach.uniqueAlt;\n\t\t\t\tbreak;\n\t\t\t}\n\t\t\tif ( mode != PredictionMode.LL_EXACT_AMBIG_DETECTION ) {\n\t\t\t\tpredictedAlt = PredictionMode.resolvesToJustOneViableAlt(altSubSets);\n\t\t\t\tif ( predictedAlt != ATN.INVALID_ALT_NUMBER ) {\n\t\t\t\t\tbreak;\n\t\t\t\t}\n\t\t\t}\n\t\t\telse {\n\t\t\t\t// In exact ambiguity mode, we never try to terminate early.\n\t\t\t\t// Just keeps scarfing until we know what the conflict is\n\t\t\t\tif ( PredictionMode.allSubsetsConflict(altSubSets) &&\n\t\t\t\t\t PredictionMode.allSubsetsEqual(altSubSets) )\n\t\t\t\t{\n\t\t\t\t\tfoundExactAmbig = true;\n\t\t\t\t\tpredictedAlt = PredictionMode.getSingleViableAlt(altSubSets);\n\t\t\t\t\tbreak;\n\t\t\t\t}\n\t\t\t\t// else there are multiple non-conflicting subsets or\n\t\t\t\t// we're not sure what the ambiguity is yet.\n\t\t\t\t// So, keep going.\n\t\t\t}\n\n\t\t\tprevious = reach;\n\t\t\tif (t != IntStream.EOF) {\n\t\t\t\tinput.consume();\n\t\t\t\tt = input.LA(1);\n\t\t\t}\n\t\t}\n\n\t\t// If the configuration set uniquely predicts an alternative,\n\t\t// without conflict, then we know that it's a full LL decision\n\t\t// not SLL.\n\t\tif ( reach.uniqueAlt != ATN.INVALID_ALT_NUMBER ) {\n\t\t\tretry_with_context_indicates_no_conflict++;\n\t\t\treportContextSensitivity(dfa, reach, startIndex, input.index());\n\t\t\tif ( predictedAlt == SLL_min_alt ) {\n\t\t\t\tretry_with_context_predicts_same_alt++;\n\t\t\t}\n\t\t\treturn predictedAlt;\n\t\t}\n\n\t\t// We do not check predicates here because we have checked them\n\t\t// on-the-fly when doing full context prediction.\n\n\t\t/*\n\t\tIn non-exact ambiguity detection mode, we might\tactually be able to\n\t\tdetect an exact ambiguity, but I'm not going to spend the cycles\n\t\tneeded to check. We only emit ambiguity warnings in exact ambiguity\n\t\tmode.\n\n\t\tFor example, we might know that we have conflicting configurations.\n\t\tBut, that does not mean that there is no way forward without a\n\t\tconflict. It's possible to have nonconflicting alt subsets as in:\n\n\t\t   LL altSubSets=[{1, 2}, {1, 2}, {1}, {1, 2}]\n\n\t\tfrom\n\n\t\t   [(17,1,[5 $]), (13,1,[5 10 $]), (21,1,[5 10 $]), (11,1,[$]),\n\t\t\t(13,2,[5 10 $]), (21,2,[5 10 $]), (11,2,[$])]\n\n\t\tIn this case, (17,1,[5 $]) indicates there is some next sequence that\n\t\twould resolve this without conflict to alternative 1. Any other viable\n\t\tnext sequence, however, is associated with a conflict.  We stop\n\t\tlooking for input because no amount of further lookahead will alter\n\t\tthe fact that we should predict alternative 1.  We just can't say for\n\t\tsure that there is an ambiguity without looking further.\n\t\t*/\n\t\tif ( foundExactAmbig ) {\n\t\t\treportAmbiguity(dfa, D, startIndex, input.index(), getConflictingAlts(reach), reach);\n\t\t}\n\n\t\treturn predictedAlt;\n\t}",
        "AfterRefact": "protected int execATNWithFullContext(DFA dfa,\n\t\t\t\t\t\t\t\t\t\t DFAState D, // how far we got before failing over\n\t\t\t\t\t\t\t\t\t\t @NotNull ATNConfigSet s0,\n\t\t\t\t\t\t\t\t\t\t @NotNull TokenStream input, int startIndex,\n\t\t\t\t\t\t\t\t\t\t ParserRuleContext outerContext)\n\t{\n\t\tif ( debug || debug_list_atn_decisions ) {\n\t\t\tSystem.out.println(\"execATNWithFullContext \"+s0);\n\t\t}\n\t\tboolean fullCtx = true;\n\t\tboolean foundExactAmbig = false;\n\t\tATNConfigSet reach = null;\n\t\tATNConfigSet previous = s0;\n\t\tinput.seek(startIndex);\n\t\tint t = input.LA(1);\n\t\tint predictedAlt;\n\t\twhile (true) { // while more work\n//\t\t\tSystem.out.println(\"LL REACH \"+getLookaheadName(input)+\n//\t\t\t\t\t\t\t   \" from configs.size=\"+previous.size()+\n//\t\t\t\t\t\t\t   \" line \"+input.LT(1).getLine()+\":\"+input.LT(1).getCharPositionInLine());\n\t\t\treach = computeReachSet(previous, t, fullCtx);\n\t\t\tif ( reach==null ) {\n\t\t\t\t// if any configs in previous dipped into outer context, that\n\t\t\t\t// means that input up to t actually finished entry rule\n\t\t\t\t// at least for LL decision. Full LL doesn't dip into outer\n\t\t\t\t// so don't need special case.\n\t\t\t\t// We will get an error no matter what so delay until after\n\t\t\t\t// decision; better error message. Also, no reachable target\n\t\t\t\t// ATN states in SLL implies LL will also get nowhere.\n\t\t\t\t// If conflict in states that dip out, choose min since we\n\t\t\t\t// will get error no matter what.\n\t\t\t\tint alt = getAltThatFinishedDecisionEntryRule(previous);\n\t\t\t\tif ( alt!=ATN.INVALID_ALT_NUMBER ) {\n\t\t\t\t\treturn alt;\n\t\t\t\t}\n\t\t\t\tthrow noViableAlt(input, outerContext, previous, startIndex);\n\t\t\t}\n\n\t\t\tCollection<BitSet> altSubSets = PredictionMode.getConflictingAltSubsets(reach);\n\t\t\tif ( debug ) {\n\t\t\t\tSystem.out.println(\"LL altSubSets=\"+altSubSets+\n\t\t\t\t\t\t\t\t   \", predict=\"+PredictionMode.getUniqueAlt(altSubSets)+\n\t\t\t\t\t\t\t\t   \", resolvesToJustOneViableAlt=\"+\n\t\t\t\t\t\t\t\t\t   PredictionMode.resolvesToJustOneViableAlt(altSubSets));\n\t\t\t}\n\n//\t\t\tSystem.out.println(\"altSubSets: \"+altSubSets);\n\t\t\treach.uniqueAlt = getUniqueAlt(reach);\n\t\t\t// unique prediction?\n\t\t\tif ( reach.uniqueAlt!=ATN.INVALID_ALT_NUMBER ) {\n\t\t\t\tpredictedAlt = reach.uniqueAlt;\n\t\t\t\tbreak;\n\t\t\t}\n\t\t\tif ( mode != PredictionMode.LL_EXACT_AMBIG_DETECTION ) {\n\t\t\t\tpredictedAlt = PredictionMode.resolvesToJustOneViableAlt(altSubSets);\n\t\t\t\tif ( predictedAlt != ATN.INVALID_ALT_NUMBER ) {\n\t\t\t\t\tbreak;\n\t\t\t\t}\n\t\t\t}\n\t\t\telse {\n\t\t\t\t// In exact ambiguity mode, we never try to terminate early.\n\t\t\t\t// Just keeps scarfing until we know what the conflict is\n\t\t\t\tif ( PredictionMode.allSubsetsConflict(altSubSets) &&\n\t\t\t\t\t PredictionMode.allSubsetsEqual(altSubSets) )\n\t\t\t\t{\n\t\t\t\t\tfoundExactAmbig = true;\n\t\t\t\t\tpredictedAlt = PredictionMode.getSingleViableAlt(altSubSets);\n\t\t\t\t\tbreak;\n\t\t\t\t}\n\t\t\t\t// else there are multiple non-conflicting subsets or\n\t\t\t\t// we're not sure what the ambiguity is yet.\n\t\t\t\t// So, keep going.\n\t\t\t}\n\n\t\t\tprevious = reach;\n\t\t\tif (t != IntStream.EOF) {\n\t\t\t\tinput.consume();\n\t\t\t\tt = input.LA(1);\n\t\t\t}\n\t\t}\n\n\t\t// If the configuration set uniquely predicts an alternative,\n\t\t// without conflict, then we know that it's a full LL decision\n\t\t// not SLL.\n\t\tif ( reach.uniqueAlt != ATN.INVALID_ALT_NUMBER ) {\n\t\t\treportContextSensitivity(dfa, predictedAlt, reach, startIndex, input.index());\n\t\t\treturn predictedAlt;\n\t\t}\n\n\t\t// We do not check predicates here because we have checked them\n\t\t// on-the-fly when doing full context prediction.\n\n\t\t/*\n\t\tIn non-exact ambiguity detection mode, we might\tactually be able to\n\t\tdetect an exact ambiguity, but I'm not going to spend the cycles\n\t\tneeded to check. We only emit ambiguity warnings in exact ambiguity\n\t\tmode.\n\n\t\tFor example, we might know that we have conflicting configurations.\n\t\tBut, that does not mean that there is no way forward without a\n\t\tconflict. It's possible to have nonconflicting alt subsets as in:\n\n\t\t   LL altSubSets=[{1, 2}, {1, 2}, {1}, {1, 2}]\n\n\t\tfrom\n\n\t\t   [(17,1,[5 $]), (13,1,[5 10 $]), (21,1,[5 10 $]), (11,1,[$]),\n\t\t\t(13,2,[5 10 $]), (21,2,[5 10 $]), (11,2,[$])]\n\n\t\tIn this case, (17,1,[5 $]) indicates there is some next sequence that\n\t\twould resolve this without conflict to alternative 1. Any other viable\n\t\tnext sequence, however, is associated with a conflict.  We stop\n\t\tlooking for input because no amount of further lookahead will alter\n\t\tthe fact that we should predict alternative 1.  We just can't say for\n\t\tsure that there is an ambiguity without looking further.\n\t\t*/\n\t\treportAmbiguity(dfa, D, startIndex, input.index(), foundExactAmbig, null, reach);\n\n\t\treturn predictedAlt;\n\t}",
        "Extra": ""
    },
    {
        "\ufeffID": "L2588",
        "Parent": "L832",
        "commitID_before": "ad9bac95199736c270940c4037b7ee7174bacca6",
        "commitID_after": "3468a5fbd868ce63c4cb61782e9baddac2ed24ae",
        "Project": "https://github.com/antlr/antlr4",
        "Type": "REPLACE_METHOD_WITH_METHOD_OBJECT",
        "Fowler_type": "Replace Function with Command",
        "path_before": "runtime\\Java\\src\\org\\antlr\\v4\\runtime\\atn\\PredictionContext.java",
        "path_after": "runtime\\Java\\src\\org\\antlr\\v4\\runtime\\atn\\PredictionContext.java",
        "name": "int calculateHashCode(PredictionContext parent, int returnState)",
        "LongName": "org.antlr.v4.runtime.atn.PredictionContext.calculateHashCode(Lorg/antlr/v4/runtime/atn/PredictionContext;I)I",
        "b_StartLine": "124",
        "b_StartColumn": "",
        "b_EndLine": "126",
        "b_EndColumn": "",
        "a_StartLine": "147",
        "a_StartColumn": "2",
        "a_EndLine": "153",
        "a_EndColumn": "3",
        "BeforeRefact": "protected static int calculateHashCode(int parentHashCode, int returnStateHashCode) {\n\t\treturn 5 * 5 * 7 + 5 * parentHashCode + returnStateHashCode;\n\t}",
        "AfterRefact": "protected static int calculateHashCode(PredictionContext parent, int returnState) {\n\t\tint hash = MurmurHash.initialize(INITIAL_HASH);\n\t\thash = MurmurHash.update(hash, parent);\n\t\thash = MurmurHash.update(hash, returnState);\n\t\thash = MurmurHash.finish(hash, 2);\n\t\treturn hash;\n\t}",
        "Extra": "public final class MurmurHash {\n\n\tprivate static final int DEFAULT_SEED = 0;\n\n\t/**\n\t * Initialize the hash using the default seed value.\n\t *\n\t * @return the intermediate hash value\n\t */\n\tpublic static int initialize() {\n\t\treturn initialize(DEFAULT_SEED);\n\t}\n\n\t/**\n\t * Initialize the hash using the specified {@code seed}.\n\t *\n\t * @param seed the seed\n\t * @return the intermediate hash value\n\t */\n\tpublic static int initialize(int seed) {\n\t\treturn seed;\n\t}\n\n\t/**\n\t * Update the intermediate hash value for the next input {@code value}.\n\t *\n\t * @param hash the intermediate hash value\n\t * @param value the value to add to the current hash\n\t * @return the updated intermediate hash value\n\t */\n\tpublic static int update(int hash, int value) {\n\t\tfinal int c1 = 0xCC9E2D51;\n\t\tfinal int c2 = 0x1B873593;\n\t\tfinal int r1 = 15;\n\t\tfinal int r2 = 13;\n\t\tfinal int m = 5;\n\t\tfinal int n = 0xE6546B64;\n\n\t\tint k = value;\n\t\tk = k * c1;\n\t\tk = (k << r1) | (k >>> (32 - r1));\n\t\tk = k * c2;\n\n\t\thash = hash ^ k;\n\t\thash = (hash << r2) | (hash >>> (32 - r2));\n\t\thash = hash * m + n;\n\n\t\treturn hash;\n\t}\n\n\t/**\n\t * Update the intermediate hash value for the next input {@code value}.\n\t *\n\t * @param hash the intermediate hash value\n\t * @param value the value to add to the current hash\n\t * @return the updated intermediate hash value\n\t */\n\tpublic static int update(int hash, Object value) {\n\t\treturn update(hash, value != null ? value.hashCode() : 0);\n\t}\n\n\t/**\n\t * Apply the final computation steps to the intermediate value {@code hash}\n\t * to form the final result of the MurmurHash 3 hash function.\n\t *\n\t * @param hash the intermediate hash value\n\t * @param numberOfWords the number of integer values added to the hash\n\t * @return the final hash result\n\t */\n\tpublic static int finish(int hash, int numberOfWords) {\n\t\thash = hash ^ (numberOfWords * 4);\n\t\thash = hash ^ (hash >>> 16);\n\t\thash = hash * 0x85EBCA6B;\n\t\thash = hash ^ (hash >>> 13);\n\t\thash = hash * 0xC2B2AE35;\n\t\thash = hash ^ (hash >>> 16);\n\t\treturn hash;\n\t}\n\n\t/**\n\t * Utility function to compute the hash code of an array using the\n\t * MurmurHash algorithm.\n\t *\n\t * @param <T> the array element type\n\t * @param data the array data\n\t * @param seed the seed for the MurmurHash algorithm\n\t * @return the hash code of the data\n\t */\n\tpublic static <T> int hashCode(T[] data, int seed) {\n\t\tint hash = initialize(seed);\n\t\tfor (T value : data) {\n\t\t\thash = update(hash, value);\n\t\t}\n\n\t\thash = finish(hash, data.length);\n\t\treturn hash;\n\t}\n\n\tprivate MurmurHash() {\n\t}\n}"
    },
    {
        "\ufeffID": "L3072",
        "Parent": "L3045",
        "commitID_before": "ad9bac95199736c270940c4037b7ee7174bacca6",
        "commitID_after": "3468a5fbd868ce63c4cb61782e9baddac2ed24ae",
        "Project": "https://github.com/antlr/antlr4",
        "Type": "ADD_PARAMETER",
        "Fowler_type": "Change Function Declaration",
        "path_before": "runtime\\Java\\src\\org\\antlr\\v4\\runtime\\BaseErrorListener.java",
        "path_after": "runtime\\Java\\src\\org\\antlr\\v4\\runtime\\BaseErrorListener.java",
        "name": "void reportContextSensitivity(Parser recognizer, DFA dfa, int startIndex, int stopIndex, int prediction, ATNConfigSet configs)",
        "LongName": "org.antlr.v4.runtime.BaseErrorListener.reportContextSensitivity(Lorg/antlr/v4/runtime/Parser;Lorg/antlr/v4/runtime/dfa/DFA;IIILorg/antlr/v4/runtime/atn/ATNConfigSet;)V",
        "b_StartLine": "71",
        "b_StartColumn": "2",
        "b_EndLine": "77",
        "b_EndColumn": "3",
        "a_StartLine": "72",
        "a_StartColumn": "2",
        "a_EndLine": "80",
        "a_EndColumn": "3",
        "BeforeRefact": "public void reportContextSensitivity(Parser recognizer,\n\t\t\t\t\t\t\t\t\t\t DFA dfa,\n\t\t\t\t\t\t\t\t\t\t int startIndex,\n\t\t\t\t\t\t\t\t\t\t int stopIndex,\n\t\t\t\t\t\t\t\t\t\t ATNConfigSet configs)\n\t{\n\t}",
        "AfterRefact": "public void reportContextSensitivity(Parser recognizer,\n\t\t\t\t\t\t\t\t\t\t DFA dfa,\n\t\t\t\t\t\t\t\t\t\t int startIndex,\n\t\t\t\t\t\t\t\t\t\t int stopIndex,\n\t\t\t\t\t\t\t\t\t\t int prediction,\n\t\t\t\t\t\t\t\t\t\t ATNConfigSet configs)\n\t{\n\t}",
        "Extra": ""
    },
    {
        "\ufeffID": "L2113",
        "Parent": "L981",
        "commitID_before": "ad9bac95199736c270940c4037b7ee7174bacca6",
        "commitID_after": "3468a5fbd868ce63c4cb61782e9baddac2ed24ae",
        "Project": "https://github.com/antlr/antlr4",
        "Type": "ADD_PARAMETER",
        "Fowler_type": "Change Function Declaration",
        "path_before": "runtime\\Java\\src\\org\\antlr\\v4\\runtime\\atn\\LL1Analyzer.java",
        "path_after": "runtime\\Java\\src\\org\\antlr\\v4\\runtime\\atn\\LL1Analyzer.java",
        "name": "void _LOOK(ATNState s, ATNState stopState, PredictionContext ctx, IntervalSet look, Set<ATNConfig> lookBusy, BitSet calledRuleStack, boolean seeThruPreds, boolean addEOF)",
        "LongName": "org.antlr.v4.runtime.atn.LL1Analyzer._LOOK(Lorg/antlr/v4/runtime/atn/ATNState;Lorg/antlr/v4/runtime/atn/ATNState;Lorg/antlr/v4/runtime/atn/PredictionContext;Lorg/antlr/v4/runtime/misc/IntervalSet;Ljava/util/Set;Ljava/util/BitSet;ZZ)V",
        "b_StartLine": "104",
        "b_StartColumn": "2",
        "b_EndLine": "166",
        "b_EndColumn": "3",
        "a_StartLine": "166",
        "a_StartColumn": "5",
        "a_EndLine": "262",
        "a_EndColumn": "3",
        "BeforeRefact": "protected void _LOOK(@NotNull ATNState s, @Nullable PredictionContext ctx,\n\t\t\t\t\t\t @NotNull IntervalSet look,\n                         @NotNull Set<ATNConfig> lookBusy,\n\t\t\t\t\t\t boolean seeThruPreds, boolean addEOF)\n\t{\n//\t\tSystem.out.println(\"_LOOK(\"+s.stateNumber+\", ctx=\"+ctx);\n        ATNConfig c = new ATNConfig(s, 0, ctx);\n        if ( !lookBusy.add(c) ) return;\n\n        if ( s instanceof RuleStopState ) {\n            if ( ctx==null ) {\n                look.add(Token.EPSILON);\n                return;\n            } else if (ctx.isEmpty() && addEOF) {\n\t\t\t\tlook.add(Token.EOF);\n\t\t\t\treturn;\n\t\t\t}\n\n\t\t\tif ( ctx != PredictionContext.EMPTY ) {\n\t\t\t\t// run thru all possible stack tops in ctx\n\t\t\t\tfor (SingletonPredictionContext p : ctx) {\n\t\t\t\t\tATNState returnState = atn.states.get(p.returnState);\n//\t\t\t\t\tSystem.out.println(\"popping back to \"+retState);\n\t\t\t\t\t_LOOK(returnState, p.parent, look, lookBusy, seeThruPreds, addEOF);\n\t\t\t\t}\n\t\t\t\treturn;\n\t\t\t}\n        }\n\n        int n = s.getNumberOfTransitions();\n        for (int i=0; i<n; i++) {\n\t\t\tTransition t = s.transition(i);\n\t\t\tif ( t.getClass() == RuleTransition.class ) {\n\t\t\t\tPredictionContext newContext =\n\t\t\t\t\tSingletonPredictionContext.create(ctx, ((RuleTransition)t).followState.stateNumber);\n\t\t\t\t_LOOK(t.target, newContext, look, lookBusy, seeThruPreds, addEOF);\n\t\t\t}\n\t\t\telse if ( t instanceof PredicateTransition ) {\n\t\t\t\tif ( seeThruPreds ) {\n\t\t\t\t\t_LOOK(t.target, ctx, look, lookBusy, seeThruPreds, addEOF);\n\t\t\t\t}\n\t\t\t\telse {\n\t\t\t\t\tlook.add(HIT_PRED);\n\t\t\t\t}\n\t\t\t}\n\t\t\telse if ( t.isEpsilon() ) {\n\t\t\t\t_LOOK(t.target, ctx, look, lookBusy, seeThruPreds, addEOF);\n\t\t\t}\n\t\t\telse if ( t.getClass() == WildcardTransition.class ) {\n\t\t\t\tlook.addAll( IntervalSet.of(Token.MIN_USER_TOKEN_TYPE, atn.maxTokenType) );\n\t\t\t}\n\t\t\telse {\n//\t\t\t\tSystem.out.println(\"adding \"+ t);\n\t\t\t\tIntervalSet set = t.label();\n\t\t\t\tif (set != null) {\n\t\t\t\t\tif (t instanceof NotSetTransition) {\n\t\t\t\t\t\tset = set.complement(IntervalSet.of(Token.MIN_USER_TOKEN_TYPE, atn.maxTokenType));\n\t\t\t\t\t}\n\t\t\t\t\tlook.addAll(set);\n\t\t\t\t}\n\t\t\t}\n\t\t}\n\t}",
        "AfterRefact": "protected void _LOOK(@NotNull ATNState s,\n\t\t\t\t\t\t @Nullable ATNState stopState,\n\t\t\t\t\t\t @Nullable PredictionContext ctx,\n\t\t\t\t\t\t @NotNull IntervalSet look,\n                         @NotNull Set<ATNConfig> lookBusy,\n\t\t\t\t\t\t @NotNull BitSet calledRuleStack,\n\t\t\t\t\t\t boolean seeThruPreds, boolean addEOF)\n\t{\n//\t\tSystem.out.println(\"_LOOK(\"+s.stateNumber+\", ctx=\"+ctx);\n        ATNConfig c = new ATNConfig(s, 0, ctx);\n        if ( !lookBusy.add(c) ) return;\n\n\t\tif (s == stopState) {\n\t\t\tif (ctx == null) {\n\t\t\t\tlook.add(Token.EPSILON);\n\t\t\t\treturn;\n\t\t\t} else if (ctx.isEmpty() && addEOF) {\n\t\t\t\tlook.add(Token.EOF);\n\t\t\t\treturn;\n\t\t\t}\n\t\t}\n\n        if ( s instanceof RuleStopState ) {\n            if ( ctx==null ) {\n                look.add(Token.EPSILON);\n                return;\n            } else if (ctx.isEmpty() && addEOF) {\n\t\t\t\tlook.add(Token.EOF);\n\t\t\t\treturn;\n\t\t\t}\n\n\t\t\tif ( ctx != PredictionContext.EMPTY ) {\n\t\t\t\t// run thru all possible stack tops in ctx\n\t\t\t\tfor (int i = 0; i < ctx.size(); i++) {\n\t\t\t\t\tATNState returnState = atn.states.get(ctx.getReturnState(i));\n//\t\t\t\t\tSystem.out.println(\"popping back to \"+retState);\n\n\t\t\t\t\tboolean removed = calledRuleStack.get(returnState.ruleIndex);\n\t\t\t\t\ttry {\n\t\t\t\t\t\tcalledRuleStack.clear(returnState.ruleIndex);\n\t\t\t\t\t\t_LOOK(returnState, stopState, ctx.getParent(i), look, lookBusy, calledRuleStack, seeThruPreds, addEOF);\n\t\t\t\t\t}\n\t\t\t\t\tfinally {\n\t\t\t\t\t\tif (removed) {\n\t\t\t\t\t\t\tcalledRuleStack.set(returnState.ruleIndex);\n\t\t\t\t\t\t}\n\t\t\t\t\t}\n\t\t\t\t}\n\t\t\t\treturn;\n\t\t\t}\n        }\n\n        int n = s.getNumberOfTransitions();\n        for (int i=0; i<n; i++) {\n\t\t\tTransition t = s.transition(i);\n\t\t\tif ( t.getClass() == RuleTransition.class ) {\n\t\t\t\tif (calledRuleStack.get(((RuleTransition)t).target.ruleIndex)) {\n\t\t\t\t\tcontinue;\n\t\t\t\t}\n\n\t\t\t\tPredictionContext newContext =\n\t\t\t\t\tSingletonPredictionContext.create(ctx, ((RuleTransition)t).followState.stateNumber);\n\n\t\t\t\ttry {\n\t\t\t\t\tcalledRuleStack.set(((RuleTransition)t).target.ruleIndex);\n\t\t\t\t\t_LOOK(t.target, stopState, newContext, look, lookBusy, calledRuleStack, seeThruPreds, addEOF);\n\t\t\t\t}\n\t\t\t\tfinally {\n\t\t\t\t\tcalledRuleStack.clear(((RuleTransition)t).target.ruleIndex);\n\t\t\t\t}\n\t\t\t}\n\t\t\telse if ( t instanceof PredicateTransition ) {\n\t\t\t\tif ( seeThruPreds ) {\n\t\t\t\t\t_LOOK(t.target, stopState, ctx, look, lookBusy, calledRuleStack, seeThruPreds, addEOF);\n\t\t\t\t}\n\t\t\t\telse {\n\t\t\t\t\tlook.add(HIT_PRED);\n\t\t\t\t}\n\t\t\t}\n\t\t\telse if ( t.isEpsilon() ) {\n\t\t\t\t_LOOK(t.target, stopState, ctx, look, lookBusy, calledRuleStack, seeThruPreds, addEOF);\n\t\t\t}\n\t\t\telse if ( t.getClass() == WildcardTransition.class ) {\n\t\t\t\tlook.addAll( IntervalSet.of(Token.MIN_USER_TOKEN_TYPE, atn.maxTokenType) );\n\t\t\t}\n\t\t\telse {\n//\t\t\t\tSystem.out.println(\"adding \"+ t);\n\t\t\t\tIntervalSet set = t.label();\n\t\t\t\tif (set != null) {\n\t\t\t\t\tif (t instanceof NotSetTransition) {\n\t\t\t\t\t\tset = set.complement(IntervalSet.of(Token.MIN_USER_TOKEN_TYPE, atn.maxTokenType));\n\t\t\t\t\t}\n\t\t\t\t\tlook.addAll(set);\n\t\t\t\t}\n\t\t\t}\n\t\t}\n\t}",
        "Extra": ""
    },
    {
        "\ufeffID": "L5418",
        "Parent": "L543",
        "commitID_before": "3468a5fbd868ce63c4cb61782e9baddac2ed24ae",
        "commitID_after": "5e05b71e8b1cd52cf0e77559786cc4c18dc85c37",
        "Project": "https://github.com/antlr/antlr4",
        "Type": "REMOVE_ASSIGNMENT_TO_PARAMETERS",
        "Fowler_type": "Split Variable",
        "path_before": "runtime\\Java\\src\\org\\antlr\\v4\\runtime\\Parser.java",
        "path_after": "runtime\\Java\\src\\org\\antlr\\v4\\runtime\\Parser.java",
        "name": "void enterOuterAlt(ParserRuleContext localctx, int altNum)",
        "LongName": "org.antlr.v4.runtime.Parser.enterOuterAlt(Lorg/antlr/v4/runtime/ParserRuleContext;I)V",
        "b_StartLine": "",
        "b_StartColumn": "",
        "b_EndLine": "",
        "b_EndColumn": "",
        "a_StartLine": "",
        "a_StartColumn": "",
        "a_EndLine": "",
        "a_EndColumn": "",
        "BeforeRefact": "public void enterOuterAlt(ParserRuleContext localctx, int altNum) {\n\t\t// if we have new localctx, make sure we replace existing ctx\n\t\t// that is previous child of parse tree\n\t\tif ( _buildParseTrees && _ctx != localctx ) {\n\t\t\tParserRuleContext parent = (ParserRuleContext)_ctx.parent;\n\t\t\tif ( parent!=null )\t{\n\t\t\t\tparent.removeLastChild();\n\t\t\t\tparent.addChild(localctx);\n\t\t\t}\n\t\t}\n\t\t_ctx = localctx;\n\t\t_ctx.altNum = altNum;\n\t}",
        "AfterRefact": "public void enterOuterAlt(ParserRuleContext localctx, int altNum) {\n\t\t// if we have new localctx, make sure we replace existing ctx\n\t\t// that is previous child of parse tree\n\t\tif ( _buildParseTrees && _ctx != localctx ) {\n\t\t\tParserRuleContext parent = (ParserRuleContext)_ctx.parent;\n\t\t\tif ( parent!=null )\t{\n\t\t\t\tparent.removeLastChild();\n\t\t\t\tparent.addChild(localctx);\n\t\t\t}\n\t\t}\n\t\t_ctx = localctx;\n\t}",
        "Extra": ""
    },
    {
        "\ufeffID": "L3446",
        "Parent": "L3013",
        "commitID_before": "ad9bac95199736c270940c4037b7ee7174bacca6",
        "commitID_after": "3468a5fbd868ce63c4cb61782e9baddac2ed24ae",
        "Project": "https://github.com/antlr/antlr4",
        "Type": "EXTRACT_METHOD",
        "Fowler_type": "Extract Function",
        "path_before": "runtime\\Java\\src\\org\\antlr\\v4\\runtime\\DefaultErrorStrategy.java",
        "path_after": "",
        "name": "void reportMatch(Parser recognizer)",
        "LongName": "org.antlr.v4.runtime.DefaultErrorStrategy.reportMatch(Lorg/antlr/v4/runtime/Parser;)V",
        "b_StartLine": "340",
        "b_StartColumn": "2",
        "b_EndLine": "358",
        "b_EndColumn": "3",
        "a_StartLine": "109",
        "a_StartColumn": "2",
        "a_EndLine": "112",
        "a_EndColumn": "3",
        "BeforeRefact": "public Token singleTokenDeletion(Parser recognizer) {\n\t\tint nextTokenType = recognizer.getInputStream().LA(2);\n\t\tIntervalSet expecting = getExpectedTokens(recognizer);\n\t\tif ( expecting.contains(nextTokenType) ) {\n\t\t\treportUnwantedToken(recognizer);\n\t\t\t/*\n\t\t\tSystem.err.println(\"recoverFromMismatchedToken deleting \"+\n\t\t\t\t\t\t\t   ((TokenStream)recognizer.getInputStream()).LT(1)+\n\t\t\t\t\t\t\t   \" since \"+((TokenStream)recognizer.getInputStream()).LT(2)+\n\t\t\t\t\t\t\t   \" is what we want\");\n\t\t\t*/\n\t\t\trecognizer.consume(); // simply delete extra token\n\t\t\t// we want to return the token we're actually matching\n\t\t\tToken matchedSymbol = recognizer.getCurrentToken();\n\t\t\tendErrorCondition(recognizer);  // we know current token is correct\n\t\t\treturn matchedSymbol;\n\t\t}\n\t\treturn null;\n\t}",
        "AfterRefact": "protected Token singleTokenDeletion(@NotNull Parser recognizer) {\n\t\tint nextTokenType = recognizer.getInputStream().LA(2);\n\t\tIntervalSet expecting = getExpectedTokens(recognizer);\n\t\tif ( expecting.contains(nextTokenType) ) {\n\t\t\treportUnwantedToken(recognizer);\n\t\t\t/*\n\t\t\tSystem.err.println(\"recoverFromMismatchedToken deleting \"+\n\t\t\t\t\t\t\t   ((TokenStream)recognizer.getInputStream()).LT(1)+\n\t\t\t\t\t\t\t   \" since \"+((TokenStream)recognizer.getInputStream()).LT(2)+\n\t\t\t\t\t\t\t   \" is what we want\");\n\t\t\t*/\n\t\t\trecognizer.consume(); // simply delete extra token\n\t\t\t// we want to return the token we're actually matching\n\t\t\tToken matchedSymbol = recognizer.getCurrentToken();\n\t\t\treportMatch(recognizer);  // we know current token is correct\n\t\t\treturn matchedSymbol;\n\t\t}\n\t\treturn null;\n\t}\npublic void reportMatch(Parser recognizer) {\n\t\tendErrorCondition(recognizer);\n\t}",
        "Extra": ""
    },
    {
        "\ufeffID": "L3949",
        "Parent": "L103",
        "commitID_before": "ed47b7f487bafa48cff47f051af81a004cd36049",
        "commitID_after": "a30e87b6ac67f14a42b97d427bb1c8c6ba18cd87",
        "Project": "https://github.com/junit-team/junit4",
        "Type": "ADD_PARAMETER",
        "Fowler_type": "Change Function Declaration",
        "path_before": "src\\main\\java\\org\\junit\\experimental\\theories\\Theories.java",
        "path_after": "src\\main\\java\\org\\junit\\experimental\\theories\\Theories.java",
        "name": "TheoryAnchor(FrameworkMethod method, TestClass testClass)",
        "LongName": "org.junit.experimental.theories.Theories$TheoryAnchor.<init>(Lorg/junit/runners/model/FrameworkMethod;Lorg/junit/runners/model/TestClass;)V",
        "b_StartLine": "76",
        "b_StartColumn": "2",
        "b_EndLine": "78",
        "b_EndColumn": "3",
        "a_StartLine": "78",
        "a_StartColumn": "3",
        "a_EndLine": "81",
        "a_EndColumn": "4",
        "BeforeRefact": "public TheoryAnchor(FrameworkMethod method) {\n\t\t\tfTestMethod= method;\n\t\t}",
        "AfterRefact": "public TheoryAnchor(FrameworkMethod method, TestClass testClass) {\n\t\t\tfTestMethod= method;\n            fTestClass= testClass;\n\t\t}",
        "Extra": ""
    },
    {
        "\ufeffID": "L8052",
        "Parent": "L103",
        "commitID_before": "ed47b7f487bafa48cff47f051af81a004cd36049",
        "commitID_after": "a30e87b6ac67f14a42b97d427bb1c8c6ba18cd87",
        "Project": "https://github.com/junit-team/junit4",
        "Type": "ADD_PARAMETER",
        "Fowler_type": "Change Function Declaration",
        "path_before": "src\\test\\java\\org\\junit\\tests\\experimental\\theories\\extendingwithstubs\\StubbedTheories.java",
        "path_after": "src\\test\\java\\org\\junit\\tests\\experimental\\theories\\extendingwithstubs\\StubbedTheories.java",
        "name": "StubbedTheoryAnchor(FrameworkMethod method, TestClass testClass)",
        "LongName": "org.junit.tests.experimental.theories.extendingwithstubs.StubbedTheories$StubbedTheoryAnchor.<init>(Lorg/junit/runners/model/FrameworkMethod;Lorg/junit/runners/model/TestClass;)V",
        "b_StartLine": "26",
        "b_StartColumn": "",
        "b_EndLine": "28",
        "b_EndColumn": "",
        "a_StartLine": "27",
        "a_StartColumn": "3",
        "a_EndLine": "29",
        "a_EndColumn": "4",
        "BeforeRefact": "public StubbedTheoryAnchor(FrameworkMethod method) {\n\t\t\tsuper(method);\n\t\t}",
        "AfterRefact": "public StubbedTheoryAnchor(FrameworkMethod method, TestClass testClass) {\n\t\t\tsuper(method, testClass);\n\t\t}",
        "Extra": ""
    },
    {
        "\ufeffID": "L4884",
        "Parent": "L4876",
        "commitID_before": "ed47b7f487bafa48cff47f051af81a004cd36049",
        "commitID_after": "a30e87b6ac67f14a42b97d427bb1c8c6ba18cd87",
        "Project": "https://github.com/junit-team/junit4",
        "Type": "INLINE_TEMP",
        "Fowler_type": "Inline Variable",
        "path_before": "src\\main\\java\\org\\junit\\internal\\runners\\model\\EachTestNotifier.java",
        "path_after": "src\\main\\java\\org\\junit\\internal\\runners\\model\\EachTestNotifier.java",
        "name": "void addFailure(Throwable targetException)",
        "LongName": "org.junit.internal.runners.model.EachTestNotifier.addFailure(Ljava/lang/Throwable;)V",
        "b_StartLine": "",
        "b_StartColumn": "",
        "b_EndLine": "",
        "b_EndColumn": "",
        "a_StartLine": "21",
        "a_StartColumn": "2",
        "a_EndLine": "28",
        "a_EndColumn": "3",
        "BeforeRefact": "public void addFailure(Throwable targetException) {\n\t\tif (targetException instanceof MultipleFailureException) {\n\t\t\tMultipleFailureException mfe= (MultipleFailureException) targetException;\n\t\t\tfor (Throwable each : mfe.getFailures())\n\t\t\t\taddFailure(each);\n\t\t\treturn;\n\t\t}\n\t\tfNotifier.fireTestFailure(new Failure(fDescription, targetException));\n\t}",
        "AfterRefact": "public void addFailure(Throwable targetException) {\n\t\tif (targetException instanceof MultipleFailureException) {\n\t\t\taddMultipleFailureException((MultipleFailureException) targetException);\n\t\t} else {\n\t\t\tfNotifier\n\t\t\t\t\t.fireTestFailure(new Failure(fDescription, targetException));\n\t\t}\n\t}",
        "Extra": ""
    },
    {
        "\ufeffID": "L5882",
        "Parent": "L103",
        "commitID_before": "ed47b7f487bafa48cff47f051af81a004cd36049",
        "commitID_after": "a30e87b6ac67f14a42b97d427bb1c8c6ba18cd87",
        "Project": "https://github.com/junit-team/junit4",
        "Type": "EXTRACT_METHOD",
        "Fowler_type": "Extract Function",
        "path_before": "src\\main\\java\\org\\junit\\runners\\BlockJUnit4ClassRunner.java",
        "path_after": "src\\main\\java\\org\\junit\\runners\\BlockJUnit4ClassRunner.java",
        "name": "void runNotIgnored(FrameworkMethod method, EachTestNotifier eachNotifier)",
        "LongName": "org.junit.runners.BlockJUnit4ClassRunner.runNotIgnored(Lorg/junit/runners/model/FrameworkMethod;Lorg/junit/internal/runners/model/EachTestNotifier;)V",
        "b_StartLine": "67",
        "b_StartColumn": "",
        "b_EndLine": "84",
        "b_EndColumn": "",
        "a_StartLine": "75",
        "a_StartColumn": "2",
        "a_EndLine": "87",
        "a_EndColumn": "3",
        "BeforeRefact": "protected void runChild(FrameworkMethod method, RunNotifier notifier) {\n\t\tEachTestNotifier eachNotifier= makeNotifier(method, notifier);\n\t\tif (method.getAnnotation(Ignore.class) != null) {\n\t\t\teachNotifier.fireTestIgnored();\n\t\t\treturn;\n\t\t}\n\n\t\teachNotifier.fireTestStarted();\n\t\ttry {\n\t\t\tmethodBlock(method).evaluate();\n\t\t} catch (AssumptionViolatedException e) {\n\t\t\teachNotifier.addFailedAssumption(e);\n\t\t} catch (Throwable e) {\n\t\t\teachNotifier.addFailure(e);\n\t\t} finally {\n\t\t\teachNotifier.fireTestFinished();\n\t\t}\n\t}",
        "AfterRefact": "protected void runChild(FrameworkMethod method, RunNotifier notifier) {\n\t\tEachTestNotifier eachNotifier= makeNotifier(method, notifier);\n\t\tif (method.getAnnotation(Ignore.class) != null) {\n\t\t\trunIgnored(eachNotifier);\n\t\t} else {\n\t\t\trunNotIgnored(method, eachNotifier);\n\t\t}\n\t}\n\n\tprivate void runNotIgnored(FrameworkMethod method,\n\t\t\tEachTestNotifier eachNotifier) {\n\t\teachNotifier.fireTestStarted();\n\t\ttry {\n\t\t\tmethodBlock(method).evaluate();\n\t\t} catch (AssumptionViolatedException e) {\n\t\t\teachNotifier.addFailedAssumption(e);\n\t\t} catch (Throwable e) {\n\t\t\teachNotifier.addFailure(e);\n\t\t} finally {\n\t\t\teachNotifier.fireTestFinished();\n\t\t}\n\t}",
        "Extra": ""
    },
    {
        "\ufeffID": "L5880",
        "Parent": "L103",
        "commitID_before": "ed47b7f487bafa48cff47f051af81a004cd36049",
        "commitID_after": "a30e87b6ac67f14a42b97d427bb1c8c6ba18cd87",
        "Project": "https://github.com/junit-team/junit4",
        "Type": "EXTRACT_METHOD",
        "Fowler_type": "Extract Function",
        "path_before": "src\\main\\java\\org\\junit\\runners\\BlockJUnit4ClassRunner.java",
        "path_after": "src\\main\\java\\org\\junit\\runners\\BlockJUnit4ClassRunner.java",
        "name": "void runIgnored(EachTestNotifier eachNotifier)",
        "LongName": "org.junit.runners.BlockJUnit4ClassRunner.runIgnored(Lorg/junit/internal/runners/model/EachTestNotifier;)V",
        "b_StartLine": "67",
        "b_StartColumn": "",
        "b_EndLine": "84",
        "b_EndColumn": "",
        "a_StartLine": "89",
        "a_StartColumn": "2",
        "a_EndLine": "91",
        "a_EndColumn": "3",
        "BeforeRefact": "protected void runChild(FrameworkMethod method, RunNotifier notifier) {\n\t\tEachTestNotifier eachNotifier= makeNotifier(method, notifier);\n\t\tif (method.getAnnotation(Ignore.class) != null) {\n\t\t\teachNotifier.fireTestIgnored();\n\t\t\treturn;\n\t\t}\n\n\t\teachNotifier.fireTestStarted();\n\t\ttry {\n\t\t\tmethodBlock(method).evaluate();\n\t\t} catch (AssumptionViolatedException e) {\n\t\t\teachNotifier.addFailedAssumption(e);\n\t\t} catch (Throwable e) {\n\t\t\teachNotifier.addFailure(e);\n\t\t} finally {\n\t\t\teachNotifier.fireTestFinished();\n\t\t}\n\t}",
        "AfterRefact": "protected void runChild(FrameworkMethod method, RunNotifier notifier) {\n\t\tEachTestNotifier eachNotifier= makeNotifier(method, notifier);\n\t\tif (method.getAnnotation(Ignore.class) != null) {\n\t\t\trunIgnored(eachNotifier);\n\t\t} else {\n\t\t\trunNotIgnored(method, eachNotifier);\n\t\t}\n\t}\n\n\tprivate void runNotIgnored(FrameworkMethod method,\n\t\t\tEachTestNotifier eachNotifier) {\n\t\teachNotifier.fireTestStarted();\n\t\ttry {\n\t\t\tmethodBlock(method).evaluate();\n\t\t} catch (AssumptionViolatedException e) {\n\t\t\teachNotifier.addFailedAssumption(e);\n\t\t} catch (Throwable e) {\n\t\t\teachNotifier.addFailure(e);\n\t\t} finally {\n\t\t\teachNotifier.fireTestFinished();\n\t\t}\n\t}\n\n\tprivate void runIgnored(EachTestNotifier eachNotifier) {\n\t\teachNotifier.fireTestIgnored();\n\t}",
        "Extra": ""
    },
    {
        "\ufeffID": "L4889",
        "Parent": "L103",
        "commitID_before": "ed47b7f487bafa48cff47f051af81a004cd36049",
        "commitID_after": "a30e87b6ac67f14a42b97d427bb1c8c6ba18cd87",
        "Project": "https://github.com/junit-team/junit4",
        "Type": "EXTRACT_METHOD",
        "Fowler_type": "Extract Function",
        "path_before": "src\\main\\java\\org\\junit\\internal\\runners\\model\\EachTestNotifier.java",
        "path_after": "src\\main\\java\\org\\junit\\internal\\runners\\model\\EachTestNotifier.java",
        "name": "void addMultipleFailureException(MultipleFailureException mfe)",
        "LongName": "org.junit.internal.runners.model.EachTestNotifier.addMultipleFailureException(Lorg/junit/internal/runners/model/MultipleFailureException;)V",
        "b_StartLine": "",
        "b_StartColumn": "",
        "b_EndLine": "",
        "b_EndColumn": "",
        "a_StartLine": "30",
        "a_StartColumn": "2",
        "a_EndLine": "33",
        "a_EndColumn": "3",
        "BeforeRefact": "public void addFailure(Throwable targetException) {\n\t\tif (targetException instanceof MultipleFailureException) {\n\t\t\tMultipleFailureException mfe= (MultipleFailureException) targetException;\n\t\t\tfor (Throwable each : mfe.getFailures())\n\t\t\t\taddFailure(each);\n\t\t\treturn;\n\t\t}\n\t\tfNotifier.fireTestFailure(new Failure(fDescription, targetException));\n\t}",
        "AfterRefact": "public void addFailure(Throwable targetException) {\n\t\tif (targetException instanceof MultipleFailureException) {\n\t\t\taddMultipleFailureException((MultipleFailureException) targetException);\n\t\t} else {\n\t\t\tfNotifier\n\t\t\t\t\t.fireTestFailure(new Failure(fDescription, targetException));\n\t\t}\n\t}\n\n\tprivate void addMultipleFailureException(MultipleFailureException mfe) {\n\t\tfor (Throwable each : mfe.getFailures())\n\t\t\taddFailure(each);\n\t}",
        "Extra": ""
    },
    {
        "\ufeffID": "L7126",
        "Parent": "L6751",
        "commitID_before": "ed47b7f487bafa48cff47f051af81a004cd36049",
        "commitID_after": "a30e87b6ac67f14a42b97d427bb1c8c6ba18cd87",
        "Project": "https://github.com/junit-team/junit4",
        "Type": "INTRODUCE_ASSERTION",
        "Fowler_type": "Introduce Assertion",
        "path_before": "src\\test\\java\\org\\junit\\tests\\experimental\\categories\\CategoryTest.java",
        "path_after": "src\\test\\java\\org\\junit\\tests\\experimental\\categories\\CategoryTest.java",
        "name": "void testCountWithExplicitFilter()",
        "LongName": "org.junit.tests.experimental.categories.CategoryTest.testCountWithExplicitFilter()V",
        "b_StartLine": "128",
        "b_StartColumn": "",
        "b_EndLine": "133",
        "b_EndColumn": "",
        "a_StartLine": "129",
        "a_StartColumn": "",
        "a_EndLine": "135",
        "a_EndColumn": "",
        "BeforeRefact": "public void testCountWithExplicitFilter() throws Throwable {\n\t\tCategoryFilter include= CategoryFilter.include(SlowTests.class);\n\t\tRequest baseRequest= Request.aClass(TestSuiteWithNoCategories.class);\n\t\tResult result= new JUnitCore().run(baseRequest.filterWith(include));\n\t\tassertTrue(result.wasSuccessful());\n\t}",
        "AfterRefact": "public void testCountWithExplicitFilter() throws Throwable {\n\t\tCategoryFilter include= CategoryFilter.include(SlowTests.class);\n\t\tRequest baseRequest= Request.aClass(TestSuiteWithNoCategories.class);\n\t\tResult result= new JUnitCore().run(baseRequest.filterWith(include));\n\t\tassertTrue(result.wasSuccessful());\n\t\tassertEquals(2, result.getRunCount());\n\t}",
        "Extra": ""
    },
    {
        "\ufeffID": "L126",
        "Parent": "L118",
        "commitID_before": "ed47b7f487bafa48cff47f051af81a004cd36049",
        "commitID_after": "a30e87b6ac67f14a42b97d427bb1c8c6ba18cd87",
        "Project": "https://github.com/junit-team/junit4",
        "Type": "EXTRACT_METHOD",
        "Fowler_type": "Extract Function",
        "path_before": "src\\main\\java\\junit\\framework\\TestSuite.java",
        "path_after": "src\\main\\java\\junit\\framework\\TestSuite.java",
        "name": "public TestSuite(final Class<? extends TestCase> theClass)",
        "LongName": "junit.framework.TestSuite.<init>()V",
        "b_StartLine": "128",
        "b_StartColumn": "",
        "b_EndLine": "151",
        "b_EndColumn": "",
        "a_StartLine": "128",
        "a_StartColumn": "",
        "a_EndLine": "155",
        "a_EndColumn": "",
        "BeforeRefact": "public TestSuite(final Class<? extends TestCase> theClass) {\n\t\tfName= theClass.getName();\n\t\ttry {\n\t\t\tgetTestConstructor(theClass); // Avoid generating multiple error messages\n\t\t} catch (NoSuchMethodException e) {\n\t\t\taddTest(warning(\"Class \"+theClass.getName()+\" has no public constructor TestCase(String name) or TestCase()\"));\n\t\t\treturn;\n\t\t}\n\n\t\tif (!Modifier.isPublic(theClass.getModifiers())) {\n\t\t\taddTest(warning(\"Class \"+theClass.getName()+\" is not public\"));\n\t\t\treturn;\n\t\t}\n\n\t\tClass<?> superClass= theClass;\n\t\tList<String> names= new ArrayList<String>();\n\t\twhile (Test.class.isAssignableFrom(superClass)) {\n\t\t\tfor (Method each : superClass.getDeclaredMethods())\n\t\t\t\taddTestMethod(each, names, theClass);\n\t\t\tsuperClass= superClass.getSuperclass();\n\t\t}\n\t\tif (fTests.size() == 0)\n\t\t\taddTest(warning(\"No tests found in \"+theClass.getName()));\n\t}",
        "AfterRefact": "public TestSuite(final Class<?> theClass) {\n\t\taddTestsFromTestCase(theClass);\n\t}\n\n\tprivate void addTestsFromTestCase(final Class<?> theClass) {\n\t\tfName= theClass.getName();\n\t\ttry {\n\t\t\tgetTestConstructor(theClass); // Avoid generating multiple error messages\n\t\t} catch (NoSuchMethodException e) {\n\t\t\taddTest(warning(\"Class \"+theClass.getName()+\" has no public constructor TestCase(String name) or TestCase()\"));\n\t\t\treturn;\n\t\t}\n\n\t\tif (!Modifier.isPublic(theClass.getModifiers())) {\n\t\t\taddTest(warning(\"Class \"+theClass.getName()+\" is not public\"));\n\t\t\treturn;\n\t\t}\n\n\t\tClass<?> superClass= theClass;\n\t\tList<String> names= new ArrayList<String>();\n\t\twhile (Test.class.isAssignableFrom(superClass)) {\n\t\t\tfor (Method each : superClass.getDeclaredMethods())\n\t\t\t\taddTestMethod(each, names, theClass);\n\t\t\tsuperClass= superClass.getSuperclass();\n\t\t}\n\t\tif (fTests.size() == 0)\n\t\t\taddTest(warning(\"No tests found in \"+theClass.getName()));\n\t}\n\t",
        "Extra": ""
    }
]